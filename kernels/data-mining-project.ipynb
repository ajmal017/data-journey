{"cells":[{"metadata":{},"cell_type":"markdown","source":"**1. The problem statement **\n\nIn this kernel, I try to make predictions where the prediction task is to determine whether a person makes over 50K a year. I implement Random Forest Classification, Logistic Regression, Decision Tree and SVM with Python and Scikit-Learn. So, to answer the question, I build a Random Forest classifier,  Logistic Regression, Decision Tree and SVM to predict whether a person makes over 50K a year."},{"metadata":{},"cell_type":"markdown","source":"**2. Import libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nsns.set(style=\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Import dataset **"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"data = '/kaggle/input/income-classification/income_evaluation.csv'\n\ndf = pd.read_csv(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Exploratory data analysis **\n\nNow, I will explore the data to gain insights about the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the shape\nprint('The shape of the dataset : ', df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are 32561 instances and 15 attributes in the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Rename column names **\n\nWe can see that the dataset does not have proper column names. The column names contain underscore. We should give proper names to the columns. I will do it as follows:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n\ndf.columns = col_names\n\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Findings**\n    \n*     We can see that the dataset contains 9 character variables and 6 numerical variables.\n*     income is the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The above df.describe() command presents statistical properties in vertical form."},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\n\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Types of variables**\n\n* In this section, I segregate the dataset into categorical and numerical variables.\n\n* There are a mixture of categorical and numerical variables in the dataset.\n \n* Categorical variables have data type object. Numerical variables have data type int64.\n \n* First of all, I will explore categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [var for var in df.columns if df[var].dtype=='O']\n\nprint('There are {} categorical variables\\n'.format(len(categorical)))\n\nprint('The categorical variables are :\\n\\n', categorical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 9 categorical variables in the dataset.\n\n* The categorical variables are given by workclass, education, marital_status, occupation, relationship, race, sex, native_country and income."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[categorical].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now, we will check the frequency distribution of categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"for var in categorical: \n    \n    print(df[var].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Percentage of frequency distribution of values"},{"metadata":{},"cell_type":"markdown","source":"**Explore income target variable**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\n\ndf['income'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that there are no missing values in the income target variable.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# view number of unique values\n\ndf['income'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are 2 unique values in the income variable.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# view the unique values\n\ndf['income'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The two unique values are <=50K and >50K.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# view the frequency distribution of values\n\ndf['income'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view percentage of frequency distribution of values\n\ndf['income'].value_counts()/len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize frequency distribution of income variable\n\nf,ax=plt.subplots(1,2,figsize=(18,8))\n\nax[0] = df['income'].value_counts().plot.pie(explode=[0,0],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Income Share')\n\n\n#f, ax = plt.subplots(figsize=(6, 8))\nax[1] = sns.countplot(x=\"income\", data=df, palette=\"Set1\")\nax[1].set_title(\"Frequency distribution of income variable\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 8))\nax = sns.countplot(x=\"income\", hue=\"sex\", data=df, palette=\"Set1\")\nax.set_title(\"Frequency distribution of income variable wrt sex\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that males make more money than females in both the income categories.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 8))\nax = sns.countplot(x=\"income\", hue=\"race\", data=df, palette=\"Set1\")\nax.set_title(\"Frequency distribution of income variable wrt race\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that whites make more money than non-whites in both the income categories.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of unique labels \n\ndf.workclass.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view frequency distribution of values\n\ndf.workclass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace '?' values in workclass variable with `NaN`\n\ndf['workclass'].replace(' ?', np.NaN, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# again check the frequency distribution of values in workclass variable\n\ndf.workclass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 6))\nax = df.workclass.value_counts().plot(kind=\"bar\", color=\"green\")\nax.set_title(\"Frequency distribution of workclass variable\")\nax.set_xticklabels(df.workclass.value_counts().index, rotation=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are lot more private workers than other category of workers."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(12, 8))\nax = sns.countplot(x=\"workclass\", hue=\"income\", data=df, palette=\"Set1\")\nax.set_title(\"Frequency distribution of workclass variable wrt income\")\nax.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of unique labels\n\ndf.occupation.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view unique labels\n\ndf.occupation.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view frequency distribution of values\n\ndf.occupation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace '?' values in occupation variable with `NaN`\n\ndf['occupation'].replace(' ?', np.NaN, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# again check the frequency distribution of values\n\ndf.occupation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize frequency distribution of `occupation` variable\n\nf, ax = plt.subplots(figsize=(12, 8))\nax = sns.countplot(x=\"occupation\", data=df, palette=\"Set1\")\nax.set_title(\"Frequency distribution of occupation variable\")\nax.set_xticklabels(df.occupation.value_counts().index, rotation=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of unique labels\n\ndf.native_country.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view unique labels \n\ndf.native_country.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check frequency distribution of values\n\ndf.native_country.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace '?' values in native_country variable with `NaN`\n\ndf['native_country'].replace(' ?', np.NaN, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# again check the frequency distribution of values\n\ndf.native_country.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize frequency distribution of `native_country` variable\n\nf, ax = plt.subplots(figsize=(16, 12))\nax = sns.countplot(x=\"native_country\", data=df, palette=\"Set1\")\nax.set_title(\"Frequency distribution of native_country variable\")\nax.set_xticklabels(df.native_country.value_counts().index, rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[categorical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for cardinality in categorical variables\n\nfor var in categorical:\n    \n    print(var, ' contains ', len(df[var].unique()), ' labels')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that native_country column contains relatively large number of labels as compared to other columns. I will check for cardinality after train-test split.**"},{"metadata":{},"cell_type":"markdown","source":"**Find numerical variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = [var for var in df.columns if df[var].dtype!='O']\n\nprint('There are {} numerical variables\\n'.format(len(numerical)))\n\nprint('The numerical variables are :\\n\\n', numerical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[numerical].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[numerical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that there are no missing values in the numerical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10,8))\nx = df['age']\nax = sns.distplot(x, bins=10, color='blue')\nax.set_title(\"Distribution of age variable\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Explore relationship between age and income variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 8))\nax = sns.boxplot(x=\"income\", y=\"age\", data=df)\nax.set_title(\"Visualize income wrt age variable\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As expected, younger people make less money as compared to senior people."},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot correlation heatmap to find out correlations\n\ndf.corr().style.format(\"{:.4}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that there is no strong correlation between variables.**"},{"metadata":{},"cell_type":"markdown","source":"****Declare feature vector and target variable****"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['income'], axis=1)\n\ny = df['income']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split data into separate training and test set **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scikit-Learn (sklearn) → Commonly used open source machine learning library**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the shape of X_train and X_test\n\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n** I will do feature engineering on different variables. **\n\n** First, I will show the categorical and numerical variables separately in the training set. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n\ncategorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n\nnumerical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print percentage of missing values in the categorical variables in training set\n\nX_train[categorical].isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print categorical variables with missing data\n\nfor col in categorical:\n    if X_train[col].isnull().mean()>0:\n        print(col, (X_train[col].isnull().mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df2 in [X_train, X_test]:\n    df2['workclass'].fillna(X_train['workclass'].mode()[0], inplace=True)\n    df2['occupation'].fillna(X_train['occupation'].mode()[0], inplace=True)\n    df2['native_country'].fillna(X_train['native_country'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in categorical variables in X_train\n\nX_train[categorical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in categorical variables in X_test\n\nX_test[categorical].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As a final check, I will check for missing values in X_train and X_test.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in X_train\n\nX_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values in X_test\n\nX_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that there are no missing values in X_train and X_test.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preview categorical variables in X_train\n\nX_train[categorical].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import category encoders\n\nimport category_encoders as ce","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One Hot Encoding means that categorical variables are represented as binary.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode categorical variables with one-hot encoding\n\nencoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship', \n                                 'race', 'sex', 'native_country'])\n\nX_train = encoder.fit_transform(X_train)\n\nX_test = encoder.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Similarly, I will take a look at the X_test set.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = X_train.columns\nfrom sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)\nX_train = pd.DataFrame(X_train, columns=[cols])\nX_test = pd.DataFrame(X_test, columns=[cols])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We now have X_train dataset ready to be fed into the Random Forest classifier.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n# instantiate the classifier \n\nrfc = RandomForestClassifier(random_state=0)\n\n\n\n# fit the model\n\nrfc.fit(X_train, y_train)\n\n\n\n# Predict the Test set results\n\ny_pred = rfc.predict(X_test)\n\n\n\n# Check accuracy score \n\nfrom sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with 10 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate the classifier with n_estimators = 100\n\nrfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)\n\n\n\n# fit the model to the training set\n\nrfc_100.fit(X_train, y_train)\n\n\n\n# Predict on the test set results\n\ny_pred_100 = rfc_100.predict(X_test)\n\n\n\n# Check accuracy score \n\nprint('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** The expected accuracy increases with number of decision-trees in the model. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"logr = LogisticRegression()\nlogr.fit(X_train,y_train)\ny_predict_lr = logr.predict(X_test)\nacc_log = metrics.accuracy_score(y_predict_lr,y_test)\nprint('The accuracy of the Logistic Regression is', acc_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\ny_predict_dt = dt.predict(X_test)\nacc_dt = metrics.accuracy_score(y_predict_dt,y_test)\nprint('The accuracy of the Decision Tree is', acc_dt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv = SVC() #select the algorithm\nsv.fit(X_train,y_train) # we train the algorithm with the training data and the training output\ny_predict_svm = sv.predict(X_test) #now we pass the testing data to the trained algorithm\nacc_svm = metrics.accuracy_score(y_predict_svm,y_test)\nprint('The accuracy of the SVM is:', acc_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the Confusion Matrix and slice it into four pieces\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\n\nprint('Confusion matrix\\n\\n', cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize confusion matrix with seaborn heatmap\n\ncm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}