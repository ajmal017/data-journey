{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Breast cancer detection\n\n* Large images show of tissue slices of patients with breast cancer\n* 80 % of breast cancer is ...\n* Our goal: Given a patient and a patch of a tissue slice predict wheather it contains IDC or not.\n    * 3 possibilities: healthy tissue, IDC, another subtype of breast cancer\n* business case: prediction so far is done manually by pathologists and varies from expert to expert. The goal is to assist with an automatic detection of tumors (not expert dependent). \n\n\n## Table of contents\n\n1. Motivation\n2. Preparation & peek at the data structure\n3. Inductive breast cancer visualisation\n4. Predicting IDC tissue from scratch\n5. Predicting IDC tissue with transfer learning\n6. Error analysis & results\n7. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"# Motivation\n\n# Preparation & peek at the data structure\n\n## Loading packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, CyclicLR\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\nfrom glob import glob\nfrom skimage.io import imread\nfrom os import listdir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"run_training = False\nretrain = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring the data structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"listdir(\"../input/breast-histopathology-images/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, in this folder we should find several images or a further substructure of folders."},{"metadata":{"trusted":true},"cell_type":"code","source":"listdir(\"../input/breast-histopathology-images/IDC_regular_ps50_idx5\")[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ah ok. These are patient ids. For each patient we have an individual subfolder that contains image patches. \n\n### How many patients do we have?"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = \"../input/breast-histopathology-images/IDC_regular_ps50_idx5/\"\nfolder = listdir(base_path)\nlen(folder)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost 280 patients. That's a small number compared to the expected number of patients one would like to analyse with our algorithm after deployment. **Consequently overfitting to this specific patient distribution is very likely and we need to take care about the generalization performance of our model**. "},{"metadata":{},"cell_type":"markdown","source":"### How many patches do we have in total?\n\nOur algorithm needs to decide whether an image patch contains IDC or not. Consequently not the whole patient tissue slice but the single patches have to be considered as input to our algorithm. How many of them do we have in total?"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_images = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    for c in [0, 1]:\n        patient_path = base_path + patient_id \n        class_path = patient_path + \"/\" + str(c) + \"/\"\n        subfiles = listdir(class_path)\n        total_images += len(subfiles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, roughly 280000 images. To feed the algorithm with image patches it would be nice to store the path of each image. This way we can load batches of images only one by one without storing the pixel values of all images. "},{"metadata":{},"cell_type":"markdown","source":"### Storing the image_path, patient_id and the target"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n\nk = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    patient_path = base_path + patient_id \n    for c in [0,1]:\n        class_path = patient_path + \"/\" + str(c) + \"/\"\n        subfiles = listdir(class_path)\n        for m in range(len(subfiles)):\n            image_path = subfiles[m]\n            data.iloc[k][\"path\"] = class_path + image_path\n            data.iloc[k][\"target\"] = c\n            data.iloc[k][\"patient_id\"] = patient_id\n            k += 1  \n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, now for each patient we know the path for each patch as well as if it contains IDC or not (the target)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No surprise. This matches the total number of patches. "},{"metadata":{},"cell_type":"markdown","source":"### What do we know about our data?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cancer_perc = data.groupby(\"patient_id\").target.value_counts()/ data.groupby(\"patient_id\").target.size()\ncancer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.distplot(data.groupby(\"patient_id\").size(), ax=ax[0], color=\"Orange\", kde=False, bins=30)\nax[0].set_xlabel(\"Number of patches\")\nax[0].set_ylabel(\"Frequency\");\nax[0].set_title(\"How many patches do we have per patient?\");\nsns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"Tomato\", kde=False, bins=30)\nax[1].set_title(\"How much percentage of an image is covered by IDC?\")\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"% of patches with IDC\");\nsns.countplot(data.target, palette=\"Set2\", ax=ax[2]);\nax[2].set_xlabel(\"no(0) versus yes(1)\")\nax[2].set_title(\"How many patches show IDC?\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights\n\n1. The number of image patches per patient varies a lot! **This leads to the questions whether all images show the same resolution of tissue cells of if this varies between patients**. \n2. Some patients have more than 80 % patches that show IDC! Consequently the tissue is full of cancer or only a part of the breast was covered by the tissue slice that is focused on the IDC cancer. **Does a tissue slice per patient cover the whole region of interest?**\n3. The **classes of IDC versus no IDC are imbalanced**. We have to check this again after setting up a validation strategy and find a strategy to deal with class weights (if we like to apply them)."},{"metadata":{},"cell_type":"markdown","source":"## Visualising the breast tissue\n\nThis part is a bit tricky! We have to extract all coordinates of image patches that are stored in the image names. Then we can use the coordinates to reconstruct the whole breast tissue of a patient. This way we can also explore how diseased tissue looks like compared to healthy ones. To simplify this task let's write a method that takes a patient and outcomes a dataframe with coordinates and targets."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cancer_dataframe(patient_id, cancer_id):\n    path = base_path + patient_id + \"/\" + cancer_id\n    files = listdir(path)\n    dataframe = pd.DataFrame(files, columns=[\"filename\"])\n    path_names = path + \"/\" + dataframe.filename.values\n    dataframe = dataframe.filename.str.rsplit(\"_\", n=4, expand=True)\n    dataframe.loc[:, \"target\"] = np.int(cancer_id)\n    dataframe.loc[:, \"path\"] = path_names\n    dataframe = dataframe.drop([0, 1, 4], axis=1)\n    dataframe = dataframe.rename({2: \"x\", 3: \"y\"}, axis=1)\n    dataframe.loc[:, \"x\"] = dataframe.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    dataframe.loc[:, \"y\"] = dataframe.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    return dataframe\n\ndef get_patient_dataframe(patient_id):\n    df_0 = get_cancer_dataframe(patient_id, \"0\")\n    df_1 = get_cancer_dataframe(patient_id, \"1\")\n    patient_df = df_0.append(df_1)\n    return patient_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example = get_patient_dataframe(data.patient_id.values[0])\nexample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Binary cancer visualisation\n\nBefore we will take a look at the whole tissue let's keep it a bit simpler by looking at the target structure in the x-y-space for a handful of patients:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5,3,figsize=(20, 25))\n\npatient_ids = data.patient_id.unique()\n\nfor n in range(5):\n    for m in range(3):\n        patient_id = patient_ids[m + 3*n]\n        example = get_patient_dataframe(patient_id)\n        ax[n,m].scatter(example.x.values, example.y.values, c=example.target.values, cmap=\"coolwarm\", s=20);\n        ax[n,m].set_title(\"patient \" + patient_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights\n\n* Sometimes we don't have the full tissue information. It seems that tissue patches have been discarded or lost during preparation. \n* Reading the paper (link!) that seems to be related to this data this could also be part of the preprocessing."},{"metadata":{},"cell_type":"markdown","source":"### Visualising the whole breast tissue\n\nOk, now it's time to go one step deeper with our EDA. Given the coordinates of image patches we could try to reconstruct the whole tissue image (not only the targets). "},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualise_breast_tissue(patient_id):\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example = \"14305\"\n\nexample_df = get_patient_dataframe(example)\nmax_point = [example_df.y.max()-1, example_df.x.max()-1]\ngrid = 255*np.ones(shape = (max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\nmask = 255*np.ones(shape = (max_point[0] + 50, max_point[1] + 50, 3)).astype(np.uint8)\n\nbroken_patches = []\nfor n in range(len(example_df)):\n    try:\n        image = imread(example_df.path.values[n])\n\n        x_start = example_df.x.values[n] - 1\n        y_start = example_df.y.values[n] - 1\n        x_end = x_start + 50\n        y_end = y_start + 50\n\n        grid[y_start:y_end, x_start:x_end] = image\n     \n        #mask[y_start:y_end, x_start:x_end] = np.ones(shape=(50,50,3))\n    except ValueError:\n        broken_patches.append(example_df.path.values[n])\n\nplt.figure(figsize=(20,20))\nplt.imshow(grid, cmap=\"Blues\", vmin=150, alpha=0.8)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"broken_patches","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting cancer patches"},{"metadata":{},"cell_type":"markdown","source":"### Validation strategy\n\nLet's start very simple by selecting 40 % of the patients as test data and the remaining 60 % for training and developing. This seems arbitrary and we should rethink this strategy in the next cycle of our datascience workflow. A better idea could be to cluster patients with dependence on the size of the tumor, the number of total patches and statistical quantities of area coverd by the patches. The reason behind that is that we would like to have test patients that cover a broad range of possible variations. Only then we can measure something like a generalisation performance.     "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\ndata.loc[:, \"target\"] = data.target.astype(np.str)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patients = data.patient_id.unique()\n\ntrain_ids, sub_test_ids = train_test_split(patients,\n                                           test_size=0.3,\n                                           random_state=0)\ntest_ids, dev_ids = train_test_split(sub_test_ids, test_size=0.5, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_ids), len(dev_ids), len(test_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = data.loc[data.patient_id.isin(train_ids),:].copy()\ntest_df = data.loc[data.patient_id.isin(test_ids),:].copy()\ndev_df = data.loc[data.patient_id.isin(dev_ids),:].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(train_df.target, ax=ax[0])\nsns.countplot(dev_df.target, ax=ax[1])\nsns.countplot(test_df.target, ax=ax[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = compute_class_weight(class_weight=\"balanced\",\n                                     y=train_df.target.astype(np.int),\n                                     classes=[0,1])\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BreastCancerDataset(Dataset):\n    \n    def __init__(self, root_dir, df, transform=None):\n        self.root_dir = root_dir\n        self.states = df\n        self.transform=transform\n      \n    def __len__(self):\n        return len(self.states)\n        \n    def __getitem__(self, idx):\n        image_path = self.root_dir + self.states.species.values[idx] + \"/\" \n        image_path += self.states.image_name.values[idx]\n        image = Image.open(image_path)\n        image = image.convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n         \n        target = self.states.target.values[idx]\n        return {\"image\": image, \"label\": target}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = BreastCancerDataset(base_path, train_df, transform=my_transform(key=\"train\"))\ndev_dataset = BreastCancerDataset(base_path, dev_df, transform=my_transform(key=\"val\"))\ntest_dataset = BreastCancerDataset(base_path, test_df, transform=my_transform(key=\"val\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Loader"},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\n\ndef recall(y_true, y_pred):\n    \"\"\"Recall metric.\n    Only computes a batch-wise average of recall.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n    Only computes a batch-wise average of precision.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n\ndef fbeta_score(y_true, y_pred, beta=1):\n    \"\"\"Computes the F score.\n    The F score is the weighted harmonic mean of precision and recall.\n    Here it is only computed as a batch-wise average, not globally.\n    This is useful for multi-label classification, where input samples can be\n    classified as sets of labels. By only using accuracy (precision) a model\n    would achieve a perfect score by simply assigning every class to every\n    input. In order to avoid this, a metric should penalize incorrect class\n    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n    computes this, as a weighted mean of the proportion of correct class\n    assignments vs. the proportion of incorrect class assignments.\n    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n    correct classes becomes more important, and with beta > 1 the metric is\n    instead weighted towards penalizing incorrect class assignments.\n    \"\"\"\n    if beta < 0:\n        raise ValueError('The lowest choosable beta is zero (only precision).')\n\n    # If there are no true positives, fix the F score at 0 like sklearn.\n    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n        return 0\n\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    bb = beta ** 2\n    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n    return fbeta_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Explaining predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results & error analysis "},{"metadata":{},"cell_type":"markdown","source":"## Conclusion"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}