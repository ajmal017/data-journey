{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.compose import make_column_transformer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom fancyimpute import IterativeImputer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Lets start-off by loading data\ntrain = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting Started\n\nFor future processings, I will concatinate two sets together. So that training set and test set will have the same number of features in the same format. This will provide great ease to process when the models are being implemented. \n\nIn order to preserve the boarderline between training set and test set, I am recording the initial number of rows each has. Although the number of columns and the data wihtin those columns will change in future, number of rows will remain in tact. "},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train = train.shape[0]\nn_test = test.shape[0]\n\ntest_id = test[\"Id\"]\n\ntrain.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)\n\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n   ## 1. Missing Data"},{"metadata":{},"cell_type":"markdown","source":"As a first step, I would like to get a look at the data, explore the data types in each columns and missing values. \n\nShowing the ratio between missing values and total values in given column will help me get an understanding on the severity of missing values. \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"AllData\")\n(all_data_rows, all_data_columns) = all_data.shape\nprint(\" Number of rows: {} \\n Number of columns: {}\".format(all_data_rows, all_data_columns))\nprint(train.sample(3))\n\ndef display_missing(df):\n    for col in df.columns.tolist():\n        print(\"{} column missing values: {} / {}\".format(col, df[col].isnull().sum(),df.shape[0]))\n\ndisplay_missing(all_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above analysis provided info about missing values, now we can make an intiution on what is our threshold going to be for missing values. \n\nThe columns with missing values surpassing the threshold will be dropped.  "},{"metadata":{},"cell_type":"markdown","source":"From intuition, 20% is a good threshold for now. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def filterProblematicColumns(df,threshold):\n    listOfColumnNames = []\n    for col in df.columns.tolist():\n        if df[col].isnull().sum()> threshold:\n            listOfColumnNames.append(col)\n            print(col)\n    \n    return listOfColumnNames\n\nportion = 0.2\nthreshold = all_data.shape[0] * portion\n\n\ncolumnsToDrop = filterProblematicColumns(all_data, threshold)\n\nall_data = all_data.drop(columns=columnsToDrop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that problematic values dropped, we can work on filling missing values that lie below the threshold.\n\nWe can start our work by analyzing the remaining columns with missing values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_with_missing_values = all_data.loc[:, all_data.isnull().any()]\nmissing_columns = columns_with_missing_values.columns.tolist()\n\nprint(\"Columns with Missing Values: \",\"\\n\", \"\\n\", missing_columns, \"\\n\")\nprint(columns_with_missing_values.describe())\nprint(all_data.shape)\nprint(\"\\n\", \"--------------\", \"\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There are several approaches for handling missing data. \n\nThe standard approach is to fill missing values with basic statistical approach. This corresponds to analyzing the range, deviation and mean of the data. If standard deviation is high and range of data is wide, choose median to reduce the impact of outliers and if the deviation is low, choose to work with mean value to fill missing values. \n\nIn this project, I would like to work with more advanced techniques of imputation. Advanced imputation techniques encapsulates, using KNN or Multiple Imputation by Chained Equations(MICE) to impute missing values. \n\nSince MICE is more time efficient than KNN imputation, I would like to work with that in this exercise. You can use the link below to look for different imputation techniques. \n\n- This is the link: (https://medium.com/ibm-data-science-experience/missing-data-conundrum-exploration-and-imputation-techniques-9f40abe0fd87)\n"},{"metadata":{},"cell_type":"markdown","source":"Checking for correlation with a heatmap is a good idea to visualize relationships. Unfortunately, here there are two drawbacks. \n\n    1. There are too many features to get a sense of just by looking at correlation values or at a heatmap\n    \n    2. There are non-numeric columns within the dataset. Correlations only work between numeric data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"numcols = all_data.select_dtypes(include = np.number).columns\n\n#Lets start by plotting a heatmap to determine if any variables are correlated\nplt.figure(figsize = (12,8))\nsns.heatmap(data= all_data[numcols].corr())\nplt.show()\nplt.gcf().clear()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def corr_missing_values(df, columns): \n    for column in columns:\n        df_corr = df.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n        df_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n        print(df_corr[df_corr['Feature 1'] == column])\n        print(\"\")\n\ncorr_missing_values(all_data, [x for x in missing_columns if x in numcols])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.Encoding values"},{"metadata":{},"cell_type":"markdown","source":"There are two reasons for encoding non-numeric values: \n\n    1- We have decided to deal with missing values using MICE. MICE can only fill missing values if other values are numeric. The regression can only be implemented for imputation, if the values are numbers. \n    \n    2- The predictive models will be requiring numeric values for the modeling process. \n    \n\nThere are different consideration for encoding values. Ordinal values are values given in some sort of order in relation with eachother. Nominal values are values where such ordering does not exist. \n\nFor ordinal values, I will be using OrdinalEncoder and for nominal values, I will be using dummies to encode. "},{"metadata":{},"cell_type":"markdown","source":"   ### 2a. Ordinal Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\nnumeric_columns = all_data.select_dtypes(include = np.number).columns.tolist()\nnominal_columns = [\"MSZoning\",\"Street\",\"LandContour\",\"LotConfig\",\"Neighborhood\",\"Condition1\",\"Condition2\",\"BldgType\",\"HouseStyle\",\"RoofStyle\",\"RoofMatl\",\"Exterior1st\",\"Exterior2nd\",\"MasVnrType\",\"Foundation\",\"Heating\",\"CentralAir\",\"Electrical\",\"GarageType\",\"SaleCondition\"]\nordinal_columns = [\"LotShape\",\"Utilities\",\"LandSlope\",\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"HeatingQC\",\"KitchenQual\",\"Functional\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\"PavedDrive\",\"SaleType\"]\n\n#Check if numbers match, to make sure no columns are left out\nprint(all_data.shape[1])\nprint(len(numeric_columns), len(nominal_columns), len(ordinal_columns))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While encoding, it is vital that we skip missing values. Because ordinal encoder does not work with missing values. We will impute those missing values, once everydata is turned into numeric. Then MICE will handle the missing values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"##Â Ordinal Encoding (by skipping null values)\n\nordinal_enc_dict = {}\nfor col_name in ordinal_columns:\n    ordinal_enc_dict[col_name] = OrdinalEncoder()\n\n    col = all_data[col_name]\n    col_not_null = col[col.notnull()]\n    reshaped_vals = col_not_null.values.reshape(-1,1)\n\n    encoded_vals = ordinal_enc_dict[col_name].fit_transform(reshaped_vals)\n    all_data.loc[col.notnull(), col_name] = np.squeeze(encoded_vals)\n\n#Check if the values are encoded and no column has been skipped.   \nprint(all_data[ordinal_columns].head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###   2b. Nominal Values"},{"metadata":{},"cell_type":"markdown","source":"I have find hard time to find solution to encode nominal values with missing data. I am open to suggestions here. Please comment below if you have any advice. \n\nSince dummies do not work with missing values. I choosed a more standard approach to continue. I have investigated nominal columns with missing data. I have discovered the amount of missing data is relatively low. I have choosed to fill those missing values on the basis of occurence. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(display_missing(all_data[nominal_columns]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Imputation with mode\nnom_cols_withnull = all_data[nominal_columns].columns[all_data[nominal_columns].isnull().any()].tolist()\n\nmost_common_imputed = all_data[nom_cols_withnull].apply(lambda x: x.fillna(x.value_counts().index[0]))\n\nfor col_name in most_common_imputed.columns:\n    all_data[col_name] = most_common_imputed[col_name]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Encoding nominal values using dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"nom_df = pd.get_dummies(all_data[nominal_columns], prefix=nominal_columns)\n\nfor col_name in nom_df.columns:\n    all_data[col_name] = nom_df[col_name]\n\nall_data = all_data.drop(columns= nominal_columns)\n\nprint(all_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Imputation with MICE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fancyimpute import IterativeImputer\n\n\nMICE_imputer = IterativeImputer()\nordinal_mice = all_data.copy(deep = True)\n\nordinal_mice.iloc[:,:] = np.round(MICE_imputer.fit_transform(ordinal_mice))\n\nfor col_name in ordinal_columns:\n    all_data[col_name] = ordinal_mice[col_name]\n\nfor col_name in numeric_columns:\n    all_data[col_name] = ordinal_mice[col_name]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if all_data.isnull().values.any():\n    print(\"Yuh artÄ±k!\")\n    print(\"GOSHHH!!!!!\")\n    print(\"Breakdown loading...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Splitting the Concatinated DataSet and Feature Scaling"},{"metadata":{},"cell_type":"markdown","source":"After all the processes, we can divide the training and test set from each other for model testing. \n\nFeature Scaling is a crutial step here to regularize the weight of each parameter to the outcome. Otherwise, values with greater magnitude will overweight in the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\n\ny = train[\"SalePrice\"]\nX = all_data.loc[:n_train-1,:]\ntest = all_data.loc[n_train:,:]\n\n\nX.iloc[:,:] = scaler.fit_transform(X.loc[:,:])\ntest.iloc[:,:] = scaler.fit_transform(test.loc[:,:])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size=0.20, random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Hyperparameter tuning and GridSearchCV"},{"metadata":{},"cell_type":"markdown","source":"In hyperparameter tuning, the main purpose is to find parameters that give out best predictions for validation set. This way, we avoid overfitting and get more generalized result for real tests. \n\nGridSearchCV is a decent tool to try different parameters while crossvalidating trials on the test set\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge, Lasso, LinearRegression\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\n\n\n\n# create and fit a ridge regression model, testing each alpha\nridge = Ridge()\nlasso = Lasso()\nlr = LinearRegression()\n\nkernel_ridge = KernelRidge()\n\nparam_grid_kr = {'alpha': [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              'kernel':['polynomial'], \n              'degree':[2,3,4,5,6,7,8],\n              'coef0':[0,1,1.5,2,2.5,3,3.5,10]}\n### \n#kernel_ridge = GridSearchCV(kernel_ridge, \n #                param_grid = param_grid_kr, \n  #               scoring = \"neg_mean_squared_error\", \n   #             cv = 5,\n    #             n_jobs = -1,\n     #            verbose = 1)\n\n#kernel_ridge.fit(X,y)\n#print(pd.DataFrame(kernel_ridge.cv_results_))\n#k_best = kernel_ridge.best_estimator_\n#kernel_ridge.best_score_\n\nparam_grid = {\"alpha\": [0.001,0.003,0.01,0.3,0.1,0.3,1,3,10,30,100,300,1000,3000,100000]}\n\nprint(\"-----------Stats for Ridge-----------------\", \"\\n\")\ngrid_ridge = GridSearchCV(ridge, param_grid = param_grid, cv = 10, scoring = \"neg_mean_squared_error\", n_jobs=-1) \ngrid_ridge.fit(X, y)\nprint(pd.DataFrame(grid_ridge.cv_results_))\n\nprint(\"-----------Stats for Lasso-----------------\", \"\\n\")\ngrid_lasso = GridSearchCV(lasso, param_grid = param_grid, cv = 10, scoring = \"neg_mean_squared_error\", n_jobs=-1) \ngrid_lasso.fit(X_train, y_train)\nprint(pd.DataFrame(grid_lasso.cv_results_))\n\n#print(kernel_ridge.best_score_)\n#print(kernel_ridge.best_estimator_.alpha)\n\nprint(\"-----------Scoreboard for Ridge-----------------\", \"\\n\")\nprint(grid_ridge.best_score_)\nprint(grid_ridge.best_estimator_.alpha)\n\nprint(\"-----------Scoreboard for Lasso-----------------\", \"\\n\")\n\nprint(grid_lasso.best_score_)\nprint(grid_lasso.best_estimator_.alpha)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ridge = Ridge(alpha = 300)\ntest_ridge.fit(X,y)\npredictions = test_ridge.predict(test)\n\n\n#output = pd.DataFrame({'Id': test_id, 'SalePrice': predictions})\n#output.to_csv('first_draft.csv', index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Please feel free to add comments and give recommendations on the work. I would be happy to improve myself. I hope this will help you! "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}