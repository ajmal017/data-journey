{"cells":[{"metadata":{"_uuid":"1c7b7a7b-d138-4c7a-b7e2-36bcd78b03d6","_cell_guid":"91afaa34-a976-4fdf-bef0-8399ee88738d","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split \nfrom matplotlib import pyplot as plt\nfrom torchvision import transforms\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau,StepLR\nimport csv\nimport time\nimport cv2\n\ntraindata=pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntestdata=pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\n\ntrainset=traindata.drop('label',axis=1)\ntrainlabel=traindata['label']\n\ntestset=testdata.drop('id',axis=1)\n\ntrain_data,validation_data,train_label,validation_label=train_test_split(trainset,trainlabel,test_size=0.01,stratify=trainlabel,random_state=42)\n\ntrain_data=train_data.to_numpy().astype(np.float32).reshape(len(train_data),28,28,1)\ntrain_label=torch.from_numpy(train_label.to_numpy())\nvalidation_data=validation_data.to_numpy().astype(np.float32).reshape(len(validation_data),28,28,1)\nvalidation_label=torch.from_numpy(validation_label.to_numpy())\ntest_data=testset.to_numpy().reshape(len(testset),28,28,1)\n\nnew_train_data=train_data[0][np.newaxis,:]\nnew_train_label=np.array([train_label[0]])\n\ndef imgtrans(im,datagroup,labelgroup,imglabel):\n    global j\n    img1=cv2.warpAffine(im,rot_mat1,(28,28),flags=cv2.INTER_LINEAR)[np.newaxis,:,:,np.newaxis]\n    img3=cv2.warpAffine(im,scale_mat1,(28,28),flags=cv2.INTER_LINEAR)[np.newaxis,:,:,np.newaxis]\n    img5=cv2.warpAffine(im,shift_mat1,(28,28),flags=cv2.INTER_LINEAR)[np.newaxis,:,:,np.newaxis]\n    img2=cv2.warpAffine(im,rot_mat2,(28,28),flags=cv2.INTER_LINEAR)[np.newaxis,:,:,np.newaxis]\n    img4=cv2.warpAffine(im,scale_mat2,(28,28),flags=cv2.INTER_LINEAR)[np.newaxis,:,:,np.newaxis]\n    img6=cv2.warpAffine(im,shift_mat2,(28,28),flags=cv2.INTER_LINEAR)[np.newaxis,:,:,np.newaxis]\n    im=im[np.newaxis,:,:,np.newaxis]\n    #data=np.concatenate((datagroup[j],im,img1),axis=0)\n    #label=np.concatenate((labelgroup[j],np.array([imglabel]),np.array([imglabel])),axis=0)\n    data=np.concatenate((datagroup[j],im,img1,img2,img3,img4,img5,img6),axis=0)\n    label=np.concatenate((labelgroup[j],np.array([imglabel]),np.array([imglabel]),np.array([imglabel]),np.array([imglabel]),np.array([imglabel]),np.array([imglabel]),np.array([imglabel])),axis=0)\n    datagroup[j]=data\n    labelgroup[j]=label\n    \n#start=time.time()\nrot_mat1=cv2.getRotationMatrix2D((14,14),10,1)     #旋转\nrot_mat2=cv2.getRotationMatrix2D((14,14),-10,1)\nscale_mat1=cv2.getRotationMatrix2D((14,14),0,1.1)  #缩放\nscale_mat2=cv2.getRotationMatrix2D((14,14),0,0.9)\nshift_mat1= np.float32([[1,0,3],[0,1,3]])                                  #平移\nshift_mat2 = np.float32([[1,0,-3],[0,1,-3]])\nj=0\ndatadict={}\nfor i in range(13):\n    datadict[i]=new_train_data\nlabeldict={}\nfor i in range(13):\n    labeldict[i]=new_train_label\nstart=time.time()\nfor i in range(len(train_data)):\n    img=train_data[i,:,:,0]\n    imgtrans(img,datadict,labeldict,train_label[i])\n    if i%5000==0:\n        print(datadict[j].shape,labeldict[j].shape,time.time()-start)\n        start=time.time()\n        j+=1\n        \nfor i in range(13):\n    new_train_data=np.concatenate((new_train_data,datadict[i]),axis=0)\n    new_train_label=np.concatenate((new_train_label,labeldict[i]),axis=0)\n    \nnew_train_data=new_train_data[1:,:,:,:]\nnew_train_label=new_train_label[1:]\n\ntrain_data=new_train_data\ntrain_label=torch.from_numpy(new_train_label)\n\nnew_train_data=np.concatenate((train_data,test_data),axis=0)\nprint(new_train_data.shape)\n\n#fig,axes=plt.subplots(10,10,figsize=(10,10))\n#for i in range(10):\n#    for j in range(10):\n#        axes[i][j].axis('off')\n#        axes[i][j].imshow(train_data[i*10+j,:,:,0])\n#fig.suptitle('train_data')\n\n#fig2,axes2=plt.subplots(10,10,figsize=(10,10))\n#for i in range(10):\n#    for j in range(10):\n#        axes2[i][j].axis('off')\n#        axes2[i][j].imshow(test_data[i*10+j,:,:,0])\n#fig2.suptitle('test_data')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89df2c66-405d-4d8b-b892-f6c9718206a6","_cell_guid":"d41dad96-72f7-49ea-8353-b6edf4d55fee","trusted":true},"cell_type":"code","source":"\nclass mydataset(torch.utils.data.Dataset):\n    def __init__(self,data,label=None):\n        self.data=data\n        self.label=label\n        \n    def __getitem__(self,index):\n        img=self.data[index]\n        img=transforms.ToTensor()(img)\n        if self.label is not None:\n            label=self.label[index]\n            return img,label            #train.val\n        else:\n            return img                  #test\n    \n    def __len__(self):\n        return len(self.data)\ntrainset=mydataset(train_data,train_label)\ntrain_loader=torch.utils.data.DataLoader(trainset,batch_size=1024,shuffle=True)\nvalset=mydataset(validation_data,validation_label)\nval_loader=torch.utils.data.DataLoader(valset,batch_size=64,shuffle=False)\ntestset=mydataset(test_data)\ntest_loader=torch.utils.data.DataLoader(testset,batch_size=64,shuffle=False)\nprint(len(train_loader))\nprint(len(val_loader))\nprint(len(test_loader))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b82edf0a-405a-461e-9948-636814c29fdf","_cell_guid":"a14cc1f8-abce-4203-b7f4-7e70c1bd3b95","trusted":true},"cell_type":"code","source":"class maxout(nn.Module):\n            def __init__(self):\n                super(maxout,self).__init__()\n                \n            def forward(self,input):\n                x1,x2=torch.chunk(input,2,1)\n                output=torch.nn.functional.relu(x2-x1)+x1\n                return output\n            \nclass lenet(nn.Module):\n        def __init__(self):\n            super(lenet,self).__init__()\n            self.features=nn.Sequential(\n                nn.Conv2d(1,64,3),         #26\n                nn.BatchNorm2d(64),\n                nn.LeakyReLU(0.1),\n                nn.Conv2d(64,64,3),        #24\n                nn.BatchNorm2d(64),\n                nn.LeakyReLU(0.1),\n                nn.Conv2d(64,128,3),        #22\n                nn.BatchNorm2d(128),\n                nn.LeakyReLU(0.1),\n                nn.Conv2d(128,128,3),        #20\n                nn.BatchNorm2d(128),\n                nn.LeakyReLU(0.1),\n                nn.MaxPool2d(2,2),         #10\n                nn.Dropout(p=0.2),\n                nn.Conv2d(128,256,3),        #8\n                nn.BatchNorm2d(256),\n                nn.LeakyReLU(0.1),\n                nn.Conv2d(256,256,3),        #6\n                nn.BatchNorm2d(256),\n                nn.LeakyReLU(0.1),\n                nn.MaxPool2d(2,2),         #3\n                nn.Dropout(p=0.2),\n            )\n            \n            self.classify=nn.Sequential(\n                nn.Linear(2304,512),\n                nn.BatchNorm1d(512),\n                nn.LeakyReLU(0.1),\n                nn.Linear(512,10),\n            )\n        def forward(self,input):\n            x=self.features(input)\n            x=x.view(x.size(0),-1)\n            x=self.classify(x)\n            return x\nLenet=lenet()\nLenet.to('cuda')\nprint('building model......')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fdf1b0e-bfe8-4642-8432-caf06258fcba","_cell_guid":"ac5d0917-f6e1-45d0-9d5f-d53e6760e605","trusted":true},"cell_type":"code","source":"print('train......')\nepoch=25\ncriterion=nn.CrossEntropyLoss()\noptimizer=torch.optim.SGD(Lenet.parameters(),lr=0.001,momentum=0.99,weight_decay=0.001)\n#lr_scheduler=ReduceLROnPlateau(optimizer,factor=0.5,patience=4)\nlr_scheduler=StepLR(optimizer,step_size=5,gamma=0.5)\n\n#train\nstart=time.time()\nfor i in range(epoch):\n    Lenet.train()\n    loss_total=0\n    \n    for idx,(img,label) in enumerate(train_loader):\n            img=img.to('cuda')\n            label=label.to('cuda')\n            output=Lenet(img)\n            loss=criterion(output,label)\n            loss_total+=loss.item()\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            if idx%100==0:\n                    print('epoch:{} , {}/{} , loss:{:.6f}  {:.6f} , lr={}'.format(i,idx,len(train_loader),loss_total/(idx+1),loss.item(),optimizer.param_groups[0]['lr']))\n    lr_scheduler.step()\nprint('time: {} s'.format(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"815f05c6-ea7f-4d32-8f53-8b751d5bf977","_cell_guid":"412d5043-4a76-4c4e-a5ac-688a27875f29","trusted":true},"cell_type":"code","source":"#validation\nprint('validate......')\nwith torch.no_grad():\n    Lenet.eval()\n    correct=0\n    total=600\n    for idx,(img,label) in enumerate(val_loader):\n            img=img.to('cuda')\n            label=label.to('cuda')\n            output=Lenet(img)\n            prediction=torch.max(output,dim=1)[1]\n            correct+=sum(prediction==label).item()\n    print('val accuracy:{:.6f}'.format(correct/total))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fde06b5-1703-4709-bf47-d4043e57ae89","_cell_guid":"0602a0bb-c40a-40c8-b5a1-d31b6e52de2c","trusted":true},"cell_type":"code","source":"#pseudo label\nprint('pseudo label data......')\nnew_train_label=train_label.to('cuda')\n\nwith torch.no_grad():\n    Lenet.eval()\n    for idx,img in enumerate(test_loader):\n        img=img.to('cuda')\n        img=img.float()\n        output=Lenet(img)\n        _,predictions=torch.max(output,1)\n        new_train_label=torch.cat((new_train_label,predictions),dim=0)\nprint(new_train_data.shape)\nprint(new_train_label.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c3b4db1-e687-4650-9afe-f6132c93c754","_cell_guid":"c00a2fab-8752-4d26-8590-853c84ffd782","trusted":true},"cell_type":"code","source":"#retrain\nprint('retrain with pseudo label......')\nnew_trainset=mydataset(new_train_data,new_train_label)\nnew_train_loader=torch.utils.data.DataLoader(new_trainset,batch_size=1024,shuffle=True)\n\nepoch=30\noptimizer=torch.optim.Adam(Lenet.parameters(),lr=0.001,weight_decay=0.001)\n#optimizer=torch.optim.SGD(Lenet.parameters(),lr=0.001,momentum=0.9,weight_decay=0.001)\nlr_scheduler=ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=2)\n#lr_scheduler=StepLR(optimizer,step_size=5,gamma=0.5)\n\n#train\nbestnet=None\nbestloss=1\nstart=time.time()\nfor i in range(epoch):\n    Lenet.train()\n    loss_total=0\n    \n    for idx,(img,label) in enumerate(new_train_loader):\n            img=img.to('cuda')\n            label=label.to('cuda')\n            img=img.float()\n            output=Lenet(img)\n            loss=criterion(output,label)\n            loss_total+=loss.item()\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            if idx%100==0:\n                    print('epoch:{} , {}/{} , loss:{:.6f}  {:.6f} , lr={}'.format(i,idx,len(train_loader),loss_total/(idx+1),loss.item(),optimizer.param_groups[0]['lr']))\n            if loss.item()<bestloss:\n                bestloss=loss.item()\n                bestnet=Lenet\n    lr_scheduler.step(loss_total/len(new_train_loader))\nprint('time: {} s'.format(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf56861f-6e93-46af-b561-a18da349bd4e","_cell_guid":"b628b1d6-4e77-4acb-908d-486763e6a451","trusted":true},"cell_type":"code","source":"#validation\nprint('validate......')\nwith torch.no_grad():\n    Lenet.eval()\n    correct=0\n    total=600\n    for idx,(img,label) in enumerate(val_loader):\n            img=img.to('cuda')\n            label=label.to('cuda')\n            output=Lenet(img)\n            prediction=torch.max(output,dim=1)[1]\n            correct+=sum(prediction==label).item()\n    print('val accuracy:{:.6f}'.format(correct/total))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81f586f0-275b-4605-953f-9dfbe1049c73","_cell_guid":"d77ca725-c004-4562-978d-af45e364c73c","trusted":true},"cell_type":"code","source":"#validation\nprint('bestnet validate......')\nwith torch.no_grad():\n    bestnet.eval()\n    correct=0\n    total=600\n    for idx,(img,label) in enumerate(val_loader):\n            img=img.to('cuda')\n            label=label.to('cuda')\n            output=bestnet(img)\n            prediction=torch.max(output,dim=1)[1]\n            correct+=sum(prediction==label).item()\n    print('val accuracy:{:.6f}'.format(correct/total))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"925a851e-2d35-4653-8f23-ebcd0182a38a","_cell_guid":"8a189ca6-f48b-4b47-b65e-91d4590e0c21","trusted":true},"cell_type":"code","source":"#test \nprint('test data......')\nsubmission=open('submission.csv','w',newline='')\nsubmission=csv.writer(submission)\nsubmission.writerow(['id','label'])\n\nwith torch.no_grad():\n    bestnet.eval()\n    for idx,img in enumerate(test_loader):\n        img=img.to('cuda')\n        img=img.float()\n        output=bestnet(img)\n        _,predictions=torch.max(output,1)\n        for i in range(len(img)):\n            submission.writerow([idx*64+i,predictions[i].item()])\nprint('finished......')","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}