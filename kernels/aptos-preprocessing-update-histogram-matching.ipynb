{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Various possible Pre-processing options"},{"metadata":{},"cell_type":"markdown","source":"This notebook has been updated with histogram matching technique. In histogram matching/specification an image is transformed such that its histogram matches another specified histogram. In other words, you choose a template image and then you want a source image to look like the template. In this case, I chose a source and a templateby going through a few images. The results are not upto to the mark though."},{"metadata":{},"cell_type":"markdown","source":"This post is to highlight some useful preprocessing steps.\n\n1. Median subtraction\n2. Gamma Correction\n3. Adaptive Histogram Equalization\n4. Contrast Stretching\n5. Histogram Normalization\n6. Histogram Matching/Specification (**UPDATE**)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"List of files in the directory."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(os.listdir('/kaggle/input/aptos2019-blindness-detection/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root = '/kaggle/input/aptos2019-blindness-detection/'\ntrain_df = pd.read_csv(os.path.join(root, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Class label distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Highly skewed distribution of labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(8, 5))\ntrain_df['diagnosis'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Randomly pick 5 images from each of the five labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n\n\n\nSEED = 125\nfig = plt.figure(figsize=(25, 16))\nimg_list = []\nimg_size = []\n# display 10 images from each class\n#for class_id in sorted(train_y.unique()):\nfor class_id in [0, 1, 2, 3, 4]:\n    for i, (idx, row) in enumerate(train_df.loc[train_df['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path = os.path.join(root, 'train_images', '{}.png'.format(row['id_code']))\n        image = cv2.imread(path)\n        img_size.append(image.shape)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        #image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        img_list.append(row['id_code'])\n        \n        plt.imshow(image)\n        ax.set_title('Label: %d ' % (class_id) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some Preprocessing steps"},{"metadata":{},"cell_type":"markdown","source":"## 1. Median subtraction\n\nBorrowed the following from https://www.kaggle.com/joorarkesteijn/fast-cropping-preprocessing-and-augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 256\n\ndef info_image(im):\n    # Compute the center (cx, cy) and radius of the eye\n    cy = im.shape[0]//2\n    midline = im[cy,:]\n    midline = np.where(midline>midline.mean()/3)[0]\n    if len(midline)>im.shape[1]//2:\n        x_start, x_end = np.min(midline), np.max(midline)\n    else: # This actually rarely happens p~1/10000\n        x_start, x_end = im.shape[1]//10, 9*im.shape[1]//10\n    cx = (x_start + x_end)/2\n    r = (x_end - x_start)/2\n    return cx, cy, r\n\ndef resize_image(im, augmentation=False):\n    # Crops, resizes and potentially augments the image to IMAGE_SIZE\n    cx, cy, r = info_image(im)\n    scaling = IMAGE_SIZE/(2*r)\n    rotation = 0\n    if augmentation:\n        scaling *= 1 + 0.3 * (np.random.rand()-0.5)\n        rotation = 360 * np.random.rand()\n    M = cv2.getRotationMatrix2D((cx,cy), rotation, scaling)\n    M[0,2] -= cx - IMAGE_SIZE/2\n    M[1,2] -= cy - IMAGE_SIZE/2\n    return cv2.warpAffine(im,M,(IMAGE_SIZE,IMAGE_SIZE)) # This is the most important line\n\ndef subtract_median_bg_image(im):\n    k = np.max(im.shape)//20*2+1\n    bg = cv2.medianBlur(im, k)\n    return cv2.addWeighted (im, 4, bg, -4, 128)\n\n#def subtract_gaussian_bg_image(im):\n#    k = np.max(im.shape)/10\n#    bg = cv2.GaussianBlur(im ,(0,0) ,k)\n#    return cv2.addWeighted (im, 4, bg, -4, 128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To remove irregularities along the circular boundary of the image\nPARAM = 96\ndef Radius_Reduction(img,PARAM):\n    h,w,c=img.shape\n    Frame=np.zeros((h,w,c),dtype=np.uint8)\n    cv2.circle(Frame,(int(math.floor(w/2)),int(math.floor(h/2))),int(math.floor((h*PARAM)/float(2*100))), (255,255,255), -1)\n    Frame1=cv2.cvtColor(Frame, cv2.COLOR_BGR2GRAY)\n    img1 =cv2.bitwise_and(img,img,mask=Frame1)\n    return img1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Read image"},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[0])))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nfig=plt.figure(figsize=(8, 8))\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Resizing the image"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(8, 8))\nres_image = resize_image(image)\nplt.imshow(res_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Subtracting the median blur image from the original"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(8, 8))\nsub_med = subtract_median_bg_image(res_image)\nplt.imshow(sub_med)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Removing the circular boundary to remove irregularities"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(8, 8))\nimg_rad_red=Radius_Reduction(sub_med, PARAM)\nplt.imshow(img_rad_red)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above collection of pre-processing was done for 5 images belonging to each of the five classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"w=10\nh=10\nfig=plt.figure(figsize=(20, 20))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    #img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[i-1])))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    res_image = resize_image(img)\n    sub_med = subtract_median_bg_image(res_image)\n    img_rad_red=Radius_Reduction(sub_med, PARAM)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img_rad_red)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Gamma Correction\n\nThe Gamma value builds a relation between the pixel value and its actual brightness in an image. Gamma correction is highly used in image editing.\n\nhttps://www.cambridgeincolour.com/tutorials/gamma-correction.htm"},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[0])))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nres_image = resize_image(image)\n\nmatplotlib.rc('figure', figsize=[7, 7])\nplt.imshow(res_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def adjust_gamma(image, gamma):\n    # build a lookup table mapping the pixel values [0, 255] to\n    # their adjusted gamma values\n    invGamma = 1.0 / gamma\n    table = np.array([((i / 255.0) ** invGamma) * 255\n                for i in np.arange(0, 256)]).astype(\"uint8\")\n    \n    # apply gamma correction using the lookup table\n    return cv2.LUT(image, table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A value **< 1.0** will make the image **darker** while values **> 1.0** makes the image **brighter**"},{"metadata":{"trusted":true},"cell_type":"code","source":"adjusted = adjust_gamma(res_image, gamma=0.5)\nadjusted_75 = adjust_gamma(res_image, gamma=0.75)\nadjusted_15 = adjust_gamma(res_image, gamma=1.5)\nadjusted_3 = adjust_gamma(res_image, gamma=2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matplotlib.rc('figure', figsize=[15, 15])\n\nfig, axarr = plt.subplots(2,2)\naxarr[0,0].imshow(adjusted)\naxarr[0,1].imshow(adjusted_75)\naxarr[1,0].imshow(adjusted_15)\naxarr[1,1].imshow(adjusted_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Selective Gamma correction\n\nGet the median of all the pixel values of the grayscaled image within the mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"Parameter = 95\n\ndef Redius_Reduction(img, Parameter):\n    h,w,c=img.shape\n    Frame=np.zeros((h,w,c),dtype=np.uint8)\n    cv2.circle(Frame,(int(math.floor(w/2)),int(math.floor(h/2))),int(math.floor((h*Parameter)/float(2*100))), (255,255,255), -1)\n    Frame1=cv2.cvtColor(Frame, cv2.COLOR_BGR2GRAY)\n    img1 =cv2.bitwise_and(img,img,mask=Frame1)\n    return img1, Frame1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w=10\nh=10\nfig=plt.figure(figsize=(20, 20))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    #img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[i-1])))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    res_image = resize_image(img)\n    #sub_med = subtract_median_bg_image(res_image)\n    img_rad_red, mask = Redius_Reduction(res_image, Parameter)\n    \n    \n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img_rad_red)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nw=10\nh=10\nfig=plt.figure(figsize=(20, 20))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    \n    img = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[i-1])))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    res_image = resize_image(img)\n    \n    \n    \n    img_rad_red, mask = Redius_Reduction(img, Parameter)\n    pixel_list = img_rad_red[:,:,1][np.where(mask == 255)].tolist()\n    \n    print('Median:', np.median(pixel_list))\n    adjusted_img = None\n    \n    if (np.median(pixel_list) < 70):\n        print('Inside')\n        adjusted_img = adjust_gamma(res_image, gamma = 1.65)\n        \n    elif (np.median(pixel_list) > 180):\n        adjusted_img = adjust_gamma(res_image, gamma = 0.75)\n        \n    \n    else:\n        \n        adjusted_img = res_image\n    \n    fig.add_subplot(rows, columns, i)\n    plt.imshow(adjusted_img)\n    \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Adaptive Histogram Equalization\n\nhttps://stackoverflow.com/questions/24341114/simple-illumination-correction-in-images-opencv-c\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----Converting image to LAB Color model----------------------------------- \nlab= cv2.cvtColor(res_image, cv2.COLOR_BGR2LAB)\nmatplotlib.rc('figure', figsize=[7, 7])\nplt.imshow(lab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#-----Splitting the LAB image to different channels-------------------------\nl, a, b = cv2.split(lab)\n#cv2.imshow('l_channel', l)\n#cv2.imshow('a_channel', a)\n#cv2.imshow('b_channel', b)\n\n#-----Applying CLAHE to L-channel-------------------------------------------\nclahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\ncl = clahe.apply(l)\nmatplotlib.rc('figure', figsize=[7, 7])\nplt.imshow(cl)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\nlimg = cv2.merge((cl,a,b))\nmatplotlib.rc('figure', figsize=[7, 7])\nplt.imshow(limg)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----Converting image from LAB Color model to RGB model--------------------\nfinal = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\nmatplotlib.rc('figure', figsize=[7, 7])\nplt.imshow(final)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying the above operations for the list of images."},{"metadata":{"trusted":true},"cell_type":"code","source":"w=10\nh=10\nfig=plt.figure(figsize=(20, 20))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    #img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[i-1])))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    res_image = resize_image(img)\n    lab= cv2.cvtColor(res_image, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    cl = clahe.apply(l)\n    limg = cv2.merge((cl,a,b))\n    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(final)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** `clipLimit` and `tileGridSize` are parameters that can be tweaked"},{"metadata":{},"cell_type":"markdown","source":"## 4. Contrast stretching"},{"metadata":{"trusted":true},"cell_type":"code","source":"def contrast_stretching(img):        \n    rr, gg, bb = cv2.split(img)    \n    imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)    \n    im = imgray    \n    ih, iw = imgray.shape    \n    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(imgray)    \n    for i in range(ih):        \n        for j in range(iw):            \n            im[i, j] = 255 * ((gg[i, j] - minVal) / (maxVal - minVal))        \n    limg = cv2.merge((rr, im, bb))    \n    return limg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contrast_image = contrast_stretching(res_image)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(contrast_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Histogram Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def histogram_normalization(image):    \n    hist,bins = np.histogram(image.flatten(),256,[0,256])    \n    cdf = hist.cumsum()   \n    # cdf_normalized = cdf * hist.max()/ cdf.max()    \n    cdf_m = np.ma.masked_equal(cdf,0)    \n    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())    \n    cdf = np.ma.filled(cdf_m,0).astype('uint8')     \n    img2 = cdf[image]    \n    return img2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_norm_image = histogram_normalization(res_image)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(hist_norm_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Histogram matching (**UPDATE**)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def matching(source,template):    \n    oldshape = source.shape    \n    source1 = source.ravel()    \n    template1 = template.ravel()    \n    s_values, bin_idx, s_counts = np.unique(source1, return_inverse=True,return_counts=True)    \n    t_values, t_counts = np.unique(template1, return_counts=True)    \n    s_quantiles = np.cumsum(s_counts).astype(np.float64)    \n    s_quantiles /= s_quantiles[-1]    \n    t_quantiles = np.cumsum(t_counts).astype(np.float64)    \n    t_quantiles /= t_quantiles[-1]    \n    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)    \n    interp_t_values1=interp_t_values.astype(np.uint8)    \n    sub=interp_t_values-interp_t_values1    \n    interp_t_values1[sub>.5]+=1    \n    match_v1=interp_t_values1[bin_idx].reshape(oldshape).astype(np.uint8)    \n    #match_v2=Radius_Reduction(match_v1, PARAM)    \n    return match_v1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Histo_Specification(source, template):    \n    #source_v5=Ychannel_Stretch(source_v4)    \n    #source_v6 = cv2.resize(source,(IMAGE_SIZE, IMAGE_SIZE)) \n    #template_v6 = cv2.resize(template,(IMAGE_SIZE, IMAGE_SIZE)) \n    source_v6 = resize_image(source)\n    template_v6 = resize_image(template)\n    f=[]    \n    for x in range(0,3):        \n        f.append(matching(source_v6[:,:,x], template_v6[:,:,x]))    \n    img = cv2.merge((f[0],f[1],f[2]))     \n    return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Source image**"},{"metadata":{"trusted":true},"cell_type":"code","source":"source = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[3])))\nsource = cv2.cvtColor(source, cv2.COLOR_BGR2RGB)\n#source = contrast_stretching(source)\n#source = histogram_normalization(source)\nfig=plt.figure(figsize=(5, 5))\nplt.imshow(source)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Template image**"},{"metadata":{"trusted":true},"cell_type":"code","source":"template = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[13])))\ntemplate = cv2.cvtColor(template, cv2.COLOR_BGR2RGB)\nfig=plt.figure(figsize=(5, 5))\nplt.imshow(template)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histo_matched_image = Histo_Specification(source, template)\nfig=plt.figure(figsize=(5, 5))\nplt.imshow(histo_matched_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w=10\nh=10\nfig=plt.figure(figsize=(20, 20))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    #img = np.random.randint(10, size=(h,w))\n    img = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[i-1])))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #res_image = resize_image(img)\n    #sub_med = subtract_median_bg_image(res_image)\n    #img_rad_red=Radius_Reduction(sub_med, PARAM)\n    histo_matched_image = Histo_Specification(img, template)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(histo_matched_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** Clearly some of the images have not been processed as expected. This highly depends on the choice of the template image."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"def Root_Channel_SQUR(crop):    \n    blu=crop[:,:,0].astype(np.int64)    \n    gre=crop[:,:,1].astype(np.int64)    \n    red=crop[:,:,2].astype(np.int64)      \n    lll=(((blu**2)+(gre**2)+(red**2))/float(3))**0.5    \n    lll=lll.astype(np.uint8)#1st version of image    \n    return lll","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Root_Channel_SQUR_image = Root_Channel_SQUR(res_image)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(Root_Channel_SQUR_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merging multiple outputs"},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 125\nfig = plt.figure(figsize=(25, 16))\nimg_list = []\nimg_size = []\n# display 10 images from each class\n#for class_id in sorted(train_y.unique()):\nfor class_id in [0, 1, 2, 3, 4]:\n    for i, (idx, row) in enumerate(train_df.loc[train_df['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path = os.path.join(root, 'train_images', '{}.png'.format(row['id_code']))\n        image = cv2.imread(path)\n        img_size.append(image.shape)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        #image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        img_list.append(row['id_code'])\n        \n        print(row['id_code'])\n        \n        \n        plt.imshow(image)\n        ax.set_title('Label: %d ' % (class_id) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Krisch filter"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Krish(crop):    \n    Input=crop[:,:,1]    \n    a,b=Input.shape    \n    Kernel=np.zeros((3,3,8))#windows declearations(8 windows)    \n    Kernel[:,:,0]=np.array([[5,5,5],[-3,0,-3],[-3,-3,-3]])     \n    Kernel[:,:,1]=np.array([[-3,5,5],[-3,0,5],[-3,-3,-3]])    \n    Kernel[:,:,2]=np.array([[-3,-3,5],[-3,0,5],[-3,-3,5]])    \n    Kernel[:,:,3]=np.array([[-3,-3,-3],[-3,0,5],[-3,5,5]])    \n    Kernel[:,:,4]=np.array([[-3,-3,-3],[-3,0,-3],[5,5,5]])    \n    Kernel[:,:,5]=np.array([[-3,-3,-3],[5,0,-3],[5,5,-3]])    \n    Kernel[:,:,6]=np.array([[5,-3,-3],[5,0,-3],[5,-3,-3]])    \n    Kernel[:,:,7]=np.array([[5,5,-3],[5,0,-3],[-3,-3,-3]])    \n    #Kernel=(1/float(15))*Kernel    \n    #Convolution output    \n    dst=np.zeros((a,b,8))    \n    for x in range(0,8):        \n        dst[:,:,x] = cv2.filter2D(Input,-1,Kernel[:,:,x])    \n    Out=np.zeros((a,b))    \n    for y in range(0,a-1):        \n        for z in range(0,b-1):            \n            Out[y,z]=max(dst[y,z,:])    \n    Out=np.uint8(Out)            \n    return Out\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Krish_image = Krish(res_image)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(Krish_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"                             **-----*-----*-----**"},{"metadata":{},"cell_type":"markdown","source":"### Additional functions that might be useful."},{"metadata":{"trusted":true},"cell_type":"code","source":"def illumination_correction(image, factor):       \n    hls= cv2.cvtColor(image, cv2.COLOR_BGR2HLS)    \n    hh,ll,ss = cv2.split(hls)    \n    final_v = cv2.medianBlur(ss, factor)    \n    conv = cv2.merge((hh,final_v,ll))    \n    fin = cv2.cvtColor(conv, cv2.COLOR_HSV2BGR)\n    return fin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"illum_image = illumination_correction(res_image, factor = 31)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(illum_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### HOG"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.feature import hog\n\ndef HOG_Image(crop):    \n    image=crop[:,:,1]    \n    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(4, 4),cells_per_block=(2, 2), visualise=True)    \n    return hog_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread(os.path.join(root, 'train_images', '{}.png'.format(img_list[0])))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nres_image = resize_image(image)\n\nhog_image = HOG_Image(res_image)\n#matplotlib.rc('figure', figsize=[7, 7])\n#plt.imshow(hog_image)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(hog_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Tan_inv(crop):    \n    gre=crop[:,:,1].astype(np.float64)    \n    red=crop[:,:,2].astype(np.float64)        \n    red[red==0]=0.000001    \n    m=gre/red# n=((np.arctan(m))*180)/3.14#n=((np.arctan(m))*255)/3.14    \n    n=np.arctan(m)#j=n.astype(np.uint8)    \n    ij=(n*255)/3.14    \n    j=ij.astype(np.uint8)    \n    equ = cv2.equalizeHist(j)    \n    return equ\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tan_inv_image = Tan_inv(res_image)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(Tan_inv_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Cos_inv(crop):    \n    blu=crop[:,:,0].astype(np.float64)    \n    gre=crop[:,:,1].astype(np.float64)    \n    red=crop[:,:,2].astype(np.float64)     \n    l=((blu**2)+(gre**2)+(red**2))**0.5    \n    l=l.astype(np.float64)    \n    l[l==0]=0.0000000001    \n    m=blu/l    \n    Max=np.max(m)    \n    Min=np.min(m)    \n    j=((m-float(Min)/(float(Max)-float(Min)))*2)-1    \n    n=((np.arccos(j))*255)/3.14    \n    nm=n.astype(np.uint8)    \n    equ1 = cv2.equalizeHist(nm)    \n    return equ1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Cos_inv_image = Cos_inv(res_image)\n\nmatplotlib.rc('figure', figsize=[15, 15])\nfig, axarr = plt.subplots(1,2)\naxarr[0].imshow(res_image)\naxarr[1].imshow(Cos_inv_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kindly send me your suggestions."},{"metadata":{"trusted":true},"cell_type":"code","source":"#In progress\n'''\ntemplate = cv2.imread(os.path.join(root, ''))\ntemplate1 = cv2.imread(os.path.join(root, ''))\ntemplate2 = cv2.imread(os.path.join(root, ''))\ntemplate3 = cv2.imread(os.path.join(root, ''))\ntemplate4 = cv2.imread(os.path.join(root, ''))\ntemplate5 = cv2.imread(os.path.join(root, ''))\ntemplate6 = cv2.imread(os.path.join(root, ''))\ntemplate7 = cv2.imread(os.path.join(root, ''))\n\ndef matching(source, template):    \n    oldshape = source.shape    \n    source1 = source.ravel()    \n    template1 = np.asarray(template)   \n    s_values, bin_idx, s_counts = np.unique(source1, return_inverse=True,return_counts=True)    \n    t_values, t_counts = np.unique(template1, return_counts=True)    \n    s_quantiles = np.cumsum(s_counts).astype(np.float64)    \n    s_quantiles /= s_quantiles[-1]    \n    t_quantiles = np.cumsum(t_counts).astype(np.float64)    \n    t_quantiles /= t_quantiles[-1]    \n    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)    \n    interp_t_values1=interp_t_values.astype(np.uint8)    \n    sub=interp_t_values-interp_t_values1    \n    interp_t_values1[sub>.5]+=1    \n    match_v1=interp_t_values1[bin_idx].reshape(oldshape).astype(np.uint8)    \n    #match_v2=Radius_Reduction(match_v1, PARAM)    \n    return match_v1\n\ntemplates_list = [template, template1, template2, template3, template4, template5, template6, template7]\n\nr_l = []\ng_l= []\nb_l = []\nfor t in templates_list:\n    t = cv2.resize(t, (IMAGE_SIZE, IMAGE_SIZE))\n    r_l.append(list(t[:,:,0].ravel()))\n    g_l.append(list(t[:,:,1].ravel()))\n    b_l.append(list(t[:,:,2].ravel()))\n\nr_list = [item for sublist in r_l for item in sublist]\ng_list = [item for sublist in g_l for item in sublist]\nb_list = [item for sublist in b_l for item in sublist]\n\nr_list = list(set(r_list))\ng_list = list(set(g_list))\nb_list = list(set(b_list))\n\nsource = cv2.imread(os.path.join(root, ''))\nsource = cv2.resize(source, (IMAGE_SIZE, IMAGE_SIZE))\n\nmatch_r = matching(source[:,:,0], r_list)\nmatch_g = matching(source[:,:,1], g_list)\nmatch_b = matching(source[:,:,2], b_list)\n\nfin = cv2.merge((match_r, match_g, match_b))\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}