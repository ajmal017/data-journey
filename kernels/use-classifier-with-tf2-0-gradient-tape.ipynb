{"cells":[{"metadata":{},"cell_type":"markdown","source":"### USE Classifier with lower-level TensorFlow\n\n**Note:**<br>\nIn previous commits I tested out LSTM for question answering classification. In terms of performance, it didn't do too well. Thus I've decided to experiment a bit with a USE classifier instead and see how far I can get with that.\n\n**Implementation:**<br>\nThis is a TensorFlow implementation of an USE classifier for a question answering problem. What makes this implementation different from a more \"high level\" tensorflow implementation is the `tf.GradientTape` API for automatic differentiation (details can be for example be found [here](https://www.tensorflow.org/tutorials/customization/autodiff) and elsewhere).<br> \n\n**Additional:**<br>\nIn addition to using `tf.GraidentTape`, and because the neural network is relatively simple, I've implemented the dense layers \"from scratch\" (ie. using `tf.Variable()`, `tf.matmul(x,w)` etc.), because why not? :-)\n\n<br>\n*This kernel does not explore the data. For that you could check out some of the great EDA kernels: [introduction](https://www.kaggle.com/corochann/google-quest-first-data-introduction), [getting started](https://www.kaggle.com/phoenix9032/get-started-with-your-questions-eda-model-nn) & [another getting started](https://www.kaggle.com/hamditarek/get-started-with-nlp-lda-lsa).*\n\n---\n**Update 1 (Commit 20)**:\n* Adding `tf.function` decorator to functions with heavy computations. In this case, **this will speed up the training signficantly.**\n* Adding category and host as input (very first time I use these as input). At this point the implementation starts to get a bit messy\n---\n**Update 2 (Commit 21)**:\n* Fixing bug where dropout was applied during test time. Now dropout is ignored when not training\n* Adjusting dropout rates a bit\n* Increasing number of dense units slightly\n---\n**Update 3 (Commit 22)**:\n* Adding test time dropout \n* Predicting every example 30 times.\n---"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport re\nimport tensorflow_hub as hub\nimport tensorflow as tf\nimport gc\nimport os\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\n\nnp.set_printoptions(suppress=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1. Read data"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/google-quest-challenge/'\n\ndf_train = pd.read_csv(PATH+'train.csv')\ndf_test = pd.read_csv(PATH+'test.csv')\ndf_sub = pd.read_csv(PATH+'sample_submission.csv')\nprint('train shape =', df_train.shape)\nprint('test shape =', df_test.shape)\n\noutput_categories = list(df_train.columns[11:])\ninput_categories = list(df_train.columns[[1,2,5,9,10]])\nprint('\\noutput categories:\\n\\t', output_categories)\nprint('\\ninput categories:\\n\\t', input_categories)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Convert plain text to USE vectors"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_to_use_vectors(df, embed):\n    t = np.empty((len(df), 512))\n    q = np.empty((len(df), 512))\n    a = np.empty((len(df), 512))\n    for i, instance in tqdm(df.iterrows()):\n        t[i, :] = embed([str(instance.question_title)])[\"outputs\"].numpy().flatten()\n        q[i, :] = embed([str(instance.question_body)])[\"outputs\"].numpy().flatten()\n        a[i, :] = embed([str(instance.answer)])[\"outputs\"].numpy().flatten()\n    return t, q, a\n\nembed = hub.load('../input/universalsentenceencoderlarge4/')\n\ntrain_t, train_q, train_a = convert_to_use_vectors(df_train, embed)\ntest_t, test_q, test_a = convert_to_use_vectors(df_test, embed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2b. Add axuillary data for additional inputs"},{"metadata":{"trusted":true},"cell_type":"code","source":"def onehot_features(train, test, column):\n    from pandas.api.types import CategoricalDtype\n    categories = train[column].dropna().unique()\n    train[column] = train[column].astype(CategoricalDtype(categories))\n    test[column] = test[column].astype(CategoricalDtype(categories))\n\n    train = pd.get_dummies(train[column])\n    test = pd.get_dummies(test[column])\n    return train, test\n\n\ntrain_category, test_category = onehot_features(df_train, df_test, 'category')\nassert all(train_category.columns == test_category.columns), 'Mismatch between train and test set'\ntrain_category = np.asarray(train_category, dtype=np.float32)\ntest_category = np.asarray(test_category, dtype=np.float32)\nprint('train category one hot shape = {}'.format(train_category.shape))\nprint('test category one hot shape = {}'.format(test_category.shape))\n\ntrain_host, test_host = onehot_features(df_train, df_test, 'host')\nassert all(train_host.columns == test_host.columns), 'Mismatch between train and test set'\ntrain_host = np.asarray(train_host, dtype=np.float32)\ntest_host = np.asarray(test_host, dtype=np.float32)\nprint('train host one hot shape = {}'.format(train_host.shape))\nprint('test host one hot shape = {}'.format(test_host.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Define Spearman metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_spearmanr(trues, preds):\n    rhos = []\n    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n        rho = spearmanr(tcol, pcol + np.random.normal(0, 1e-7, pcol.shape[0]))\n        rhos.append(rho.correlation)\n    return np.mean(rhos)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Create helper functions and Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_weights(init, shape):\n    W = tf.Variable(init(shape))\n    b = tf.Variable(0.)\n    return W, b\n\ndef dense_hidden(x, w, b, dropout_rate, training):\n    x = tf.matmul(x, w) + b\n    x = tf.nn.relu(x)\n    if training:\n        return tf.nn.dropout(x, dropout_rate)\n    return x\n\ndef dense_output(x, w, b):\n    x = tf.matmul(x, w) + b\n    x = tf.nn.sigmoid(x)\n    return x\n\n\nclass NeuralNet(tf.keras.Model):\n\n    def __init__(self, inputs_units, dense_units, dropout_rates, aux_units, name=\"NeuralNet\"):\n        \"\"\"\n        Parameters\n        ----------\n        input_units : list (3 elements)\n            length of (1) use vector, (2) one-hot vec cateogry & (3) one-hot vec host\n            for an input example, i.e. input_units=[512, 5, 63]\n        dense_units : list\n            containing the number of units that will be used for each layer\n        dropout_rates : list \n            the rates of dropout for each of the dense_units/layers (except output layer)\n        aux_units: int\n            number of units for the two auxillary layers\n        \n        \"\"\"\n        \n        super(NeuralNet, self).__init__(name)\n        \n        glorot = tf.initializers.glorot_uniform()\n        self.dropout_rates = dropout_rates\n        self.W1, self.b1 = initialize_weights(glorot, (input_units[0], dense_units[0]))\n        self.W2, self.b2 = initialize_weights(glorot, (dense_units[0], dense_units[1]))\n        self.W3, self.b3 = initialize_weights(glorot, (dense_units[0], dense_units[2]))\n        self.W4, self.b4 = initialize_weights(glorot, (dense_units[0], dense_units[3]))\n        self.W5, self.b5 = initialize_weights(\n            glorot, (dense_units[1]+dense_units[2]+dense_units[3]+(aux_units*2), dense_units[4]))\n        \n        self.W_aux1, self.b_aux1 = initialize_weights(glorot, (inputs_units[1], aux_units))\n        self.W_aux2, self.b_aux2 = initialize_weights(glorot, (inputs_units[2], aux_units))\n    \n    @tf.function\n    def call(self, inputs, training=False):\n        \n        # sharing first layer (\"text\" input)\n        x0 = dense_hidden(inputs[0], self.W1, self.b1, self.dropout_rates[0], training)\n        x1 = dense_hidden(inputs[1], self.W1, self.b1, self.dropout_rates[0], training)\n        x2 = dense_hidden(inputs[2], self.W1, self.b1, self.dropout_rates[0], training)\n        # no more sharing\n        x0 = dense_hidden(x0, self.W2, self.b2, self.dropout_rates[1], training)\n        x1 = dense_hidden(x1, self.W3, self.b3, self.dropout_rates[2], training)\n        x2 = dense_hidden(x2, self.W4, self.b4, self.dropout_rates[3], training)\n        \n        # aux layers\n        # category input -> hidden_layer\n        x3 = dense_hidden(inputs[3], self.W_aux1, self.b_aux1, self.dropout_rates[-1], training)\n        # host input -> hidden layer\n        x4 = dense_hidden(inputs[4], self.W_aux2, self.b_aux2, self.dropout_rates[-1], training)\n        \n        # concat and output\n        x = tf.concat([x0, x1, x2, x3, x4], axis=1)\n        return dense_output(x, self.W5, self.b5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Creating functions for creating tf.Dataset and for Model training \n\nWith Gradient Tape and eager execution you have a lot of control over your training steps. You can track computations and calculate gradients with respect to the variables of your choice. For tracking `tf.constant` we need to do `tape.watch(constant)`, however, trainable variables are automatically watched over.<br>\n\nBe aware that computing metric during training may add significant time to the training loop."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(inputs, outputs=None, batch_size=8):\n    dataset_inputs = tf.data.Dataset.from_tensor_slices(inputs)\n    if outputs is not None:\n        dataset_outputs = tf.data.Dataset.from_tensor_slices(outputs)\n        return tf.data.Dataset.zip((dataset_inputs, dataset_outputs)).batch(batch_size)\n    return dataset_inputs.batch(batch_size)\n\ndef get_train_step_fn():\n    \"\"\"This is a workaround so that the tf.function decorator\n    works for the cross-validation. i.e. when it's called \n    a second and third time etc..\"\"\"\n    @tf.function\n    def train_step(model, loss_function, optimizer, metric, x, y):\n        with tf.GradientTape() as tape:\n            pred = model(x, training=True)\n            loss = loss_function(y, pred)\n        # compute gradients of all trainable variables with respect to the loss\n        grad = tape.gradient(loss, model.trainable_variables)\n        # apply gradients to the variables/updating them\n        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n        # batch metric calculation\n        metric(y, pred)\n\n        return loss, pred\n    return train_step\n\ndef train_and_predict(model, loss_function, optimizer, metric, \n                      train_dataset, valid_dataset, test_dataset, num_epochs):\n    \n    train_step = get_train_step_fn()\n    valid_snapshot_preds, test_snapshot_preds = [], []\n    train_scores, valid_scores = [0.], [0.]\n    for epoch in range(num_epochs):\n        \n        print(\"\\nepoch %03d\" % (epoch+1))\n        \n        # training loop\n        epoch_loss = 0.\n        train_preds, train_trues = np.empty((0, 30), np.float32), np.empty((0, 30), np.float32)\n        for batch, (x_train, y_train) in enumerate(train_dataset):\n            loss, pred = train_step(model, loss_function, optimizer, metric, x_train, y_train)\n            epoch_loss += loss\n            train_trues = np.append(train_trues, y_train.numpy(), axis=0)\n            train_preds = np.append(train_preds, pred.numpy(), axis=0)\n            \n            print(\"batch {:03d} : train loss {:.3f} : train cosine {:.3f} : train spearman {:.3f} : valid spearman {:.3f}\"\n                  .format(batch+1, epoch_loss/(batch+1), metric.result().numpy(), train_scores[-1], valid_scores[-1]), end=\"\\r\")\n            \n        train_scores.append(compute_spearmanr(train_trues, train_preds))\n        \n        # validation loop\n        dropout_preds = []\n        for _ in range(30):\n            valid_preds, valid_trues = np.empty((0, 30), np.float32), np.empty((0, 30), np.float32)\n            for (x_val, y_val) in valid_dataset:\n                valid_preds = np.append(valid_preds, model(x_val, training=True).numpy(), axis=0) # note training = True for dropout\n                valid_trues = np.append(valid_trues, y_val.numpy(), axis=0)\n            dropout_preds.append(valid_preds)\n        valid_snapshot_preds.append(np.average(dropout_preds, axis=0))\n        valid_scores.append(compute_spearmanr(valid_trues, np.average(valid_snapshot_preds, axis=0)))\n        \n        # just to update current print before moving to next epoch\n        print(\"batch {:03d} : train loss {:.3f} : train cosine {:.3f} : train spearman {:.3f} : valid spearman {:.3f}\"\n              .format(batch+1, epoch_loss/(batch+1), metric.result().numpy(), train_scores[-1], valid_scores[-1]), end=\"\\r\")\n        \n        # manually resetting metric\n        metric.reset_states()\n        \n        # test loop \n        dropout_preds = []\n        for _ in range(30):\n            test_preds = np.empty((0, 30), np.float32)\n            for x_test in test_dataset:\n                test_preds = np.append(test_preds, model(x_test, training=True).numpy(), axis=0) # note training = True for dropout\n            dropout_preds.append(test_preds)\n        test_snapshot_preds.append(np.average(dropout_preds, axis=0))\n\n        \n    return valid_snapshot_preds, test_snapshot_preds, train_scores, valid_scores\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6. Cross validation \n\nFinally training and predicting with the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_units = [512, 5, 63] # use, cat, host input size\ndense_units = [512, 256, 256, 256, 30] # for shared layer, non-shared layers, output layer\naux_units = 256 # for aux layers\ndropout_rates = [0.3, 0.2, 0.2, 0.2] # for shared layer, non-shared layers\nnum_folds = 5\nnum_epochs = 12\nlearning_rate = 5e-4\nbatch_size = 64\n\nmodel = None\noptimizer = tf.keras.optimizers.Adam(learning_rate)\nloss_function = tf.keras.losses.BinaryCrossentropy()\nmetric = tf.keras.metrics.CosineSimilarity()\n\ngkf = GroupKFold(n_splits=num_folds).split(X=df_train.question_body, groups=df_train.question_body)\n\nvalid_fold_predictions = []\ntest_fold_predictions = []\ntrain_fold_scores = []\nvalid_fold_scores = []\nfor fold, (train_idx, valid_idx) in enumerate(gkf):\n    \n    print(\"\\n\\nfold {:01d}\".format(fold+1))\n    model = NeuralNet(input_units, dense_units, dropout_rates, aux_units)\n\n    train_dataset = create_dataset(\n        (train_t[train_idx], train_q[train_idx], train_a[train_idx], \n         train_category[train_idx], train_host[train_idx]), \n         np.asarray(df_train[output_categories].iloc[train_idx]),\n         batch_size)\n\n    valid_dataset = create_dataset(\n        (train_t[valid_idx], train_q[valid_idx], train_a[valid_idx], \n         train_category[valid_idx], train_host[valid_idx]), \n         np.asarray(df_train[output_categories].iloc[valid_idx]),\n         batch_size)\n\n    test_dataset = create_dataset(\n        (test_t, test_q, test_a, \n         test_category, test_host),\n         None,\n         batch_size)\n    \n    valid_preds, test_preds, train_scores, valid_scores = train_and_predict(\n        model, loss_function, optimizer, metric,\n        train_dataset, valid_dataset, test_dataset, num_epochs)\n\n    valid_fold_predictions.append(valid_preds)\n    test_fold_predictions.append(test_preds)\n    train_fold_scores.append(train_scores)\n    valid_fold_scores.append(valid_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7. Plot spearmanr vs epochs\n\nThe way the train scores are obtained makes the comparison with the valid scores/spearmanr far from perfect. The train preds are obtained for each batch during the epoch, and is thus heavily influenced by earlier examples that epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, axes = plt.subplots(1, num_folds, figsize=(num_folds*5, num_folds))\n\nfor i, ax in enumerate(axes.reshape(-1)):\n    ax.plot(np.linspace(0., len(train_fold_scores[i])-1, len(train_fold_scores[i])), \n            train_fold_scores[i], label='training')\n    ax.plot(np.linspace(0., len(valid_fold_scores[i])-1, len(valid_fold_scores[i])), \n            valid_fold_scores[i], label='validation')\n    ax.set_title(\"Fold {}\".format(i+1))\n    if i == 0:\n        ax.set_ylabel(\"spearman rho\")\n    ax.set_xlabel(\"epochs\")\n    ax.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8. Submit test predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# if snapshot preds:\ndef compute_final_predictions(test_fold_predictions):\n    snapshot_averages = [np.average(test_fold_predictions[i], axis=0) for i in range(len(test_fold_predictions))]\n    return np.mean(snapshot_averages, axis=0)\n\ndf_sub.iloc[:, 1:] = compute_final_predictions(test_fold_predictions)\ndf_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if not snapshot preds:\n# df_sub.iloc[:, 1:] = np.mean(test_fold_predictions, axis=0)\n# df_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}