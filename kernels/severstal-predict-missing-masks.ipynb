{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this kernel\n\nThe goal is to:\n* Investigate the problem of null masks by exploring the distribution of NaN per image.\n* Reduce image size to 224x224 for simpler models.\n* Create a lightweight CNN to predict if a certain image has no defect (i.e., it has 4 missing masks). This will be useful in order to reduce the computation power needed to train a segmentation model (e.g. Mask R-CNN), since we can immediately discard the image with 4 missing masks.\n\nThis is a work in progress, and I will update the kernel in the next few days. I'll work hard on this if you show some support :)\n\n### Updates\n* V9: Changed model from MobileNet to DenseNet."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam, Nadam\nimport tensorflow as tf\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\n\nprint(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nprint(submission_df.shape)\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_test_images = submission_df['ImageId_ClassId'].apply(\n    lambda x: x.split('_')[0]\n).unique()\n\nunique_test_images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n\nThis EDA will mainly focus on detecting how the null masks are distributed. We will group all the `ImageId_ClassId` by their respective ImageId, and keep track of the number of missing masks for each image."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['isNan'] = pd.isna(train_df['EncodedPixels'])\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(\n    lambda x: x.split('_')[0]\n)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_nan_df = train_df.groupby(by='ImageId', axis=0).agg('sum')\ntrain_nan_df.reset_index(inplace=True)\ntrain_nan_df.rename(columns={'isNan': 'missingCount'}, inplace=True)\ntrain_nan_df['missingCount'] = train_nan_df['missingCount'].astype(np.int32)\ntrain_nan_df['allMissing'] = (train_nan_df['missingCount'] == 4).astype(int)\n\ntrain_nan_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_nan_df = pd.DataFrame(unique_test_images, columns=['ImageId'])\nprint(test_nan_df.shape)\ntest_nan_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_nan_df['missingCount'].hist()\ntrain_nan_df['missingCount'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice that an overwhelming number of images have 3 to 4 missing masks. In fact, all except 2 images have 2+ missing masks. This means that we would basically need to train the final segmentation model on less than half of the data points."},{"metadata":{},"cell_type":"markdown","source":"# Reducing Image Size"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_img(code, base, resize=True):\n    path = f'{base}/{code}'\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, (256, 256))\n    \n    return img\n\ndef validate_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../tmp/train'\nvalidate_path(train_path)\n\nfor code in tqdm(train_nan_df['ImageId']):\n    img = load_img(\n        code,\n        base='../input/severstal-steel-defect-detection/train_images'\n    )\n    path = code.replace('.jpg', '')\n    cv2.imwrite(f'{train_path}/{path}.png', img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_nan_df['ImageId'] = train_nan_df['ImageId'].apply(\n    lambda x: x.replace('.jpg', '.png')\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\n\ndef create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.1,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,\n        rotation_range=10,\n        height_shift_range=0.1,\n        width_shift_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        rescale=1/255.,\n        validation_split=0.15\n    )\n\ndef create_test_gen():\n    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n        test_nan_df,\n        directory='../input/severstal-steel-defect-detection/test_images/',\n        x_col='ImageId',\n        class_mode=None,\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\ndef create_flow(datagen, subset):\n    return datagen.flow_from_dataframe(\n        train_nan_df, \n        directory='../tmp/train',\n        x_col='ImageId', \n        y_col='allMissing', \n        class_mode='other',\n        target_size=(256, 256),\n        batch_size=BATCH_SIZE,\n        subset=subset\n    )\n\n# Using original generator\ndata_generator = create_datagen()\ntrain_gen = create_flow(data_generator, 'training')\nval_gen = create_flow(data_generator, 'validation')\ntest_gen = create_test_gen()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    densenet = DenseNet121(\n        include_top=False,\n        input_shape=(256,256,3),\n        weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5'\n    )\n    \n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Nadam(),\n        metrics=['accuracy']\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_steps = train_nan_df.shape[0] / BATCH_SIZE\n\ncheckpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_acc', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    patience=5,\n    verbose=1,\n    min_lr=1e-6\n)\n\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch=total_steps * 0.85,\n    validation_data=val_gen,\n    validation_steps=total_steps * 0.15,\n    epochs=40,\n    callbacks=[checkpoint, reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save results as CSV files"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model.h5')\ny_test = model.predict_generator(\n    test_gen,\n    steps=len(test_gen),\n    verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_nan_df['allMissing'] = y_test\n\nhistory_df.to_csv('history.csv', index=False)\ntrain_nan_df.to_csv('train_missing_count.csv', index=False)\ntest_nan_df.to_csv('test_missing_count.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}