{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Power of Recommendation Engine\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;suppose you're planning to buy a laptop without any idea about the right configuration. So i would check with my friends and colleagues for recommendation and they suggests laptops based on your requirement , their knowledge and trending. The same way Amazon recommends you a laptop based on your previous search , popularity and keeps on showing the best recommendation and tempt you to buy a laptop even if you drop the plan. All the major company has recommendation in their products such as Youtube shows recommendations based on your interests and activity.\n\nWe'll explore how to implement it, before that there are two types of Recommendation Engine\n\n* Content Based Filtering\n* Collabarative Based Filtering\n\n#### Content Based Filtering\nThis algorithm recommends products which are similar to the ones that a user has liked in the past.\n\n#### Collabaratvie Based Filtering\nThe collaborative filtering algorithm uses “User Behavior” for recommending items."},{"metadata":{},"cell_type":"markdown","source":"In this Kernel, we shall look at Content Based Filtering implementation"},{"metadata":{},"cell_type":"markdown","source":"Our task is When User search a movie We'll recommend the top 10 similar movies"},{"metadata":{},"cell_type":"markdown","source":"Implementation is so simple, We're going to combine and create a bulk of keywords for each movie from the multiple given datasets and final similarity between each movie and popup the top similar movies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"../input/movielens-20m-dataset\")\nos.chdir(\"../input/movielens-20m-dataset/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genome_tags = pd.read_csv(\"genome_tags.csv\")\n\n# We drop this dataset, since this doesn't have any useful features for predictions\nlink = pd.read_csv(\"link.csv\")\ngenome_scores = pd.read_csv(\"genome_scores.csv\")\n\n# For efficiency and compatability We pick top 5000 rows\nmovies = pd.read_csv(\"movie.csv\",nrows=5000)\nrating = pd.read_csv(\"rating.csv\")\ntag = pd.read_csv(\"tag.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset shape\nprint(\"genome_tags shape is {}\".format(genome_tags.shape))\nprint(\"genome_scores shape is {}\".format(genome_scores.shape))\nprint(\"movies shape is {}\".format(movies.shape))\nprint(\"rating shape is {}\".format(rating.shape))\nprint(\"tag shape is {}\".format(tag.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(genome_scores.columns)\nprint(movies.columns)\nprint(rating.columns)\nprint(tag.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"movieId feature is common in all dataset, using that we'll combine all the dataset into final_dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# genome_scores dataset has relevance feature which says that how much a tag is relevant to the movie and\n# it's value range from 0 to 1, we'll consider only the value which has more than 0.5 relevance. So this gives better \n# predicrion. And We'll merge the tag with genome_scores dataset.\ngenome_scores = genome_scores[genome_scores['relevance']> 0.5].merge(genome_tags,on='tagId',how='left') \n\n# concatenating all the tag that belongs to a movie and forming a tag collection for each movie\ngenome_scores = genome_scores.groupby('movieId')['tag'].apply(' '.join).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset = pd.merge(movies,genome_scores,on='movieId',how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming tag as keywords\ntag = tag.rename(columns = {\"tag\":\"keywords\"})\ntag['keywords'].fillna('',inplace=True)\ntag = tag.groupby('movieId')['keywords'].apply(' '.join).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset = pd.merge(final_dataset,tag,on='movieId',how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset['genres'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset['keywords'] = final_dataset['keywords'] + \" \" +final_dataset['tag'] +  \" \" + \\\n    final_dataset['genres'].str.replace(\"|\",\" \")\nfinal_dataset['keywords'].fillna(\"\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rating will be used for collabarative filtering, so we'll skip this now\n# final_dataset = pd.merge(final_dataset,rating,on='movieId',how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Both tag and genres values has added to keywords so we drop this \nfinal_dataset.drop(['tag','genres'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_dataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_vect = TfidfVectorizer(stop_words='english')\nX = c_vect.fit_transform(final_dataset['keywords'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are other similiary distance metric available which are euclidean distance,manhattan distance, Pearson coefficient etc\n# But for sparse matrix cosine similarity works better\ncosine_sim = cosine_similarity(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_movie_recommendation(movie_name):\n    idx = final_dataset[final_dataset['title'].str.contains(movie_name)].index\n    if len(idx):\n        movie_indices = sorted(list(enumerate(cosine_sim[idx[0]])), key=lambda x: x[1], reverse=True)[1:11]\n        movie_indices = [i[0] for i in movie_indices]\n        return movie_indices\n    else : \n        return []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = \"Toy Story 2\"\nrecommended_movie_list = get_movie_recommendation(title)\nmovies.iloc[recommended_movie_list].set_index('movieId')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our system predicts exactly the similar movies of Toy story\n\nMajor drawback of this approach is that it predicts the same lists of movie for all the user who search Toy story irrespective of their interest and their likes. So we need an algorithm to predict based on User behaviour for that We'll use collabrative filtering."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"I'm writing my other kernel for collabarative filtering. Will update once it is completed.\n\n**Please upvote it if you like it. Thanks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}