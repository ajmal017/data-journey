{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\"../input/\"\nX_full = pd.read_csv(\"../input/learn-together/train.csv\", \n                index_col=0)\ntest = pd.read_csv(\"../input/learn-together/test.csv\", \n                   index_col=0)\n\nTARGET = 'Cover_Type'\n#X_full[TARGET] = X_full[TARGET].transform(str)\nX = X_full.copy()\ny = X_full[TARGET]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(X.shape)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 54 columns or features and 15120 observations.\nThe dataset is balanced, there are only 7 values for the label (Cover_Type), and each type have same sample size (2160 rows)\n\nIt is a multi classification problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Excellent!! all features are numeric\n`Soil_TypeX` and `Wilderness_AreaX` are OHE features of categorical variables. Hence they are binary columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no NANs!!!\nLets train our first model\n"},{"metadata":{},"cell_type":"markdown","source":"## Distances analysis\n\nDistances features are: \n- Vertical_Distance_To_Hydrology\n- Horizontal_Distance_To_Hydrology\n- Horizontal_Distance_To_Roadways\n- Horizontal_Distance_To_Fire_Points"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nX['Euclidean_distance_to_hydro'] = (X.Vertical_Distance_To_Hydrology**2 + X.Horizontal_Distance_To_Hydrology**2)**.5\n\nf, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n\nsns.distplot(X.Horizontal_Distance_To_Hydrology, color=\"b\", ax=axes[0])\nsns.distplot(X.Vertical_Distance_To_Hydrology, color=\"b\", ax=axes[1])\nsns.distplot(X['Euclidean_distance_to_hydro'], color=\"g\", ax=axes[2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interpretation\nThe first plot (horizontal distance to hydrology)\nAs expected, vegetation seems to be more abundant near hydrology.\n\nThe second plot (vertical distance), it seems that the negative values ​​could be vegetation superior to hydrology and the positive ones are vegetation inferior to hydrology. Most of the vegetation is in the downhill from hydrology with a huge amount of vegetation concentrated near 0 (high kurtosis), which means that much vegetation is at almost the same level of water.\n\nWhen calculating the Euclidean distance to hydrology as a heuristic measure, we see that our third graph looks like the first, this is because the horizontal distance has a wider distribution compared to the horizontal distance where almost all values ​​are close to zero. However, this Euclidean distance is also better suited to the line, which will improve our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def euclidean(df):\n    df['Euclidean_distance_to_hydro'] = (df.Vertical_Distance_To_Hydrology**2 \n                                         + df.Horizontal_Distance_To_Hydrology**2)**.5\n\n    return df\n\nX = euclidean(X)\ntest = euclidean(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import combinations\n\ndef distances(df):\n    cols = [\n        'Horizontal_Distance_To_Roadways',\n        'Horizontal_Distance_To_Fire_Points',\n        'Horizontal_Distance_To_Hydrology',\n    ]\n    \n    df['distance_mean'] = df[cols].mean(axis=1)\n    df['distance_sum'] = df[cols].sum(axis=1)\n    df['distance_road_fire'] = df[cols[:2]].mean(axis=1)\n    df['distance_hydro_fire'] = df[cols[1:]].mean(axis=1)\n    df['distance_road_hydro'] = df[[cols[0], cols[2]]].mean(axis=1)\n    \n    df['distance_sum_road_fire'] = df[cols[:2]].sum(axis=1)\n    df['distance_sum_hydro_fire'] = df[cols[1:]].sum(axis=1)\n    df['distance_sum_road_hydro'] = df[[cols[0], cols[2]]].sum(axis=1)\n    \n    df['distance_dif_road_fire'] = df[cols[0]] - df[cols[1]]\n    df['distance_dif_hydro_road'] = df[cols[2]] - df[cols[0]]\n    df['distance_dif_hydro_fire'] = df[cols[2]] - df[cols[1]]\n    \n    # Vertical distances measures\n    colv = ['Elevation', 'Vertical_Distance_To_Hydrology']\n    \n    df['Vertical_dif'] = df[colv[0]] - df[colv[1]]\n    df['Vertical_sum'] = df[colv].sum(axis=1)\n    \n    return df\n\nX = distances(X)\ntest = distances(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shade analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n\nsns.distplot(X['Hillshade_9am'], color=\"y\", ax=axes[0])\nsns.distplot(X['Hillshade_Noon'], color=\"b\", ax=axes[1])\nsns.distplot(X['Hillshade_3pm'], color=\"g\", ax=axes[2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].kurt()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interpretation\n\nHere we can see the variation in the amount of sunlight among three different day hours.\nBetween 9 am and noon, we see how the sunlight is increasing with a high positive kurtosis (>1) a huge peak in approx 225, that is almost the max value measurable (254). \n\nBy the 3 pm, there is a significant reduction of the light is some zones, (maybe by some hill), now the kurtosis is close to 0.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def shade(df):\n    SHADES = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n    \n    df['shade_noon_diff'] = df['Hillshade_9am'] - df['Hillshade_Noon']\n    df['shade_3pm_diff'] = df['Hillshade_Noon'] - df['Hillshade_3pm']\n    df['shade_all_diff'] = df['Hillshade_9am'] - df['Hillshade_3pm']\n    df['shade_sum'] = df[SHADES].sum(axis=1)\n    df['shade_mean'] = df[SHADES].mean(axis=1)\n    return df\n\nX = shade(X)\ntest = shade(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Soil analysis\n\n1=rubbly, 2=stony, 3=very stony, 4=extremely stony\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a dict that map soil type with rockness\n# 0=unknow 1=complex 2=rubbly, 3=stony, \n# 4=very stony, 5=extremely stony 6=extremely bouldery\nsoils = [\n    [7, 15, 8, 14, 16, 17,\n     19, 20, 21, 23], #unknow and complex \n    [3, 4, 5, 10, 11, 13],   # rubbly\n    [6, 12],    # stony\n    [2, 9, 18, 26],      # very stony\n    [1, 24, 25, 27, 28, 29, 30,\n     31, 32, 33, 34, 36, 37, 38, \n     39, 40, 22, 35], # extremely stony and bouldery\n]\n\nsoil_dict = dict()\nfor index, values in enumerate(soils):\n    for v in values:\n        soil_dict[v] = index\n        \n        \ndef soil(df, soil_dict=soil_dict):\n    df['Rocky'] =  sum(i * df['Soil_Type'+ str(i)] for i in range(1, 41))\n    df['Rocky'] = df['Rocky'].map(soil_dict) \n\n    return df\n\nX = soil(X)\ntest = soil(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x=TARGET, y='Rocky', data=X)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), \n                       sharex=True, sharey=True)\nsns.scatterplot(x=TARGET, y='Elevation', \n                hue='Rocky', data=X)\n\nc_7 = (X.Cover_Type == 7)\nr_4 = X.Rocky != 4\n\n\nX['Soil_Type'] = sum(X['Soil_Type' + str(i)] * i for i in range(1, 41))\nX[c_7][r_4].Soil_Type.value_counts()\n\nX[X['Soil_Type']==35].Cover_Type.value_counts()\nX[X['Soil_Type']==23].Cover_Type.value_counts()\nX[X['Soil_Type']==4].Cover_Type.value_counts()\nX[X['Soil_Type']==21].Cover_Type.value_counts()"},{"metadata":{},"cell_type":"markdown","source":"## Elevation analysis\n\nElevation is the most important feature (see feature importance section). Hence we would compare this with other features (bivariate analysis), and make some transformations creating new features that help our tree algos to make better splits."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x=TARGET, y='Elevation', data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Hillshade_9am', y='Elevation', \n                hue=TARGET, data=X, y_jitter=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Hillshade_Noon', y='Elevation', \n                hue=TARGET, data=X, y_jitter=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Hillshade_3pm', y='Elevation', \n                hue=TARGET, data=X, y_jitter=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nf, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Euclidean_distance_to_hydro', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def elevation(df):\n    df['ElevationHydro'] = df['Elevation'] - 0.25 * df['Euclidean_distance_to_hydro']\n    return df\n\nX = elevation(X)\ntest = elevation(test)\nf, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Euclidean_distance_to_hydro', y='ElevationHydro', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Vertical_Distance_To_Hydrology', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def elevationV(df):\n    df['ElevationV'] = df['Elevation'] - df['Vertical_Distance_To_Hydrology']\n    return df\n\nX = elevationV(X)\ntest = elevationV(test)\nf, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Vertical_Distance_To_Hydrology', y='ElevationV', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Horizontal_Distance_To_Hydrology', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def elevationH(df):\n    df['ElevationH'] = df['Elevation'] - 0.19 * df['Horizontal_Distance_To_Hydrology']\n    return df\n\nX = elevationH(X)\ntest = elevationH(test)\nf, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Horizontal_Distance_To_Hydrology', y='ElevationH', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Horizontal_Distance_To_Roadways', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Horizontal_Distance_To_Fire_Points', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='distance_road_fire', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kernel_features(df):\n    df['Elevation2'] = df['Elevation']**2\n    df['ElevationLog'] = np.log1p(df['Elevation'])\n    return df\n\nX = kernel_features(X)\ntest = kernel_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Aspect', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(x='Slope', y='Elevation', \n                hue=TARGET, data=X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Slope and Aspect analysis\nSlope and Aspect are degrees features, from 0 to 360 degrees\n\nFirst the slope, the min slope is 0 and the max slope is 52, is vertical inclination respect to the horizon. \n\nNow, Aspect, this feature is in degrees from 0 to 360, I guess refers to cardinal direction of the slope (this is a particular guess). \nI guess 0 refer to North direction for slope, and 180 to the south and so on.\n\nGenerally, the sun moves from east to west (since our optical), hence in a mountain at morning the east side is illuminated and the west is still shade, at noon maybe both sides are illuminated, and by afternoon the west side receives more light than the east side.\n\nNorth and South sides of the mountain, are sides that maximize the sunlight received, and have similar behavior."},{"metadata":{"trusted":true},"cell_type":"code","source":"X[['Slope', 'Aspect']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nf, axes = plt.subplots(3, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(y='Slope', x='Hillshade_9am', \n                hue='Aspect', data=X, ax=axes[0])\nsns.scatterplot(y='Slope', x='Hillshade_Noon', \n                hue='Aspect', data=X, ax=axes[1])\nsns.scatterplot(y='Slope', x='Hillshade_3pm', \n                hue='Aspect', data=X, ax=axes[2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we observe the relationship between slope, aspect, shadow and time.\n\nAt 9 am, all the flat land (slope near zero) receives the same amount of sunlight (approximately 220),\nAt noon it goes up to 240 and at 3 pm it goes down to 155.\n\nIn addition, we observe how the shadow increases the variability in the same way that the slope increases.\nAt 9 am, the aspect between 0 and 150 receives more light, and at 3 pm the relationship has changed. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def degree(df):\n    df['Aspect_cos'] = np.cos(np.radians(df.Aspect))\n    df['Aspect_sin'] = np.sin(np.radians(df.Aspect))\n    #df['Slope_sin'] = np.sin(np.radians(df.Slope))\n    df['Aspectcos_Slope'] = df.Slope * df.Aspect_cos\n    #df['Aspectsin_Slope'] = df.Slope * df.Aspect_sin\n    \n    return df\n\nX = degree(X)\ntest = degree(test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nf, axes = plt.subplots(3, 1, figsize=(15, 15), sharex=True, sharey=True)\nsns.scatterplot(y='Slope', x='Hillshade_9am', \n                hue='Aspect_sin', data=X, ax=axes[0])\nsns.scatterplot(y='Slope', x='Hillshade_Noon', \n                hue='Aspect_sin', data=X, ax=axes[1])\nsns.scatterplot(y='Slope', x='Hillshade_3pm', \n                hue='Aspect_sin', data=X, ax=axes[2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Beautiful!!\n\nThis graphic is revealing.\n\nAt 9am, the sunlight is more intense on the slopes facing east, (darker points) and clearly, the larger the slope, the greater the difference in light between the east and west sides (light points).\n\n  The north and south points have intermediate light values and their variability continues to rise in relation to the slope.\n\nAt noon, all points seem to intermingle, this is because the sun is more distributed on all sides of the mountain.\n\nBy 3pm the difference is marked, this time you can visualize beautifully in this graph as the east side has much less light than the west side."},{"metadata":{},"cell_type":"markdown","source":"## Aspect Binning\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"from bisect import bisect\n\ncardinals = [i for i in range(45, 361, 90)]\n\npoints = ['N', 'E', 'S', 'W']\n\ndef cardinal(df):\n    df['Cardinal'] = df.Aspect.apply(lambda x: points[bisect(cardinals, x) % 4])\n    return df\n\nX = cardinal(X)\ntest = cardinal(test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(5, 1, figsize=(15, 25), sharex=True, sharey=True)\nsns.scatterplot(x='Slope', y='Hillshade_3pm', \n                hue=TARGET, data=X[X.Cardinal=='E'], ax=axes[0])\nsns.scatterplot(x='Slope', y='Hillshade_3pm', \n                hue=TARGET, data=X[X.Cardinal=='W'], ax=axes[1])\nsns.scatterplot(x='Slope', y='Hillshade_3pm', \n                hue=TARGET, data=X[X.Cardinal=='N'], ax=axes[2])\nsns.scatterplot(x='Slope', y='Hillshade_3pm', \n                hue=TARGET, data=X[X.Cardinal=='S'], ax=axes[3])\nsns.scatterplot(x='Slope', y='Hillshade_3pm', \n                hue=TARGET, data=X, ax=axes[4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cardinal_num(df):\n    d = {'N': 0, 'E': 1, 'S': 0, 'W':-1}\n    df['Cardinal'] = df.Cardinal.apply(lambda x: d[x])\n    return df\n\nX = cardinal_num(X)\ntest = cardinal_num(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wilderness Area"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"x1, y1 =   'Horizontal_Distance_To_Hydrology', 'ElevationH'\nHUE = TARGET  # 'Euclidean_distance_to_hydro'\nf, axes = plt.subplots(2, 2, figsize=(25, 25), sharex=True, sharey=True)\nsns.scatterplot(x1, y1, hue=HUE, data=X[X.Wilderness_Area1 == 1], ax=axes[0][0])\nsns.scatterplot(x1, y1, hue=HUE, data=X[X.Wilderness_Area2 == 1], ax=axes[0][1])\nsns.scatterplot(x1, y1, hue=HUE, data=X[X.Wilderness_Area3 == 1], ax=axes[1][0])\nsns.scatterplot(x1, y1, hue=HUE, data=X[X.Wilderness_Area4 == 1], ax=axes[1][1])\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X['w'] = sum(i * X['Wilderness_Area'+ str(i)] for i in range(1, 5))\ntest['w'] = sum(i * test['Wilderness_Area'+ str(i)] for i in range(1, 5))\n\ncols = [\n    'ElevationH', 'Vertical_dif', 'Euclidean_distance_to_hydro', \n    'Aspectcos_Slope', 'distance_dif_hydro_road', 'Hillshade_9am'\n]\nn = ['Elev', 'Vert_d', 'Eucli', 'AspSlo', 'dist_hr', 'hillshade']\n\nstats = X.groupby('w')[cols].describe()\n\nfor i, col in enumerate(cols):\n    name = n[i] + '_mean'\n    d = {r: stats[col]['50%'][r] for r in range(1, 5)}\n    X[name] = X.w.apply(lambda r: d[r])\n    test[name] = test.w.apply(lambda r: d[r])\n\n    \nX.drop('w', inplace=True, axis=1)\ntest.drop('w', inplace=True, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop label \nif TARGET in X.columns:\n    X.drop(TARGET, axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import (\n    RandomForestClassifier,\n    ExtraTreesClassifier,\n    AdaBoostClassifier,\n)\nfrom lightgbm import LGBMClassifier\nfrom mlxtend.classifier import StackingCVClassifier\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nSEED = 2007\n\nmodels = {\n    'LGBM': LGBMClassifier(n_estimators=370,\n                           metric='multi_logloss',\n                           num_leaves=100,\n                           verbosity=0,\n                           random_state=SEED,\n                           n_jobs=-1), \n    'Random Forest': RandomForestClassifier(n_estimators=500,\n                                            n_jobs=-1,\n                                            random_state=SEED),\n    'Extra Tree': ExtraTreesClassifier(\n           max_depth=400, \n           n_estimators=450, n_jobs=-1,\n           oob_score=False, random_state=SEED, \n           warm_start=True)\n\n}\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feautures importances"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = models['Random Forest']\n\ndef feature_importances(clf, X, y, figsize=(18, 6)):\n    clf = clf.fit(X, y)\n    \n    importances = pd.DataFrame({'Features': X.columns, \n                                'Importances': clf.feature_importances_})\n    \n    importances.sort_values(by=['Importances'], axis='index', ascending=False, inplace=True)\n\n    fig = plt.figure(figsize=figsize)\n    sns.barplot(x='Features', y='Importances', data=importances)\n    plt.xticks(rotation='vertical')\n    plt.show()\n    return importances\n    \nimportances = feature_importances(clf, X, y)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def select(importances, edge):\n    c = importances.Importances >= edge\n    cols = importances[c].Features.values\n    return cols\n\ncol = select(importances, 0.0003)\nX = X[col]\ntest = test[col]    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's validate our model(s)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross validation\nfrom sklearn.model_selection import KFold, cross_val_score\n\n# model selection functions\n\ncv = KFold(n_splits=5, shuffle=True, random_state=SEED)\n\ndef cross_val(models, X=X, y=y):\n    r = dict()\n    for name, model in models.items():\n        cv_results = cross_val_score(model, X, y,\n                             cv=cv, \n                             scoring='accuracy')\n        r[name] = cv_results\n        print(name, 'Accuracy Mean {0:.4f}, Std {1:.4f}'.format(\n              cv_results.mean(), cv_results.std()))\n    return r\n    \ndef choose_best(results):\n    errors = dict()\n\n    for name, arr in results.items():\n        errors[name] = arr.mean()\n\n    best_model =  [m for m, e in errors.items() \n                   if e == max(errors.values())][0]\n    return best_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = cross_val(models)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_name = choose_best(results)\n\n\nmodel = models[best_model_name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, filename, X=X, y=y, test=test):\n    model.fit(X, y)\n    predicts = model.predict(test)\n\n    output = pd.DataFrame({'ID': test.index,\n                       TARGET: predicts})\n    output.to_csv(filename+'.csv', index=False)\n    return predicts\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stacked model"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [m for m in models.values()]\n\nstack = StackingCVClassifier(classifiers=estimators,\n                             meta_classifier=model,\n                             cv=cv,\n                             use_probas=True,\n                             use_features_in_secondary=True,\n                             verbose=1,\n                             random_state=SEED,\n                             n_jobs=-1)\n\npredict_stack = predict(stack, 'stacked')\nprint('Ready!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}