{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h3><b>This notebook presents a univariate analysis for all variables in the US Accidents dataset</b></h3>\n<br>To get a full list of the data dicitionary visit the official web page at: https://smoosavi.org/datasets/us_accidents"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# reading the data into a dataframe\naccident_df = pd.read_csv('../input/us-accidents/US_Accidents_May19.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding out number of rows and columns\nshape = accident_df.shape\nprint( \"Number of rows\" , \"{:,}\".format(shape[0]) )\nprint( \"Number of variables\" , shape[1] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print a sample to get sense of data\naccident_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some variables are numerical and some are categorical. Let's put them into two seperate groups using the ***get_numerica_data()***"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = accident_df.columns\nnum_cols = accident_df._get_numeric_data().columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The numerical values are"},{"metadata":{"trusted":true},"cell_type":"code","source":"', '.join( str(x) for x in list(num_cols) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> note that this only shows the columns that have numbers, it does NOT say whether its continous or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"str_col = list( set(cols) - set(num_cols) )\n', '.join( str(x) for x in str_col ) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Some variables like zipcode are stored as string not numbers. We will address this later in the analysis"},{"metadata":{},"cell_type":"markdown","source":"<h1>Categorical Variables</h1>"},{"metadata":{},"cell_type":"markdown","source":"Categorical variables take on values that are names or labels [1] \n\nThe following varaiables are categorical: <i>Source, TMC, Severity, Number+Street, Side, City, County, State, Zipcode, Country, Timezone, Airport_Code, Wind_Direction, Weather_Conditio,\tAmenity, Bump, Crossing, Give_Way, Junction, No_Exit, Railway, Roundabout, Station,\tStop, Traffic_Calming, Traffic_Signal, Turning_Loop, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight</i>"},{"metadata":{},"cell_type":"markdown","source":"Street number by itself is meangless, so I will combine with it the street name in a new column called 'street_name_num'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Street Number is float: can't find different way to drop decimal points and then change Number column to string other than this way\naccident_df['Number'] = accident_df['Number'].replace(np.nan, 0)\naccident_df['Number'] = accident_df['Number'].astype(int)\naccident_df['Number'] = accident_df['Number'].astype(str)\naccident_df['Number'] = accident_df['Number'].replace('0', '')\naccident_df['street_name_num'] = accident_df['Number'] + ' ' + accident_df['Street']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accident_df.sample(5)[ ['Number' , 'Street' , 'street_name_num'] ] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> street_name_num column combines both street number with street name"},{"metadata":{},"cell_type":"markdown","source":"<h3>Missing Values</h3>"},{"metadata":{},"cell_type":"markdown","source":"Most likely the data is complete but its alway a good practice to check for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"percent_missing = accident_df.isnull().sum() * 100 / len(accident_df)\nmissing_value_df = pd.DataFrame({'column_name': accident_df.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df.sort_values('percent_missing', inplace=False, ascending = False)[missing_value_df[ 'percent_missing'] != 0]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. > <i>Precipitation, Wind_chill, end_lat, and end_lng </i> have the highest missing values. The can be dropped unless further analysis show a value of keeping them for any model in future\n2. > Other variables like Wind_speed, weather_condition, visibility, humidity, termperature, pressure, wind_direction, and weather_timestamp can be imputed\n3. > In general, the data dont have missing values for important variables such as severity, location, time, weather, and drive condition\n"},{"metadata":{},"cell_type":"markdown","source":"<h2>Most frequent analysis</h2>\n<p>For each categorical variable, I will display the most frequent values. The following subsections, will group variables according to their meaning.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_plots(columns_list, ncols=3):\n    nrows= int( (len(columns_list) -1) / ncols)  + 1\n    fig, axs = plt.subplots(nrows=nrows , ncols=ncols, figsize= (20,nrows*5))\n    plt.subplots_adjust(hspace=0.7)\n    plt.subplots_adjust(wspace=0.5)\n\n    sns.set(style=\"darkgrid\")\n\n    for index ,column in enumerate( columns_list ):\n        order = accident_df[column].value_counts().iloc[:10].index\n\n        if nrows == 1:\n            g = sns.countplot(accident_df[column], alpha=0.9 ,  \n                         order= order,\n                         ax=axs[ index ])\n        else:\n            g = sns.countplot(accident_df[column], alpha=0.9 ,  \n                         order= order,\n                         ax=axs[ int(index / ncols) ][ int(index % ncols) ])\n            \n        g.set_xticklabels(rotation=60, labels = order )\n        g.set_title(column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Location</h3>\n<p>This part will look at the distribution of the following variables: <i>'City', 'County', 'State' , 'Zipcode' , 'Country' , 'street_name_num' </i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_list = ['City', 'County', 'State' , 'Zipcode' , 'Country' , 'street_name_num' ]\ncreate_plots(columns_list, ncols=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This six figures above shows that: \n* California has the most accidents among all states followed by Texas and Florida\n* Los Angeles in California is the most county with accident followed by Harris in Texas\n* Interestingly, Charlotte in NC appears as the second most city that has accident while North Carolina is the fourth when looking at the states in general.\n* Zip code is just another refliection of counties figure with Los Angelos has the highest\n* Country variables is not useful it may be dropped later since it only has one value (US).\n* Top 10 streets shows that most accidents occur on highways not local streets which make sense"},{"metadata":{},"cell_type":"markdown","source":"<h3>Time</h3>"},{"metadata":{},"cell_type":"markdown","source":"<p>This part will look at the distribution of the following variables: <i>'Timezone' , 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight' </i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_list = ['Timezone' , 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\ncreate_plots(columns_list,ncols=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the five figures above most accidents happens on the day time. So all of these varaibles can be reduced to one variable. The US/Eastern time has more values suggesting that states with Eastern time has more accidents in total compared to other states with other time zones."},{"metadata":{},"cell_type":"markdown","source":"<h3>Driving Conditions</h3>\nThis part will look at the following variables: <i>'Airport_Code', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Side', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop' </i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_list = ['Airport_Code', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Side', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', \n                'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop'] \ncreate_plots(columns_list,ncols=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The previous figures shows the presence of some specific road conditions. \n* Most recorded accidents has False (no presence) values for the conditions. \n* Turning_Loop can be dropped since its always has False value\n<p>Since this notebook for univariate analysis nothing can be tell about there relation with severity level or which objects correlate with each other. I will consider this relations in the next round of analysis </p>\n\n"},{"metadata":{},"cell_type":"markdown","source":"<h3>Accidents</h3>\nAccident severity and source is the last two categorical varaibles will be visisted in this notebook. "},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_list = ['Severity' , 'Source']\ncreate_plots(columns_list, ncols=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This shows that most accidents have severity level of 2, and MapQuest is the main accident source"},{"metadata":{},"cell_type":"markdown","source":"<h1>Numerical Variables</h1>\n<p>A numerical variable is a variable where the measurement or number has a numerical meaning. [2]\nThe following varaibles are numerical variables: <i>Distance(mi), Temperature(F), Wind_Chill(F), Humidity(%), Pressure(in), Visibility(mi), Wind_Speed(mph), Precipitation(in) </i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import describe\n\nsns.set(color_codes=True)\n\nfor column_name in ['Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)']:\n\n    mean = accident_df[column_name].mean()\n    std = accident_df[column_name].std()\n    min_ = accident_df[column_name].min()\n    max_ = accident_df[column_name].max()\n    kurt = accident_df[column_name].kurt()\n    skew = accident_df[column_name].skew()\n\n    print( column_name, ',min =' , min_ , ',max =' , max_ , ',avg =' , mean , ',std =' , std, ',skewness =' , skew, ',kurtosis =' , kurt , end='\\n')\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)' should follow a nomral distribution while the other variables have high skewness and kurtosis that means there values are centered around the mean values. See the example below of distribution plot for 'Precipitation(in)' and 'emperature(F)'"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(nrows=1 , ncols=2, figsize= (10,5))\n\nsns.distplot(  accident_df[  accident_df['Precipitation(in)'].isnull() == False ]['Precipitation(in)'] , ax=axs[ 0 ])\nsns.distplot(  accident_df[  accident_df['Temperature(F)'].isnull() == False ]['Temperature(F)'] , ax=axs[ 1 ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Wrap Up</h3>\n<p>This notebook presents a univariate analysis for the US Accidents dataset. While interesting take away will not be feasabile with univariate analysis but it should be the start for initial data analysis. The next notebook will look into more mulivariate analysis and corelation. </p>\n<p>For anay suggestions, edits, or questions leave it in the comment below</p>"},{"metadata":{},"cell_type":"markdown","source":"> "},{"metadata":{},"cell_type":"markdown","source":"<h3>References</h3>\n<li>[1] https://stattrek.com/statistics/dictionary.aspx?definition=categorical%20variable</li>\n<li>[2] https://socratic.org/questions/what-is-a-numerical-variable-and-what-is-a-categorical-variable</li>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}