digraph { 
"print[0]" -> "matplotlib: {}(0)" [label = "print"]
"print[1]" -> "matplotlib(0)" [label = "print"]
"print[0]" -> "scipy: {}(0)" [label = "print"]
"print[1]" -> "scipy(0)" [label = "print"]
"print[0]" -> "seaborn: {}(0)" [label = "print"]
"print[1]" -> "sns(0)" [label = "print"]
"print[0]" -> "pandas: {}(0)" [label = "print"]
"print[1]" -> "pd(0)" [label = "print"]
"print[0]" -> "numpy: {}(0)" [label = "print"]
"print[1]" -> "np(0)" [label = "print"]
"print[0]" -> "Python: {}(0)" [label = "print"]
"print[1]" -> "sys(0)" [label = "print"]
"sns(0)$0" -> "sns(0)" [label = "set"]
"warnings(0)$0" -> "warnings(0)" [label = "filterwarnings"]
"warnings(0)$0" -> "ignore(0)" [label = "filterwarnings"]
"sns(0)$1" -> "sns(0)$0" [label = "set_style"]
"sns(0)$1" -> "white(0)" [label = "set_style"]
"print[0]" -> "os(0)" [label = "print"]
"print[1]" -> "../input/(0)" [label = "print"]
"gendered_pronoun_df(0)$0" -> "pd(0)" [label = "read_csv"]
"gendered_pronoun_df(0)$0" -> "../input/test_stage_1.tsv(0)" [label = "read_csv"]
"gendered_pronoun_df(0)$0" -> "	(0)" [label = "read_csv"]
"submission(0)$0" -> "pd(0)" [label = "read_csv"]
"submission(0)$0" -> "../input/sample_submission_stage_1.csv(0)" [label = "read_csv"]
"gendered_pronoun_df(0)$1" -> "gendered_pronoun_df(0)$0" [label = "head"]
"gendered_pronoun_df(0)$2" -> "gendered_pronoun_df(0)$1" [label = "info"]
"print[0]" -> "gendered_pronoun_df(0)$2" [label = "print"]
"print[0]" -> "Shape of train set : (0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$2" [label = "print"]
"df(1)" -> "check_missing_data[0]" [label = "_argToVar"]
"flag(1)$0" -> "df(1)" [label = "any"]
"total(1)$0" -> "df(1)" [label = "sum"]
"percent(1)$0" -> "df(1)" [label = "Div"]
"percent(1)$0" -> "df(1)" [label = "Div"]
"percent(1)$0" -> "100(1)" [label = "Div"]
"output(1)$0" -> "pd(1)" [label = "concat"]
"output(1)$0" -> "[<_ast.Name object at 0x103283dd0>, <_ast.Name object at 0x103283890>](1)" [label = "concat"]
"output(1)$0" -> "1(1)" [label = "concat"]
"output(1)$0" -> "[<_ast.Str object at 0x103283a50>, <_ast.Str object at 0x1032832d0>](1)" [label = "concat"]
"data_type(1)$0" -> "[](1)" [label = "eq"]
"col(1)" -> "df(1)" [label = "Iter"]
"dtype(1)$0" -> "df(1)" [label = "str"]
"dtype(1)$0" -> "col(1)" [label = "str"]
"data_type(1)$1" -> "data_type(1)$0" [label = "append"]
"data_type(1)$1" -> "dtype(1)$0" [label = "append"]
"output(1)$1" -> "output(1)$0" [label = "eq"]
"output(1)$1" -> "data_type(1)$1" [label = "eq"]
"check_missing_data[0]" -> "gendered_pronoun_df(0)$2" [label = "check_missing_data"]
"gendered_pronoun_df(0)$3" -> "gendered_pronoun_df(0)$2" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "gendered_pronoun_df(0)$2" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "x(0)" [label = "apply"]
"print[0]" -> "maximum of num_words in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$3" [label = "print"]
"print[2]" -> "num_words(0)" [label = "print"]
"print[0]" -> "min of num_words in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$3" [label = "print"]
"print[2]" -> "num_words(0)" [label = "print"]
"gendered_pronoun_df(0)$4" -> "gendered_pronoun_df(0)$3" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "gendered_pronoun_df(0)$3" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "set(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "x(0)" [label = "apply"]
"print[0]" -> "maximum of num_unique_words in train(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$4" [label = "print"]
"print[2]" -> "num_unique_words(0)" [label = "print"]
"print[0]" -> "mean of num_unique_words in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$4" [label = "print"]
"print[2]" -> "num_unique_words(0)" [label = "print"]
"gendered_pronoun_df(0)$5" -> "gendered_pronoun_df(0)$4" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "gendered_pronoun_df(0)$4" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "x(0)" [label = "apply"]
"print[0]" -> "maximum of num_chars in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$5" [label = "print"]
"print[2]" -> "num_chars(0)" [label = "print"]
"eng_stopwords(0)$0" -> "stopwords(0)" [label = "set"]
"eng_stopwords(0)$0" -> "english(0)" [label = "set"]
"gendered_pronoun_df(0)$6" -> "gendered_pronoun_df(0)$5" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "gendered_pronoun_df(0)$5" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "x(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "eng_stopwords(0)$0" [label = "apply"]
"print[0]" -> "maximum of num_stopwords in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$6" [label = "print"]
"print[2]" -> "num_stopwords(0)" [label = "print"]
"gendered_pronoun_df(0)$7" -> "gendered_pronoun_df(0)$6" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "gendered_pronoun_df(0)$6" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "c(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "c(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "x(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "c(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "string(0)" [label = "apply"]
"print[0]" -> "maximum of num_punctuations in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$7" [label = "print"]
"print[2]" -> "num_punctuations(0)" [label = "print"]
"gendered_pronoun_df(0)$8" -> "gendered_pronoun_df(0)$7" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "gendered_pronoun_df(0)$7" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "x(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "w(0)" [label = "apply"]
"print[0]" -> "maximum of num_words_upper in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$8" [label = "print"]
"print[2]" -> "num_words_upper(0)" [label = "print"]
"print[0]" -> "gendered_pronoun_df(0)$8" [label = "print"]
"gendered_pronoun_df(0)$9" -> "gendered_pronoun_df(0)$8" [label = "head"]
"gendered_pronoun_df(0)$9" -> "1(0)" [label = "head"]
"pronoun(0)$0" -> "gendered_pronoun_df(0)$9" [label = "eq"]
"pronoun(0)$0" -> "Pronoun(0)" [label = "eq"]
"np(0)$0" -> "np(0)" [label = "unique"]
"np(0)$0" -> "pronoun(0)$0" [label = "unique"]
"binary(0)$0" -> "He(0)" [label = "eq"]
"binary(0)$0" -> "he(0)" [label = "eq"]
"binary(0)$0" -> "She(0)" [label = "eq"]
"binary(0)$0" -> "she(0)" [label = "eq"]
"binary(0)$0" -> "His(0)" [label = "eq"]
"binary(0)$0" -> "his(0)" [label = "eq"]
"binary(0)$0" -> "Him(0)" [label = "eq"]
"binary(0)$0" -> "him(0)" [label = "eq"]
"binary(0)$0" -> "Her(0)" [label = "eq"]
"binary(0)$0" -> "her(0)" [label = "eq"]
"binary(0)$0" -> "0(0)" [label = "eq"]
"binary(0)$0" -> "0(0)" [label = "eq"]
"binary(0)$0" -> "1(0)" [label = "eq"]
"binary(0)$0" -> "1(0)" [label = "eq"]
"binary(0)$0" -> "2(0)" [label = "eq"]
"binary(0)$0" -> "2(0)" [label = "eq"]
"binary(0)$0" -> "3(0)" [label = "eq"]
"binary(0)$0" -> "3(0)" [label = "eq"]
"binary(0)$0" -> "4(0)" [label = "eq"]
"binary(0)$0" -> "4(0)" [label = "eq"]
"index(0)" -> "range(0)" [label = "Iter"]
"index(0)" -> "len(0)" [label = "Iter"]
"index(0)" -> "gendered_pronoun_df(0)$9" [label = "Iter"]
"key(0)$0" -> "gendered_pronoun_df(0)$9" [label = "eq"]
"key(0)$0" -> "index(0)" [label = "eq"]
"key(0)$0" -> "Pronoun(0)" [label = "eq"]
"gendered_pronoun_df(0)$10" -> "gendered_pronoun_df(0)$9" [label = "eq"]
"gendered_pronoun_df(0)$10" -> "binary(0)$0" [label = "eq"]
"gendered_pronoun_df(0)$10" -> "key(0)$0" [label = "eq"]
"gendered_pronoun_df(0)$11" -> "gendered_pronoun_df(0)$10" [label = "head"]
"gendered_pronoun_df(0)$11" -> "30(0)" [label = "head"]
"text(2)" -> "generate_wordcloud[0]" [label = "_argToVar"]
"wordcloud(2)$0" -> "wc(2)" [label = "generate"]
"wordcloud(2)$0" -> "1.0(2)" [label = "generate"]
"wordcloud(2)$0" -> "eng_stopwords(2)" [label = "generate"]
"wordcloud(2)$0" -> "text(2)" [label = "generate"]
"fig(2)$0" -> "plt(2)" [label = "subplots"]
"ax(2)$0" -> "plt(2)" [label = "subplots"]
"fig(2)$0" -> "1(2)" [label = "subplots"]
"ax(2)$0" -> "1(2)" [label = "subplots"]
"fig(2)$0" -> "1(2)" [label = "subplots"]
"ax(2)$0" -> "1(2)" [label = "subplots"]
"fig(2)$0" -> "10(2)" [label = "subplots"]
"ax(2)$0" -> "10(2)" [label = "subplots"]
"fig(2)$0" -> "10(2)" [label = "subplots"]
"ax(2)$0" -> "10(2)" [label = "subplots"]
"ax(2)$1" -> "ax(2)$0" [label = "imshow"]
"ax(2)$1" -> "wordcloud(2)$0" [label = "imshow"]
"ax(2)$2" -> "ax(2)$1" [label = "axis"]
"ax(2)$2" -> "off(2)" [label = "axis"]
"ax(2)$3" -> "ax(2)$2" [label = "margins"]
"plt(2)$0" -> "plt(2)" [label = "show"]
"eng_stopwords(0)$1" -> "stopwords(0)" [label = "set"]
"eng_stopwords(0)$1" -> "english(0)" [label = "set"]
"text(0)$0" -> " (0)" [label = "join"]
"text(0)$0" -> "gendered_pronoun_df(0)$11" [label = "join"]
"generate_wordcloud[0]" -> "text(0)$0" [label = "generate_wordcloud"]
"gendered_pronoun_df(0)$12" -> "gendered_pronoun_df(0)$11" [label = "hist"]
"pd(0)$0" -> "pd(0)" [label = "scatter_matrix"]
"pd(0)$0" -> "gendered_pronoun_df(0)$12" [label = "scatter_matrix"]
"plt(0)$0" -> "plt(0)" [label = "figure"]
"sns(0)$2" -> "sns(0)$1" [label = "jointplot"]
"sns(0)$3" -> "sns(0)$2" [label = "swarmplot"]
"sns(0)$4" -> "sns(0)$3" [label = "distplot"]
"sns(0)$4" -> "gendered_pronoun_df(0)$12" [label = "distplot"]
"sns(0)$4" -> "Pronoun-offset(0)" [label = "distplot"]
"sns(0)$5" -> "sns(0)$4" [label = "violinplot"]
"our_text(0)$0" -> "gendered_pronoun_df(0)$12" [label = "eq"]
"our_text(0)$0" -> "0(0)" [label = "eq"]
"print[0]" -> "word_tokenize(0)" [label = "print"]
"print[1]" -> "our_text(0)$0" [label = "print"]
"print[0]" -> "sent_tokenize(0)" [label = "print"]
"print[1]" -> "our_text(0)$0" [label = "print"]
"phrases(0)$0" -> "our_text(0)$0" [label = "sent_tokenize"]
"words(0)$0" -> "our_text(0)$0" [label = "word_tokenize"]
"print[0]" -> "phrases(0)$0" [label = "print"]
"print[0]" -> "words(0)$0" [label = "print"]
"type[0]" -> "words(0)$0" [label = "type"]
"stopWords(0)$0" -> "stopwords(0)" [label = "set"]
"stopWords(0)$0" -> "english(0)" [label = "set"]
"words(0)$1" -> "our_text(0)$0" [label = "word_tokenize"]
"wordsFiltered(0)$0" -> "[](0)" [label = "eq"]
"w(0)" -> "words(0)$1" [label = "Iter"]
"wordsFiltered(0)$1" -> "wordsFiltered(0)$0" [label = "append"]
"wordsFiltered(0)$1" -> "w(0)" [label = "append"]
"print[0]" -> "wordsFiltered(0)$1" [label = "print"]
"stopWords(0)$1" -> "stopwords(0)" [label = "set"]
"stopWords(0)$1" -> "english(0)" [label = "set"]
"print[0]" -> "len(0)" [label = "print"]
"print[1]" -> "stopWords(0)$1" [label = "print"]
"print[0]" -> "stopWords(0)$1" [label = "print"]
"w(0)" -> "words(0)$1" [label = "Iter"]
"wordsFiltered(0)$2" -> "wordsFiltered(0)$1" [label = "append"]
"wordsFiltered(0)$2" -> "w(0)" [label = "append"]
"our_text(0)$1" -> "gendered_pronoun_df(0)$12" [label = "eq"]
"our_text(0)$1" -> "0(0)" [label = "eq"]
"word(0)" -> "word_tokenize(0)" [label = "Iter"]
"word(0)" -> "our_text(0)$1" [label = "Iter"]
"print[0]" -> "ps(0)" [label = "print"]
"print[1]" -> "word(0)" [label = "print"]
"sentences(0)$0" -> "nltk(0)" [label = "sent_tokenize"]
"sentences(0)$0" -> "our_text(0)$1" [label = "sent_tokenize"]
"sent(0)" -> "sentences(0)$0" [label = "Iter"]
"print[0]" -> "nltk(0)" [label = "print"]
"print[1]" -> "nltk(0)" [label = "print"]
"print[2]" -> "sent(0)" [label = "print"]
"sentences(0)$1" -> "nltk(0)" [label = "sent_tokenize"]
"sentences(0)$1" -> "our_text(0)$1" [label = "sent_tokenize"]
"data(0)$0" -> "[](0)" [label = "eq"]
"sent(0)" -> "sentences(0)$1" [label = "Iter"]
"data(0)$1" -> "data(0)$0" [label = "Add"]
"data(0)$1" -> "nltk(0)" [label = "Add"]
"data(0)$1" -> "nltk(0)" [label = "Add"]
"data(0)$1" -> "sent(0)" [label = "Add"]
"word(0)" -> "data(0)$1" [label = "Iter"]
"print[0]" -> "word(0)" [label = "print"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "male(0)" [label = "Add"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "names(0)$0" [label = "Add"]
"names(0)$0" -> "male.txt(0)" [label = "Add"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "female(0)" [label = "Add"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "names(0)$0" [label = "Add"]
"names(0)$0" -> "female.txt(0)" [label = "Add"]
"word(3)" -> "gender_features[0]" [label = "_argToVar"]
"word(4)" -> "gender_features[0]" [label = "_argToVar"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "male(0)" [label = "Add"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "names(0)$1" [label = "Add"]
"names(0)$1" -> "male.txt(0)" [label = "Add"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "female(0)" [label = "Add"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "names(0)$1" [label = "Add"]
"names(0)$1" -> "female.txt(0)" [label = "Add"]
"featuresets(0)$0" -> "gender_features(0)" [label = "eq"]
"featuresets(0)$0" -> "n(0)" [label = "eq"]
"featuresets(0)$0" -> "g(0)" [label = "eq"]
"featuresets(0)$0" -> "n(0)" [label = "eq"]
"featuresets(0)$0" -> "g(0)" [label = "eq"]
"featuresets(0)$0" -> "names(0)$1" [label = "eq"]
"train_set(0)$0" -> "featuresets(0)$0" [label = "eq"]
"classifier(0)$0" -> "nltk(0)" [label = "train"]
"classifier(0)$0" -> "train_set(0)$0" [label = "train"]
"print[0]" -> "classifier(0)$0" [label = "print"]
"print[1]" -> "gender_features(0)" [label = "print"]
"print[2]" -> "Frank(0)" [label = "print"]
"name(0)$0" -> "Sarah(0)" [label = "eq"]
"print[0]" -> "classifier(0)$0" [label = "print"]
"print[1]" -> "gender_features(0)" [label = "print"]
"print[2]" -> "name(0)$0" [label = "print"]
"positive_vocab(0)$0" -> "[<_ast.Str object at 0x10321ffd0>, <_ast.Str object at 0x10321f390>, <_ast.Str object at 0x10321f8d0>, <_ast.Str object at 0x10321f750>, <_ast.Str object at 0x10321f4d0>, <_ast.Str object at 0x10321ff90>, <_ast.Str object at 0x10321f510>, <_ast.Str object at 0x10321f110>](0)" [label = "eq"]
"negative_vocab(0)$0" -> "[<_ast.Str object at 0x10321f410>, <_ast.Str object at 0x10321fa50>, <_ast.Str object at 0x10321fc90>, <_ast.Str object at 0x10321f890>, <_ast.Str object at 0x10321fd10>](0)" [label = "eq"]
"neutral_vocab(0)$0" -> "[<_ast.Str object at 0x10321fb50>, <_ast.Str object at 0x10321f210>, <_ast.Str object at 0x10321f090>, <_ast.Str object at 0x10321fe90>, <_ast.Str object at 0x10321fa10>, <_ast.Str object at 0x10321fad0>, <_ast.Str object at 0x10321fd90>, <_ast.Str object at 0x10321f950>, <_ast.Str object at 0x10321fb90>, <_ast.Str object at 0x10321fcd0>](0)" [label = "eq"]
"words(5)" -> "word_feats[0]" [label = "_argToVar"]
"positive_features(0)$0" -> "word_feats(0)" [label = "eq"]
"positive_features(0)$0" -> "pos(0)" [label = "eq"]
"positive_features(0)$0" -> "pos(0)" [label = "eq"]
"positive_features(0)$0" -> "pos(0)" [label = "eq"]
"positive_features(0)$0" -> "positive_vocab(0)$0" [label = "eq"]
"negative_features(0)$0" -> "word_feats(0)" [label = "eq"]
"negative_features(0)$0" -> "neg(0)" [label = "eq"]
"negative_features(0)$0" -> "neg(0)" [label = "eq"]
"negative_features(0)$0" -> "neg(0)" [label = "eq"]
"negative_features(0)$0" -> "negative_vocab(0)$0" [label = "eq"]
"neutral_features(0)$0" -> "word_feats(0)" [label = "eq"]
"neutral_features(0)$0" -> "neu(0)" [label = "eq"]
"neutral_features(0)$0" -> "neu(0)" [label = "eq"]
"neutral_features(0)$0" -> "neu(0)" [label = "eq"]
"neutral_features(0)$0" -> "neutral_vocab(0)$0" [label = "eq"]
"train_set(0)$1" -> "negative_features(0)$0" [label = "Add"]
"train_set(0)$1" -> "positive_features(0)$0" [label = "Add"]
"train_set(0)$1" -> "neutral_features(0)$0" [label = "Add"]
"words(6)" -> "word_feats[0]" [label = "_argToVar"]
"positive_vocab(0)$1" -> "[<_ast.Str object at 0x1033661d0>, <_ast.Str object at 0x103366690>, <_ast.Str object at 0x103366f90>, <_ast.Str object at 0x103366190>, <_ast.Str object at 0x103366fd0>, <_ast.Str object at 0x103366c10>, <_ast.Str object at 0x10320e290>, <_ast.Str object at 0x10320e590>](0)" [label = "eq"]
"negative_vocab(0)$1" -> "[<_ast.Str object at 0x10320efd0>, <_ast.Str object at 0x10320eb50>, <_ast.Str object at 0x10320e0d0>, <_ast.Str object at 0x10320ef10>, <_ast.Str object at 0x10320e410>](0)" [label = "eq"]
"neutral_vocab(0)$1" -> "[<_ast.Str object at 0x10320e650>, <_ast.Str object at 0x10320e4d0>, <_ast.Str object at 0x10320ec90>, <_ast.Str object at 0x10320ea10>, <_ast.Str object at 0x10320e6d0>, <_ast.Str object at 0x10320e850>, <_ast.Str object at 0x10320eed0>, <_ast.Str object at 0x10320e3d0>, <_ast.Str object at 0x10320e950>, <_ast.Str object at 0x10320e690>](0)" [label = "eq"]
"positive_features(0)$1" -> "word_feats(0)" [label = "eq"]
"positive_features(0)$1" -> "pos(0)" [label = "eq"]
"positive_features(0)$1" -> "pos(0)" [label = "eq"]
"positive_features(0)$1" -> "pos(0)" [label = "eq"]
"positive_features(0)$1" -> "positive_vocab(0)$1" [label = "eq"]
"negative_features(0)$1" -> "word_feats(0)" [label = "eq"]
"negative_features(0)$1" -> "neg(0)" [label = "eq"]
"negative_features(0)$1" -> "neg(0)" [label = "eq"]
"negative_features(0)$1" -> "neg(0)" [label = "eq"]
"negative_features(0)$1" -> "negative_vocab(0)$1" [label = "eq"]
"neutral_features(0)$1" -> "word_feats(0)" [label = "eq"]
"neutral_features(0)$1" -> "neu(0)" [label = "eq"]
"neutral_features(0)$1" -> "neu(0)" [label = "eq"]
"neutral_features(0)$1" -> "neu(0)" [label = "eq"]
"neutral_features(0)$1" -> "neutral_vocab(0)$1" [label = "eq"]
"train_set(0)$2" -> "negative_features(0)$1" [label = "Add"]
"train_set(0)$2" -> "positive_features(0)$1" [label = "Add"]
"train_set(0)$2" -> "neutral_features(0)$1" [label = "Add"]
"classifier(0)$1" -> "NaiveBayesClassifier(0)" [label = "train"]
"classifier(0)$1" -> "train_set(0)$2" [label = "train"]
"neg(0)$0" -> "0(0)" [label = "eq"]
"pos(0)$0" -> "0(0)" [label = "eq"]
"our_text(0)$2" -> "our_text(0)$1" [label = "lower"]
"words(0)$2" -> "our_text(0)$2" [label = "split"]
"words(0)$2" -> " (0)" [label = "split"]
"word(0)" -> "words(0)$2" [label = "Iter"]
"classResult(0)$0" -> "classifier(0)$1" [label = "classify"]
"classResult(0)$0" -> "word_feats(0)" [label = "classify"]
"classResult(0)$0" -> "word(0)" [label = "classify"]
"neg(0)$1" -> "neg(0)$0" [label = "Add"]
"neg(0)$1" -> "1(0)" [label = "Add"]
"pos(0)$1" -> "pos(0)$0" [label = "Add"]
"pos(0)$1" -> "1(0)" [label = "Add"]
"print[0]" -> "Positive: (0)" [label = "print"]
"print[1]" -> "str(0)" [label = "print"]
"print[2]" -> "float(0)" [label = "print"]
"print[3]" -> "pos(0)$1" [label = "print"]
"print[4]" -> "len(0)" [label = "print"]
"print[5]" -> "words(0)$2" [label = "print"]
"print[0]" -> "Negative: (0)" [label = "print"]
"print[1]" -> "str(0)" [label = "print"]
"print[2]" -> "float(0)" [label = "print"]
"print[3]" -> "neg(0)$1" [label = "print"]
"print[4]" -> "len(0)" [label = "print"]
"print[5]" -> "words(0)$2" [label = "print"]
"nlp(0)$0" -> "spacy(0)" [label = "load"]
"nlp(0)$0" -> "en(0)" [label = "load"]
"doc(0)$0" -> "our_text(0)$2" [label = "nlp"]
"i(0)$0" -> "0(0)" [label = "eq"]
"token(0)" -> "doc(0)$0" [label = "Iter"]
"i(0)$1" -> "i(0)$0" [label = "Add"]
"i(0)$1" -> "1(0)" [label = "Add"]
"print[0]" -> ""(0)" [label = "print"]
"print[1]" -> "token(0)" [label = "print"]
"print[2]" -> ""(0)" [label = "print"]
"nlp(0)$1" -> "spacy(0)" [label = "load"]
"nlp(0)$1" -> "en(0)" [label = "load"]
"doc(0)$1" -> "our_text(0)$2" [label = "nlp"]
"i(0)$2" -> "0(0)" [label = "eq"]
"sent(0)" -> "doc(0)$1" [label = "Iter"]
"i(0)$3" -> "i(0)$2" [label = "Add"]
"i(0)$3" -> "1(0)" [label = "Add"]
"print[0]" -> "i(0)$3" [label = "print"]
"print[1]" -> " - (0)" [label = "print"]
"print[2]" -> "sent(0)" [label = "print"]
"doc(0)$2" -> "our_text(0)$2" [label = "nlp"]
"print[0]" -> "token(0)" [label = "print"]
"print[1]" -> "token(0)" [label = "print"]
"print[2]" -> "token(0)" [label = "print"]
"print[3]" -> "doc(0)$2" [label = "print"]
"doc(0)$3" -> "our_text(0)$2" [label = "nlp"]
"ent(0)" -> "doc(0)$3" [label = "Iter"]
"print[0]" -> "ent(0)" [label = "print"]
"print[1]" -> "ent(0)" [label = "print"]
"doc(0)$4" -> "our_text(0)$2" [label = "nlp"]
"displacy(0)$0" -> "displacy(0)" [label = "render"]
"displacy(0)$0" -> "doc(0)$4" [label = "render"]
"doc(0)$5" -> "our_text(0)$2" [label = "nlp"]
"displacy(0)$1" -> "displacy(0)$0" [label = "render"]
"displacy(0)$1" -> "doc(0)$5" [label = "render"]
"documents(0)$0" -> "[<_ast.Str object at 0x1031f5c10>, <_ast.Str object at 0x1031f5890>, <_ast.Str object at 0x1031f53d0>, <_ast.Str object at 0x1031f5990>, <_ast.Str object at 0x1031f5110>](0)" [label = "eq"]
"documents_2(0)$0" -> "[<_ast.Str object at 0x1031f5510>, <_ast.Str object at 0x1031f55d0>, <_ast.Str object at 0x1031f5090>, <_ast.Str object at 0x103277ad0>, <_ast.Str object at 0x1032770d0>, <_ast.Str object at 0x103277f90>](0)" [label = "eq"]
"texts(0)$0" -> "text(0)$0" [label = "eq"]
"texts(0)$0" -> "text(0)$0" [label = "eq"]
"texts(0)$0" -> "doc(0)$5" [label = "eq"]
"texts(0)$0" -> "doc(0)$5" [label = "eq"]
"texts(0)$0" -> "documents(0)$0" [label = "eq"]
"dictionary(0)$0" -> "corpora(0)" [label = "Dictionary"]
"dictionary(0)$0" -> "texts(0)$0" [label = "Dictionary"]
"print[0]" -> "dictionary(0)$0" [label = "print"]
"print[0]" -> "dictionary(0)$0" [label = "print"]
}