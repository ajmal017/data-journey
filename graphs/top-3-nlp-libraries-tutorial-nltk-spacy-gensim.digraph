digraph { 
"print[0]" -> "matplotlib: {}(0)" [label = "print"]
"print[1]" -> "matplotlib(0)" [label = "print"]
"print[0]" -> "scipy: {}(0)" [label = "print"]
"print[1]" -> "scipy(0)" [label = "print"]
"print[0]" -> "seaborn: {}(0)" [label = "print"]
"print[1]" -> "sns(0)" [label = "print"]
"print[0]" -> "pandas: {}(0)" [label = "print"]
"print[1]" -> "pd(0)" [label = "print"]
"print[0]" -> "numpy: {}(0)" [label = "print"]
"print[1]" -> "np(0)" [label = "print"]
"print[0]" -> "Python: {}(0)" [label = "print"]
"print[1]" -> "sys(0)" [label = "print"]
"sns(0)$0" -> "sns(0)" [label = "set"]
"warnings(0)$0" -> "warnings(0)" [label = "filterwarnings"]
"warnings(0)$0" -> "ignore(0)" [label = "filterwarnings"]
"sns(0)$1" -> "sns(0)$0" [label = "set_style"]
"sns(0)$1" -> "white(0)" [label = "set_style"]
"print[0]" -> "os(0)" [label = "print"]
"print[1]" -> "../input/(0)" [label = "print"]
"gendered_pronoun_df(0)$0" -> "pd(0)" [label = "read_csv"]
"gendered_pronoun_df(0)$0" -> "../input/test_stage_1.tsv(0)" [label = "read_csv"]
"gendered_pronoun_df(0)$0" -> "	(0)" [label = "read_csv"]
"submission(0)$0" -> "pd(0)" [label = "read_csv"]
"submission(0)$0" -> "../input/sample_submission_stage_1.csv(0)" [label = "read_csv"]
"gendered_pronoun_df(0)$1" -> "gendered_pronoun_df(0)$0" [label = "head"]
"gendered_pronoun_df(0)$2" -> "gendered_pronoun_df(0)$1" [label = "info"]
"print[0]" -> "gendered_pronoun_df(0)$2" [label = "print"]
"print[0]" -> "Shape of train set : (0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$2" [label = "print"]
"df(1)" -> "check_missing_data[0]" [label = "_argToVar"]
"flag(1)$0" -> "df(1)" [label = "any"]
"total(1)$0" -> "df(1)" [label = "sum"]
"percent(1)$0" -> "df(1)" [label = "Div"]
"percent(1)$0" -> "df(1)" [label = "Div"]
"percent(1)$0" -> "100(1)" [label = "Div"]
"output(1)$0" -> "pd(1)" [label = "concat"]
"output(1)$0" -> "[<_ast.Name object at 0x10a3c8c50>, <_ast.Name object at 0x10a3c8590>](1)" [label = "concat"]
"output(1)$0" -> "1(1)" [label = "concat"]
"output(1)$0" -> "[<_ast.Str object at 0x10a3c8990>, <_ast.Str object at 0x10a3c87d0>](1)" [label = "concat"]
"data_type(1)$0" -> "[](1)" [label = "eq"]
"col(1)" -> "df(1)" [label = "Iter"]
"dtype(1)$0" -> "df(1)" [label = "str"]
"dtype(1)$0" -> "col(1)" [label = "str"]
"data_type(1)$1" -> "data_type(1)$0" [label = "append"]
"data_type(1)$1" -> "dtype(1)$0" [label = "append"]
"output(1)$1" -> "output(1)$0" [label = "eq"]
"output(1)$1" -> "data_type(1)$1" [label = "eq"]
"check_missing_data[0]" -> "gendered_pronoun_df(0)$2" [label = "check_missing_data"]
"gendered_pronoun_df(0)$3" -> "gendered_pronoun_df(0)$2" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "gendered_pronoun_df(0)$2" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$3" -> "x(0)" [label = "apply"]
"print[0]" -> "maximum of num_words in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$3" [label = "print"]
"print[2]" -> "num_words(0)" [label = "print"]
"print[0]" -> "min of num_words in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$3" [label = "print"]
"print[2]" -> "num_words(0)" [label = "print"]
"gendered_pronoun_df(0)$4" -> "gendered_pronoun_df(0)$3" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "gendered_pronoun_df(0)$3" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "set(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$4" -> "x(0)" [label = "apply"]
"print[0]" -> "maximum of num_unique_words in train(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$4" [label = "print"]
"print[2]" -> "num_unique_words(0)" [label = "print"]
"print[0]" -> "mean of num_unique_words in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$4" [label = "print"]
"print[2]" -> "num_unique_words(0)" [label = "print"]
"gendered_pronoun_df(0)$5" -> "gendered_pronoun_df(0)$4" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "gendered_pronoun_df(0)$4" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$5" -> "x(0)" [label = "apply"]
"print[0]" -> "maximum of num_chars in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$5" [label = "print"]
"print[2]" -> "num_chars(0)" [label = "print"]
"eng_stopwords(0)$0" -> "stopwords(0)" [label = "set"]
"eng_stopwords(0)$0" -> "english(0)" [label = "set"]
"gendered_pronoun_df(0)$6" -> "gendered_pronoun_df(0)$5" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "gendered_pronoun_df(0)$5" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "x(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$6" -> "eng_stopwords(0)$0" [label = "apply"]
"print[0]" -> "maximum of num_stopwords in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$6" [label = "print"]
"print[2]" -> "num_stopwords(0)" [label = "print"]
"gendered_pronoun_df(0)$7" -> "gendered_pronoun_df(0)$6" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "gendered_pronoun_df(0)$6" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "c(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "c(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "x(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "c(0)" [label = "apply"]
"gendered_pronoun_df(0)$7" -> "string(0)" [label = "apply"]
"print[0]" -> "maximum of num_punctuations in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$7" [label = "print"]
"print[2]" -> "num_punctuations(0)" [label = "print"]
"gendered_pronoun_df(0)$8" -> "gendered_pronoun_df(0)$7" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "gendered_pronoun_df(0)$7" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "Text(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "len(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "w(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "str(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "x(0)" [label = "apply"]
"gendered_pronoun_df(0)$8" -> "w(0)" [label = "apply"]
"print[0]" -> "maximum of num_words_upper in data_df(0)" [label = "print"]
"print[1]" -> "gendered_pronoun_df(0)$8" [label = "print"]
"print[2]" -> "num_words_upper(0)" [label = "print"]
"print[0]" -> "gendered_pronoun_df(0)$8" [label = "print"]
"gendered_pronoun_df(0)$9" -> "gendered_pronoun_df(0)$8" [label = "head"]
"gendered_pronoun_df(0)$9" -> "1(0)" [label = "head"]
"pronoun(0)$0" -> "gendered_pronoun_df(0)$9" [label = "eq"]
"pronoun(0)$0" -> "Pronoun(0)" [label = "eq"]
"np(0)$0" -> "np(0)" [label = "unique"]
"np(0)$0" -> "pronoun(0)$0" [label = "unique"]
"binary(0)$0" -> "He(0)" [label = "eq"]
"binary(0)$0" -> "he(0)" [label = "eq"]
"binary(0)$0" -> "She(0)" [label = "eq"]
"binary(0)$0" -> "she(0)" [label = "eq"]
"binary(0)$0" -> "His(0)" [label = "eq"]
"binary(0)$0" -> "his(0)" [label = "eq"]
"binary(0)$0" -> "Him(0)" [label = "eq"]
"binary(0)$0" -> "him(0)" [label = "eq"]
"binary(0)$0" -> "Her(0)" [label = "eq"]
"binary(0)$0" -> "her(0)" [label = "eq"]
"binary(0)$0" -> "0(0)" [label = "eq"]
"binary(0)$0" -> "0(0)" [label = "eq"]
"binary(0)$0" -> "1(0)" [label = "eq"]
"binary(0)$0" -> "1(0)" [label = "eq"]
"binary(0)$0" -> "2(0)" [label = "eq"]
"binary(0)$0" -> "2(0)" [label = "eq"]
"binary(0)$0" -> "3(0)" [label = "eq"]
"binary(0)$0" -> "3(0)" [label = "eq"]
"binary(0)$0" -> "4(0)" [label = "eq"]
"binary(0)$0" -> "4(0)" [label = "eq"]
"index(0)" -> "range(0)" [label = "Iter"]
"index(0)" -> "len(0)" [label = "Iter"]
"index(0)" -> "gendered_pronoun_df(0)$9" [label = "Iter"]
"key(0)$0" -> "gendered_pronoun_df(0)$9" [label = "eq"]
"key(0)$0" -> "index(0)" [label = "eq"]
"key(0)$0" -> "Pronoun(0)" [label = "eq"]
"gendered_pronoun_df(0)$10" -> "gendered_pronoun_df(0)$9" [label = "eq"]
"gendered_pronoun_df(0)$10" -> "binary(0)$0" [label = "eq"]
"gendered_pronoun_df(0)$10" -> "key(0)$0" [label = "eq"]
"gendered_pronoun_df(0)$11" -> "gendered_pronoun_df(0)$10" [label = "head"]
"gendered_pronoun_df(0)$11" -> "30(0)" [label = "head"]
"text(2)" -> "generate_wordcloud[0]" [label = "_argToVar"]
"wordcloud(2)$0" -> "wc(2)" [label = "generate"]
"wordcloud(2)$0" -> "1.0(2)" [label = "generate"]
"wordcloud(2)$0" -> "eng_stopwords(2)" [label = "generate"]
"wordcloud(2)$0" -> "text(2)" [label = "generate"]
"fig(2)$0" -> "plt(2)" [label = "subplots"]
"ax(2)$0" -> "plt(2)" [label = "subplots"]
"fig(2)$0" -> "1(2)" [label = "subplots"]
"ax(2)$0" -> "1(2)" [label = "subplots"]
"fig(2)$0" -> "1(2)" [label = "subplots"]
"ax(2)$0" -> "1(2)" [label = "subplots"]
"fig(2)$0" -> "10(2)" [label = "subplots"]
"ax(2)$0" -> "10(2)" [label = "subplots"]
"fig(2)$0" -> "10(2)" [label = "subplots"]
"ax(2)$0" -> "10(2)" [label = "subplots"]
"ax(2)$1" -> "ax(2)$0" [label = "imshow"]
"ax(2)$1" -> "wordcloud(2)$0" [label = "imshow"]
"ax(2)$2" -> "ax(2)$1" [label = "axis"]
"ax(2)$2" -> "off(2)" [label = "axis"]
"ax(2)$3" -> "ax(2)$2" [label = "margins"]
"plt(2)$0" -> "plt(2)" [label = "show"]
"eng_stopwords(0)$1" -> "stopwords(0)" [label = "set"]
"eng_stopwords(0)$1" -> "english(0)" [label = "set"]
"text(0)$0" -> " (0)" [label = "join"]
"text(0)$0" -> "gendered_pronoun_df(0)$11" [label = "join"]
"generate_wordcloud[0]" -> "text(0)$0" [label = "generate_wordcloud"]
"gendered_pronoun_df(0)$12" -> "gendered_pronoun_df(0)$11" [label = "hist"]
"pd(0)$0" -> "pd(0)" [label = "scatter_matrix"]
"pd(0)$0" -> "gendered_pronoun_df(0)$12" [label = "scatter_matrix"]
"plt(0)$0" -> "plt(0)" [label = "figure"]
"sns(0)$2" -> "sns(0)$1" [label = "jointplot"]
"sns(0)$3" -> "sns(0)$2" [label = "swarmplot"]
"sns(0)$4" -> "sns(0)$3" [label = "distplot"]
"sns(0)$4" -> "gendered_pronoun_df(0)$12" [label = "distplot"]
"sns(0)$4" -> "Pronoun-offset(0)" [label = "distplot"]
"sns(0)$5" -> "sns(0)$4" [label = "violinplot"]
"our_text(0)$0" -> "gendered_pronoun_df(0)$12" [label = "eq"]
"our_text(0)$0" -> "0(0)" [label = "eq"]
"print[0]" -> "word_tokenize(0)" [label = "print"]
"print[1]" -> "our_text(0)$0" [label = "print"]
"print[0]" -> "sent_tokenize(0)" [label = "print"]
"print[1]" -> "our_text(0)$0" [label = "print"]
"phrases(0)$0" -> "our_text(0)$0" [label = "sent_tokenize"]
"words(0)$0" -> "our_text(0)$0" [label = "word_tokenize"]
"print[0]" -> "phrases(0)$0" [label = "print"]
"print[0]" -> "words(0)$0" [label = "print"]
"type[0]" -> "words(0)$0" [label = "type"]
"stopWords(0)$0" -> "stopwords(0)" [label = "set"]
"stopWords(0)$0" -> "english(0)" [label = "set"]
"words(0)$1" -> "our_text(0)$0" [label = "word_tokenize"]
"wordsFiltered(0)$0" -> "[](0)" [label = "eq"]
"w(0)" -> "words(0)$1" [label = "Iter"]
"wordsFiltered(0)$1" -> "wordsFiltered(0)$0" [label = "append"]
"wordsFiltered(0)$1" -> "w(0)" [label = "append"]
"print[0]" -> "wordsFiltered(0)$1" [label = "print"]
"stopWords(0)$1" -> "stopwords(0)" [label = "set"]
"stopWords(0)$1" -> "english(0)" [label = "set"]
"print[0]" -> "len(0)" [label = "print"]
"print[1]" -> "stopWords(0)$1" [label = "print"]
"print[0]" -> "stopWords(0)$1" [label = "print"]
"w(0)" -> "words(0)$1" [label = "Iter"]
"wordsFiltered(0)$2" -> "wordsFiltered(0)$1" [label = "append"]
"wordsFiltered(0)$2" -> "w(0)" [label = "append"]
"our_text(0)$1" -> "gendered_pronoun_df(0)$12" [label = "eq"]
"our_text(0)$1" -> "0(0)" [label = "eq"]
"word(0)" -> "word_tokenize(0)" [label = "Iter"]
"word(0)" -> "our_text(0)$1" [label = "Iter"]
"print[0]" -> "ps(0)" [label = "print"]
"print[1]" -> "word(0)" [label = "print"]
"sentences(0)$0" -> "nltk(0)" [label = "sent_tokenize"]
"sentences(0)$0" -> "our_text(0)$1" [label = "sent_tokenize"]
"sent(0)" -> "sentences(0)$0" [label = "Iter"]
"print[0]" -> "nltk(0)" [label = "print"]
"print[1]" -> "nltk(0)" [label = "print"]
"print[2]" -> "sent(0)" [label = "print"]
"sentences(0)$1" -> "nltk(0)" [label = "sent_tokenize"]
"sentences(0)$1" -> "our_text(0)$1" [label = "sent_tokenize"]
"data(0)$0" -> "[](0)" [label = "eq"]
"sent(0)" -> "sentences(0)$1" [label = "Iter"]
"data(0)$1" -> "data(0)$0" [label = "Add"]
"data(0)$1" -> "nltk(0)" [label = "Add"]
"data(0)$1" -> "nltk(0)" [label = "Add"]
"data(0)$1" -> "sent(0)" [label = "Add"]
"word(0)" -> "data(0)$1" [label = "Iter"]
"print[0]" -> "word(0)" [label = "print"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "male(0)" [label = "Add"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "names(0)$0" [label = "Add"]
"names(0)$0" -> "male.txt(0)" [label = "Add"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "female(0)" [label = "Add"]
"names(0)$0" -> "name(0)" [label = "Add"]
"names(0)$0" -> "names(0)$0" [label = "Add"]
"names(0)$0" -> "female.txt(0)" [label = "Add"]
"word(3)" -> "gender_features[0]" [label = "_argToVar"]
"word(4)" -> "gender_features[0]" [label = "_argToVar"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "male(0)" [label = "Add"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "names(0)$1" [label = "Add"]
"names(0)$1" -> "male.txt(0)" [label = "Add"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "female(0)" [label = "Add"]
"names(0)$1" -> "name(0)" [label = "Add"]
"names(0)$1" -> "names(0)$1" [label = "Add"]
"names(0)$1" -> "female.txt(0)" [label = "Add"]
"featuresets(0)$0" -> "gender_features(0)" [label = "eq"]
"featuresets(0)$0" -> "n(0)" [label = "eq"]
"featuresets(0)$0" -> "g(0)" [label = "eq"]
"featuresets(0)$0" -> "n(0)" [label = "eq"]
"featuresets(0)$0" -> "g(0)" [label = "eq"]
"featuresets(0)$0" -> "names(0)$1" [label = "eq"]
"train_set(0)$0" -> "featuresets(0)$0" [label = "eq"]
"classifier(0)$0" -> "nltk(0)" [label = "train"]
"classifier(0)$0" -> "train_set(0)$0" [label = "train"]
"print[0]" -> "classifier(0)$0" [label = "print"]
"print[1]" -> "gender_features(0)" [label = "print"]
"print[2]" -> "Frank(0)" [label = "print"]
"name(0)$0" -> "Sarah(0)" [label = "eq"]
"print[0]" -> "classifier(0)$0" [label = "print"]
"print[1]" -> "gender_features(0)" [label = "print"]
"print[2]" -> "name(0)$0" [label = "print"]
"positive_vocab(0)$0" -> "[<_ast.Str object at 0x10a746d50>, <_ast.Str object at 0x10a746790>, <_ast.Str object at 0x10a746a90>, <_ast.Str object at 0x10a746890>, <_ast.Str object at 0x10a7462d0>, <_ast.Str object at 0x10a746110>, <_ast.Str object at 0x10a746450>, <_ast.Str object at 0x10a746590>](0)" [label = "eq"]
"negative_vocab(0)$0" -> "[<_ast.Str object at 0x10a7465d0>, <_ast.Str object at 0x10a7464d0>, <_ast.Str object at 0x10a7469d0>, <_ast.Str object at 0x10a7468d0>, <_ast.Str object at 0x10a746210>](0)" [label = "eq"]
"neutral_vocab(0)$0" -> "[<_ast.Str object at 0x10add3590>, <_ast.Str object at 0x10add3850>, <_ast.Str object at 0x10add3c90>, <_ast.Str object at 0x10add3c10>, <_ast.Str object at 0x10add3bd0>, <_ast.Str object at 0x10add3fd0>, <_ast.Str object at 0x10add3750>, <_ast.Str object at 0x10add37d0>, <_ast.Str object at 0x10add30d0>, <_ast.Str object at 0x10add3ed0>](0)" [label = "eq"]
"words(5)" -> "word_feats[0]" [label = "_argToVar"]
"positive_features(0)$0" -> "word_feats(0)" [label = "eq"]
"positive_features(0)$0" -> "pos(0)" [label = "eq"]
"positive_features(0)$0" -> "pos(0)" [label = "eq"]
"positive_features(0)$0" -> "pos(0)" [label = "eq"]
"positive_features(0)$0" -> "positive_vocab(0)$0" [label = "eq"]
"negative_features(0)$0" -> "word_feats(0)" [label = "eq"]
"negative_features(0)$0" -> "neg(0)" [label = "eq"]
"negative_features(0)$0" -> "neg(0)" [label = "eq"]
"negative_features(0)$0" -> "neg(0)" [label = "eq"]
"negative_features(0)$0" -> "negative_vocab(0)$0" [label = "eq"]
"neutral_features(0)$0" -> "word_feats(0)" [label = "eq"]
"neutral_features(0)$0" -> "neu(0)" [label = "eq"]
"neutral_features(0)$0" -> "neu(0)" [label = "eq"]
"neutral_features(0)$0" -> "neu(0)" [label = "eq"]
"neutral_features(0)$0" -> "neutral_vocab(0)$0" [label = "eq"]
"train_set(0)$1" -> "negative_features(0)$0" [label = "Add"]
"train_set(0)$1" -> "positive_features(0)$0" [label = "Add"]
"train_set(0)$1" -> "neutral_features(0)$0" [label = "Add"]
"words(6)" -> "word_feats[0]" [label = "_argToVar"]
"positive_vocab(0)$1" -> "[<_ast.Str object at 0x10a181610>, <_ast.Str object at 0x10a181d50>, <_ast.Str object at 0x10a1810d0>, <_ast.Str object at 0x10a181ad0>, <_ast.Str object at 0x10a181550>, <_ast.Str object at 0x10a181450>, <_ast.Str object at 0x10a181210>, <_ast.Str object at 0x10a181bd0>](0)" [label = "eq"]
"negative_vocab(0)$1" -> "[<_ast.Str object at 0x10a181690>, <_ast.Str object at 0x10a1814d0>, <_ast.Str object at 0x10a181990>, <_ast.Str object at 0x10a181b50>, <_ast.Str object at 0x10a181910>](0)" [label = "eq"]
"neutral_vocab(0)$1" -> "[<_ast.Str object at 0x10a171910>, <_ast.Str object at 0x10a171ed0>, <_ast.Str object at 0x10a1716d0>, <_ast.Str object at 0x10a1717d0>, <_ast.Str object at 0x10a171950>, <_ast.Str object at 0x10a1719d0>, <_ast.Str object at 0x10a171350>, <_ast.Str object at 0x10a171490>, <_ast.Str object at 0x10a171610>, <_ast.Str object at 0x10a171b50>](0)" [label = "eq"]
"positive_features(0)$1" -> "word_feats(0)" [label = "eq"]
"positive_features(0)$1" -> "pos(0)" [label = "eq"]
"positive_features(0)$1" -> "pos(0)" [label = "eq"]
"positive_features(0)$1" -> "pos(0)" [label = "eq"]
"positive_features(0)$1" -> "positive_vocab(0)$1" [label = "eq"]
"negative_features(0)$1" -> "word_feats(0)" [label = "eq"]
"negative_features(0)$1" -> "neg(0)" [label = "eq"]
"negative_features(0)$1" -> "neg(0)" [label = "eq"]
"negative_features(0)$1" -> "neg(0)" [label = "eq"]
"negative_features(0)$1" -> "negative_vocab(0)$1" [label = "eq"]
"neutral_features(0)$1" -> "word_feats(0)" [label = "eq"]
"neutral_features(0)$1" -> "neu(0)" [label = "eq"]
"neutral_features(0)$1" -> "neu(0)" [label = "eq"]
"neutral_features(0)$1" -> "neu(0)" [label = "eq"]
"neutral_features(0)$1" -> "neutral_vocab(0)$1" [label = "eq"]
"train_set(0)$2" -> "negative_features(0)$1" [label = "Add"]
"train_set(0)$2" -> "positive_features(0)$1" [label = "Add"]
"train_set(0)$2" -> "neutral_features(0)$1" [label = "Add"]
"classifier(0)$1" -> "NaiveBayesClassifier(0)" [label = "train"]
"classifier(0)$1" -> "train_set(0)$2" [label = "train"]
"neg(0)$0" -> "0(0)" [label = "eq"]
"pos(0)$0" -> "0(0)" [label = "eq"]
"our_text(0)$2" -> "our_text(0)$1" [label = "lower"]
"words(0)$2" -> "our_text(0)$2" [label = "split"]
"words(0)$2" -> " (0)" [label = "split"]
"word(0)" -> "words(0)$2" [label = "Iter"]
"classResult(0)$0" -> "classifier(0)$1" [label = "classify"]
"classResult(0)$0" -> "word_feats(0)" [label = "classify"]
"classResult(0)$0" -> "word(0)" [label = "classify"]
"neg(0)$1" -> "neg(0)$0" [label = "Add"]
"neg(0)$1" -> "1(0)" [label = "Add"]
"pos(0)$1" -> "pos(0)$0" [label = "Add"]
"pos(0)$1" -> "1(0)" [label = "Add"]
"print[0]" -> "Positive: (0)" [label = "print"]
"print[1]" -> "str(0)" [label = "print"]
"print[2]" -> "float(0)" [label = "print"]
"print[3]" -> "pos(0)$1" [label = "print"]
"print[4]" -> "len(0)" [label = "print"]
"print[5]" -> "words(0)$2" [label = "print"]
"print[0]" -> "Negative: (0)" [label = "print"]
"print[1]" -> "str(0)" [label = "print"]
"print[2]" -> "float(0)" [label = "print"]
"print[3]" -> "neg(0)$1" [label = "print"]
"print[4]" -> "len(0)" [label = "print"]
"print[5]" -> "words(0)$2" [label = "print"]
"nlp(0)$0" -> "spacy(0)" [label = "load"]
"nlp(0)$0" -> "en(0)" [label = "load"]
"doc(0)$0" -> "our_text(0)$2" [label = "nlp"]
"i(0)$0" -> "0(0)" [label = "eq"]
"token(0)" -> "doc(0)$0" [label = "Iter"]
"i(0)$1" -> "i(0)$0" [label = "Add"]
"i(0)$1" -> "1(0)" [label = "Add"]
"print[0]" -> ""(0)" [label = "print"]
"print[1]" -> "token(0)" [label = "print"]
"print[2]" -> ""(0)" [label = "print"]
"nlp(0)$1" -> "spacy(0)" [label = "load"]
"nlp(0)$1" -> "en(0)" [label = "load"]
"doc(0)$1" -> "our_text(0)$2" [label = "nlp"]
"i(0)$2" -> "0(0)" [label = "eq"]
"sent(0)" -> "doc(0)$1" [label = "Iter"]
"i(0)$3" -> "i(0)$2" [label = "Add"]
"i(0)$3" -> "1(0)" [label = "Add"]
"print[0]" -> "i(0)$3" [label = "print"]
"print[1]" -> " - (0)" [label = "print"]
"print[2]" -> "sent(0)" [label = "print"]
"doc(0)$2" -> "our_text(0)$2" [label = "nlp"]
"print[0]" -> "token(0)" [label = "print"]
"print[1]" -> "token(0)" [label = "print"]
"print[2]" -> "token(0)" [label = "print"]
"print[3]" -> "doc(0)$2" [label = "print"]
"doc(0)$3" -> "our_text(0)$2" [label = "nlp"]
"ent(0)" -> "doc(0)$3" [label = "Iter"]
"print[0]" -> "ent(0)" [label = "print"]
"print[1]" -> "ent(0)" [label = "print"]
"doc(0)$4" -> "our_text(0)$2" [label = "nlp"]
"displacy(0)$0" -> "displacy(0)" [label = "render"]
"displacy(0)$0" -> "doc(0)$4" [label = "render"]
"doc(0)$5" -> "our_text(0)$2" [label = "nlp"]
"displacy(0)$1" -> "displacy(0)$0" [label = "render"]
"displacy(0)$1" -> "doc(0)$5" [label = "render"]
"documents(0)$0" -> "[<_ast.Str object at 0x10ae07990>, <_ast.Str object at 0x10ae07590>, <_ast.Str object at 0x10ae07250>, <_ast.Str object at 0x10ae073d0>, <_ast.Str object at 0x10ae07b10>](0)" [label = "eq"]
"documents_2(0)$0" -> "[<_ast.Str object at 0x10ae07a90>, <_ast.Str object at 0x10ae07110>, <_ast.Str object at 0x10ae074d0>, <_ast.Str object at 0x10ae07050>, <_ast.Str object at 0x10ae07210>, <_ast.Str object at 0x10ae07510>](0)" [label = "eq"]
"texts(0)$0" -> "text(0)$0" [label = "eq"]
"texts(0)$0" -> "text(0)$0" [label = "eq"]
"texts(0)$0" -> "doc(0)$5" [label = "eq"]
"texts(0)$0" -> "doc(0)$5" [label = "eq"]
"texts(0)$0" -> "documents(0)$0" [label = "eq"]
"dictionary(0)$0" -> "corpora(0)" [label = "Dictionary"]
"dictionary(0)$0" -> "texts(0)$0" [label = "Dictionary"]
"print[0]" -> "dictionary(0)$0" [label = "print"]
"print[0]" -> "dictionary(0)$0" [label = "print"]
}