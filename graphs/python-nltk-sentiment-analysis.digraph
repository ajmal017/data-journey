digraph { 
"numpy" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"np(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"np(0)" -> "numpy" [label = "assign"]
"pandas" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"pd(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"pd(0)" -> "pandas" [label = "assign"]
"sklearn.model_selection" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"train_test_split" -> "sklearn.model_selection" [label = "import"]
"train_test_split(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"train_test_split(0)" -> "train_test_split" [label = "assign"]
"nltk" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"nltk(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"nltk(0)" -> "nltk" [label = "assign"]
"nltk.corpus" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"stopwords" -> "nltk.corpus" [label = "import"]
"stopwords(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"stopwords(0)" -> "stopwords" [label = "assign"]
"nltk.classify" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"SklearnClassifier" -> "nltk.classify" [label = "import"]
"SklearnClassifier(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"SklearnClassifier(0)" -> "SklearnClassifier" [label = "assign"]
"wordcloud" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"WordCloud" -> "wordcloud" [label = "import"]
"WordCloud(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"WordCloud(0)" -> "WordCloud" [label = "assign"]
"STOPWORDS" -> "wordcloud" [label = "import"]
"STOPWORDS(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"STOPWORDS(0)" -> "STOPWORDS" [label = "assign"]
"matplotlib.pyplot" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"plt(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"plt(0)" -> "matplotlib.pyplot" [label = "assign"]
"subprocess" -> "python-nltk-sentiment-analysis.ipynb" [label = "import"]
"check_output" -> "subprocess" [label = "import"]
"check_output(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"check_output(0)" -> "check_output" [label = "assign"]
"data(0)$0" -> "pd(0)" [label = "read_csv"]
"../input/Sentiment.csv(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"data(0)$0" -> "../input/Sentiment.csv(0)" [label = "read_csv"]
"data(0)$1" -> "data(0)$0" [label = "assign"]
"[<_ast.Str object at 0x105ac4c50>, <_ast.Str object at 0x105ac4950>](0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"data(0)$1" -> "[<_ast.Str object at 0x105ac4c50>, <_ast.Str object at 0x105ac4950>](0)" [label = "assign"]
"train(0)$0" -> "data(0)$1" [label = "train_test_split"]
"test(0)$0" -> "data(0)$1" [label = "train_test_split"]
"0.1(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"train(0)$0" -> "0.1(0)" [label = "train_test_split"]
"test(0)$0" -> "0.1(0)" [label = "train_test_split"]
"train(0)$1" -> "train(0)$0" [label = "assign"]
"train(0)$1" -> "train(0)$1" [label = "assign"]
"Neutral(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"train(0)$1" -> "Neutral(0)" [label = "assign"]
"train_pos(0)$0" -> "train(0)$1" [label = "assign"]
"train_pos(0)$0" -> "train(0)$1" [label = "assign"]
"sentiment(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"train_pos(0)$0" -> "sentiment(0)" [label = "assign"]
"Positive(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"train_pos(0)$0" -> "Positive(0)" [label = "assign"]
"train_pos(0)$1" -> "train_pos(0)$0" [label = "assign"]
"text(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"train_pos(0)$1" -> "text(0)" [label = "assign"]
"train_neg(0)$0" -> "train(0)$1" [label = "assign"]
"train_neg(0)$0" -> "train(0)$1" [label = "assign"]
"train_neg(0)$0" -> "sentiment(0)" [label = "assign"]
"Negative(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"train_neg(0)$0" -> "Negative(0)" [label = "assign"]
"train_neg(0)$1" -> "train_neg(0)$0" [label = "assign"]
"train_neg(0)$1" -> "text(0)" [label = "assign"]
"data(1)" -> "wordcloud_draw[0]" [label = "_argToVar"]
"color(1)" -> "wordcloud_draw[1]" [label = "_argToVar"]
"words(1)$0" -> " (1)" [label = "join"]
"words(1)$0" -> "data(1)" [label = "join"]
"cleaned_word(1)$0" -> " (1)" [label = "join"]
"cleaned_word(1)$0" -> "word(1)" [label = "join"]
"cleaned_word(1)$0" -> "word(1)" [label = "join"]
"cleaned_word(1)$0" -> "words(1)$0" [label = "join"]
"cleaned_word(1)$0" -> "http(1)" [label = "join"]
"cleaned_word(1)$0" -> "word(1)" [label = "join"]
"cleaned_word(1)$0" -> "word(1)" [label = "join"]
"cleaned_word(1)$0" -> "@(1)" [label = "join"]
"cleaned_word(1)$0" -> "word(1)" [label = "join"]
"cleaned_word(1)$0" -> "#(1)" [label = "join"]
"cleaned_word(1)$0" -> "word(1)" [label = "join"]
"cleaned_word(1)$0" -> "RT(1)" [label = "join"]
"wordcloud(1)$0" -> "WordCloud(1)" [label = "generate"]
"wordcloud(1)$0" -> "STOPWORDS(1)" [label = "generate"]
"wordcloud(1)$0" -> "color(1)" [label = "generate"]
"wordcloud(1)$0" -> "2500(1)" [label = "generate"]
"wordcloud(1)$0" -> "2000(1)" [label = "generate"]
"wordcloud(1)$0" -> "cleaned_word(1)$0" [label = "generate"]
"plt(1)$0" -> "plt(1)" [label = "figure"]
"plt(1)$0" -> "1(1)" [label = "figure"]
"plt(1)$1" -> "plt(1)$0" [label = "imshow"]
"plt(1)$1" -> "wordcloud(1)$0" [label = "imshow"]
"plt(1)$2" -> "plt(1)$1" [label = "axis"]
"plt(1)$2" -> "off(1)" [label = "axis"]
"plt(1)$3" -> "plt(1)$2" [label = "show"]
"Positive words(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"print[0]" -> "Positive words(0)" [label = "print"]
"wordcloud_draw[0]" -> "train_pos(0)$1" [label = "wordcloud_draw"]
"white(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"wordcloud_draw[1]" -> "white(0)" [label = "wordcloud_draw"]
"Negative words(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"print[0]" -> "Negative words(0)" [label = "print"]
"wordcloud_draw[0]" -> "train_neg(0)$1" [label = "wordcloud_draw"]
"[](0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"tweets(0)$0" -> "[](0)" [label = "assign"]
"stopwords_set(0)$0" -> "stopwords(0)" [label = "set"]
"english(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"stopwords_set(0)$0" -> "english(0)" [label = "set"]
"index(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"index(0)" -> "train(0)$1" [label = "Iter"]
"row(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"row(0)" -> "train(0)$1" [label = "Iter"]
"e(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_filtered(0)$0" -> "e(0)" [label = "assign"]
"words_filtered(0)$0" -> "e(0)" [label = "assign"]
"words_filtered(0)$0" -> "row(0)" [label = "assign"]
"len(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_filtered(0)$0" -> "len(0)" [label = "assign"]
"words_filtered(0)$0" -> "e(0)" [label = "assign"]
"3(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_filtered(0)$0" -> "3(0)" [label = "assign"]
"word(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_cleaned(0)$0" -> "word(0)" [label = "assign"]
"words_cleaned(0)$0" -> "word(0)" [label = "assign"]
"words_cleaned(0)$0" -> "words_filtered(0)$0" [label = "assign"]
"http(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_cleaned(0)$0" -> "http(0)" [label = "assign"]
"words_cleaned(0)$0" -> "word(0)" [label = "assign"]
"words_cleaned(0)$0" -> "word(0)" [label = "assign"]
"@(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_cleaned(0)$0" -> "@(0)" [label = "assign"]
"words_cleaned(0)$0" -> "word(0)" [label = "assign"]
"#(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_cleaned(0)$0" -> "#(0)" [label = "assign"]
"words_cleaned(0)$0" -> "word(0)" [label = "assign"]
"RT(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"words_cleaned(0)$0" -> "RT(0)" [label = "assign"]
"words_without_stopwords(0)$0" -> "word(0)" [label = "assign"]
"words_without_stopwords(0)$0" -> "word(0)" [label = "assign"]
"words_without_stopwords(0)$0" -> "words_cleaned(0)$0" [label = "assign"]
"words_without_stopwords(0)$0" -> "word(0)" [label = "assign"]
"words_without_stopwords(0)$0" -> "stopwords_set(0)$0" [label = "assign"]
"tweets(0)$1" -> "tweets(0)$0" [label = "append"]
"tweets(0)$1" -> "words_without_stopwords(0)$0" [label = "append"]
"tweets(0)$1" -> "row(0)" [label = "append"]
"test_pos(0)$0" -> "test(0)$0" [label = "assign"]
"test_pos(0)$0" -> "test(0)$0" [label = "assign"]
"test_pos(0)$0" -> "sentiment(0)" [label = "assign"]
"test_pos(0)$0" -> "Positive(0)" [label = "assign"]
"test_pos(0)$1" -> "test_pos(0)$0" [label = "assign"]
"test_pos(0)$1" -> "text(0)" [label = "assign"]
"test_neg(0)$0" -> "test(0)$0" [label = "assign"]
"test_neg(0)$0" -> "test(0)$0" [label = "assign"]
"test_neg(0)$0" -> "sentiment(0)" [label = "assign"]
"test_neg(0)$0" -> "Negative(0)" [label = "assign"]
"test_neg(0)$1" -> "test_neg(0)$0" [label = "assign"]
"test_neg(0)$1" -> "text(0)" [label = "assign"]
"tweets(2)" -> "get_words_in_tweets[0]" [label = "_argToVar"]
"all(2)$0" -> "[](2)" [label = "assign"]
"words(2)" -> "tweets(2)" [label = "Iter"]
"sentiment(2)" -> "tweets(2)" [label = "Iter"]
"all(2)$1" -> "all(2)$0" [label = "extend"]
"all(2)$1" -> "words(2)" [label = "extend"]
"wordlist(3)" -> "get_word_features[0]" [label = "_argToVar"]
"wordlist(3)$0" -> "nltk(3)" [label = "FreqDist"]
"wordlist(3)$0" -> "wordlist(3)$0" [label = "FreqDist"]
"features(3)$0" -> "wordlist(3)$0" [label = "keys"]
"get_words_in_tweets(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"w_features(0)$0" -> "get_words_in_tweets(0)" [label = "get_word_features"]
"w_features(0)$0" -> "tweets(0)$1" [label = "get_word_features"]
"document(4)" -> "extract_features[0]" [label = "_argToVar"]
"document_words(4)$0" -> "document(4)" [label = "set"]
"word(4)" -> "w_features(4)" [label = "Iter"]
"features(4)$0" -> "features(4)" [label = "assign"]
"features(4)$0" -> "word(4)" [label = "assign"]
"features(4)$0" -> "document_words(4)$0" [label = "assign"]
"wordcloud_draw[0]" -> "w_features(0)$0" [label = "wordcloud_draw"]
"training_set(0)$0" -> "nltk(0)" [label = "apply_features"]
"extract_features(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"training_set(0)$0" -> "extract_features(0)" [label = "apply_features"]
"training_set(0)$0" -> "tweets(0)$1" [label = "apply_features"]
"classifier(0)$0" -> "nltk(0)" [label = "train"]
"classifier(0)$0" -> "training_set(0)$0" [label = "train"]
"0(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"neg_cnt(0)$0" -> "0(0)" [label = "assign"]
"pos_cnt(0)$0" -> "0(0)" [label = "assign"]
"obj(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"obj(0)" -> "test_neg(0)$1" [label = "Iter"]
"res(0)$0" -> "classifier(0)$0" [label = "classify"]
"res(0)$0" -> "extract_features(0)" [label = "classify"]
"res(0)$0" -> "obj(0)" [label = "classify"]
"neg_cnt(0)$1" -> "neg_cnt(0)$0" [label = "Add"]
"1(0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"neg_cnt(0)$1" -> "1(0)" [label = "Add"]
"obj(0)" -> "test_pos(0)$1" [label = "Iter"]
"res(0)$1" -> "classifier(0)$0" [label = "classify"]
"res(0)$1" -> "extract_features(0)" [label = "classify"]
"res(0)$1" -> "obj(0)" [label = "classify"]
"pos_cnt(0)$1" -> "pos_cnt(0)$0" [label = "Add"]
"pos_cnt(0)$1" -> "1(0)" [label = "Add"]
"[Negative]: %s/%s (0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"print[0]" -> "[Negative]: %s/%s (0)" [label = "print"]
"print[1]" -> "len(0)" [label = "print"]
"print[2]" -> "test_neg(0)$1" [label = "print"]
"print[3]" -> "neg_cnt(0)$1" [label = "print"]
"[Positive]: %s/%s (0)" -> "python-nltk-sentiment-analysis.ipynb" [label = "appears"]
"print[0]" -> "[Positive]: %s/%s (0)" [label = "print"]
"print[1]" -> "len(0)" [label = "print"]
"print[2]" -> "test_pos(0)$1" [label = "print"]
"print[3]" -> "pos_cnt(0)$1" [label = "print"]
}