digraph { 
"pal(0)$0" -> "sns(0)" [label = "color_palette"]
"print[0]" -> "# File sizes(0)" [label = "print"]
"f(0)" -> "os(0)" [label = "Iter"]
"f(0)" -> "../input(0)" [label = "Iter"]
"print[0]" -> "f(0)" [label = "print"]
"print[1]" -> "30(0)" [label = "print"]
"print[2]" -> "str(0)" [label = "print"]
"print[3]" -> "round(0)" [label = "print"]
"print[4]" -> "os(0)" [label = "print"]
"print[5]" -> "../input/(0)" [label = "print"]
"print[6]" -> "f(0)" [label = "print"]
"print[7]" -> "1000000(0)" [label = "print"]
"print[8]" -> "2(0)" [label = "print"]
"print[9]" -> "MB(0)" [label = "print"]
"df_train(0)$0" -> "pd(0)" [label = "read_csv"]
"df_train(0)$0" -> "../input/train.csv(0)" [label = "read_csv"]
"df_train(0)$1" -> "df_train(0)$0" [label = "head"]
"print[0]" -> "Total number of question pairs for training: {}(0)" [label = "print"]
"print[1]" -> "len(0)" [label = "print"]
"print[2]" -> "df_train(0)$1" [label = "print"]
"print[0]" -> "Duplicate pairs: {}%(0)" [label = "print"]
"print[1]" -> "round(0)" [label = "print"]
"print[2]" -> "df_train(0)$1" [label = "print"]
"print[3]" -> "is_duplicate(0)" [label = "print"]
"print[4]" -> "100(0)" [label = "print"]
"print[5]" -> "2(0)" [label = "print"]
"qids(0)$0" -> "pd(0)" [label = "Series"]
"qids(0)$0" -> "df_train(0)$1" [label = "Series"]
"qids(0)$0" -> "qid1(0)" [label = "Series"]
"qids(0)$0" -> "df_train(0)$1" [label = "Series"]
"qids(0)$0" -> "qid2(0)" [label = "Series"]
"print[0]" -> "Total number of questions in the training data: {}(0)" [label = "print"]
"print[1]" -> "len(0)" [label = "print"]
"print[2]" -> "np(0)" [label = "print"]
"print[3]" -> "qids(0)$0" [label = "print"]
"print[0]" -> "Number of questions that appear multiple times: {}(0)" [label = "print"]
"print[1]" -> "np(0)" [label = "print"]
"print[2]" -> "qids(0)$0" [label = "print"]
"print[3]" -> "1(0)" [label = "print"]
"plt(0)$0" -> "plt(0)" [label = "figure"]
"plt(0)$1" -> "plt(0)$0" [label = "hist"]
"plt(0)$1" -> "qids(0)$0" [label = "hist"]
"plt(0)$2" -> "plt(0)$1" [label = "yscale"]
"plt(0)$2" -> "log(0)" [label = "yscale"]
"plt(0)$3" -> "plt(0)$2" [label = "title"]
"plt(0)$3" -> "Log-Histogram of question appearance counts(0)" [label = "title"]
"plt(0)$4" -> "plt(0)$3" [label = "xlabel"]
"plt(0)$4" -> "Number of occurences of question(0)" [label = "xlabel"]
"plt(0)$5" -> "plt(0)$4" [label = "ylabel"]
"plt(0)$5" -> "Number of questions(0)" [label = "ylabel"]
"p(0)$0" -> "df_train(0)$1" [label = "mean"]
"p(0)$0" -> "is_duplicate(0)" [label = "mean"]
"print[0]" -> "Predicted score:(0)" [label = "print"]
"print[1]" -> "log_loss(0)" [label = "print"]
"print[2]" -> "df_train(0)$1" [label = "print"]
"print[3]" -> "is_duplicate(0)" [label = "print"]
"print[4]" -> "np(0)" [label = "print"]
"print[5]" -> "df_train(0)$1" [label = "print"]
"print[6]" -> "is_duplicate(0)" [label = "print"]
"print[7]" -> "p(0)$0" [label = "print"]
"df_test(0)$0" -> "pd(0)" [label = "read_csv"]
"df_test(0)$0" -> "../input/test.csv(0)" [label = "read_csv"]
"sub(0)$0" -> "pd(0)" [label = "DataFrame"]
"sub(0)$0" -> "test_id(0)" [label = "DataFrame"]
"sub(0)$0" -> "is_duplicate(0)" [label = "DataFrame"]
"sub(0)$0" -> "df_test(0)$0" [label = "DataFrame"]
"sub(0)$0" -> "test_id(0)" [label = "DataFrame"]
"sub(0)$0" -> "p(0)$0" [label = "DataFrame"]
"sub(0)$1" -> "sub(0)$0" [label = "to_csv"]
"sub(0)$1" -> "naive_submission.csv(0)" [label = "to_csv"]
"sub(0)$2" -> "sub(0)$1" [label = "head"]
"df_test(0)$1" -> "pd(0)" [label = "read_csv"]
"df_test(0)$1" -> "../input/test.csv(0)" [label = "read_csv"]
"df_test(0)$2" -> "df_test(0)$1" [label = "head"]
"print[0]" -> "Total number of question pairs for testing: {}(0)" [label = "print"]
"print[1]" -> "len(0)" [label = "print"]
"print[2]" -> "df_test(0)$2" [label = "print"]
"train_qs(0)$0" -> "pd(0)" [label = "astype"]
"train_qs(0)$0" -> "df_train(0)$1" [label = "astype"]
"train_qs(0)$0" -> "question1(0)" [label = "astype"]
"train_qs(0)$0" -> "df_train(0)$1" [label = "astype"]
"train_qs(0)$0" -> "question2(0)" [label = "astype"]
"train_qs(0)$0" -> "str(0)" [label = "astype"]
"test_qs(0)$0" -> "pd(0)" [label = "astype"]
"test_qs(0)$0" -> "df_test(0)$2" [label = "astype"]
"test_qs(0)$0" -> "question1(0)" [label = "astype"]
"test_qs(0)$0" -> "df_test(0)$2" [label = "astype"]
"test_qs(0)$0" -> "question2(0)" [label = "astype"]
"test_qs(0)$0" -> "str(0)" [label = "astype"]
"dist_train(0)$0" -> "train_qs(0)$0" [label = "apply"]
"dist_train(0)$0" -> "len(0)" [label = "apply"]
"dist_test(0)$0" -> "test_qs(0)$0" [label = "apply"]
"dist_test(0)$0" -> "len(0)" [label = "apply"]
"plt(0)$6" -> "plt(0)$5" [label = "figure"]
"plt(0)$7" -> "plt(0)$6" [label = "hist"]
"plt(0)$7" -> "dist_train(0)$0" [label = "hist"]
"plt(0)$8" -> "plt(0)$7" [label = "hist"]
"plt(0)$8" -> "dist_test(0)$0" [label = "hist"]
"plt(0)$9" -> "plt(0)$8" [label = "title"]
"plt(0)$9" -> "Normalised histogram of character count in questions(0)" [label = "title"]
"plt(0)$10" -> "plt(0)$9" [label = "legend"]
"plt(0)$11" -> "plt(0)$10" [label = "xlabel"]
"plt(0)$11" -> "Number of characters(0)" [label = "xlabel"]
"plt(0)$12" -> "plt(0)$11" [label = "ylabel"]
"plt(0)$12" -> "Probability(0)" [label = "ylabel"]
"print[0]" -> "mean-train {:.2f} std-train {:.2f} mean-test {:.2f} std-test {:.2f} max-train {:.2f} max-test {:.2f}(0)" [label = "print"]
"print[1]" -> "dist_train(0)$0" [label = "print"]
"print[2]" -> "dist_train(0)$0" [label = "print"]
"print[3]" -> "dist_test(0)$0" [label = "print"]
"print[4]" -> "dist_test(0)$0" [label = "print"]
"print[5]" -> "dist_train(0)$0" [label = "print"]
"print[6]" -> "dist_test(0)$0" [label = "print"]
"dist_train(0)$1" -> "train_qs(0)$0" [label = "apply"]
"dist_train(0)$1" -> "len(0)" [label = "apply"]
"dist_train(0)$1" -> "x(0)" [label = "apply"]
"dist_train(0)$1" -> " (0)" [label = "apply"]
"dist_test(0)$1" -> "test_qs(0)$0" [label = "apply"]
"dist_test(0)$1" -> "len(0)" [label = "apply"]
"dist_test(0)$1" -> "x(0)" [label = "apply"]
"dist_test(0)$1" -> " (0)" [label = "apply"]
"plt(0)$13" -> "plt(0)$12" [label = "figure"]
"plt(0)$14" -> "plt(0)$13" [label = "hist"]
"plt(0)$14" -> "dist_train(0)$1" [label = "hist"]
"plt(0)$15" -> "plt(0)$14" [label = "hist"]
"plt(0)$15" -> "dist_test(0)$1" [label = "hist"]
"plt(0)$16" -> "plt(0)$15" [label = "title"]
"plt(0)$16" -> "Normalised histogram of word count in questions(0)" [label = "title"]
"plt(0)$17" -> "plt(0)$16" [label = "legend"]
"plt(0)$18" -> "plt(0)$17" [label = "xlabel"]
"plt(0)$18" -> "Number of words(0)" [label = "xlabel"]
"plt(0)$19" -> "plt(0)$18" [label = "ylabel"]
"plt(0)$19" -> "Probability(0)" [label = "ylabel"]
"print[0]" -> "mean-train {:.2f} std-train {:.2f} mean-test {:.2f} std-test {:.2f} max-train {:.2f} max-test {:.2f}(0)" [label = "print"]
"print[1]" -> "dist_train(0)$1" [label = "print"]
"print[2]" -> "dist_train(0)$1" [label = "print"]
"print[3]" -> "dist_test(0)$1" [label = "print"]
"print[4]" -> "dist_test(0)$1" [label = "print"]
"print[5]" -> "dist_train(0)$1" [label = "print"]
"print[6]" -> "dist_test(0)$1" [label = "print"]
"cloud(0)$0" -> "WordCloud(0)" [label = "generate"]
"cloud(0)$0" -> "1440(0)" [label = "generate"]
"cloud(0)$0" -> "1080(0)" [label = "generate"]
"cloud(0)$0" -> " (0)" [label = "generate"]
"cloud(0)$0" -> "train_qs(0)$0" [label = "generate"]
"cloud(0)$0" -> "str(0)" [label = "generate"]
"plt(0)$20" -> "plt(0)$19" [label = "figure"]
"plt(0)$21" -> "plt(0)$20" [label = "imshow"]
"plt(0)$21" -> "cloud(0)$0" [label = "imshow"]
"plt(0)$22" -> "plt(0)$21" [label = "axis"]
"plt(0)$22" -> "off(0)" [label = "axis"]
"qmarks(0)$0" -> "np(0)" [label = "mean"]
"qmarks(0)$0" -> "train_qs(0)$0" [label = "mean"]
"qmarks(0)$0" -> "?(0)" [label = "mean"]
"qmarks(0)$0" -> "x(0)" [label = "mean"]
"math(0)$0" -> "np(0)" [label = "mean"]
"math(0)$0" -> "train_qs(0)$0" [label = "mean"]
"math(0)$0" -> "[math](0)" [label = "mean"]
"math(0)$0" -> "x(0)" [label = "mean"]
"fullstop(0)$0" -> "np(0)" [label = "mean"]
"fullstop(0)$0" -> "train_qs(0)$0" [label = "mean"]
"fullstop(0)$0" -> ".(0)" [label = "mean"]
"fullstop(0)$0" -> "x(0)" [label = "mean"]
"capital_first(0)$0" -> "np(0)" [label = "mean"]
"capital_first(0)$0" -> "train_qs(0)$0" [label = "mean"]
"capital_first(0)$0" -> "x(0)" [label = "mean"]
"capital_first(0)$0" -> "0(0)" [label = "mean"]
"capitals(0)$0" -> "np(0)" [label = "mean"]
"capitals(0)$0" -> "train_qs(0)$0" [label = "mean"]
"capitals(0)$0" -> "max(0)" [label = "mean"]
"capitals(0)$0" -> "y(0)" [label = "mean"]
"capitals(0)$0" -> "y(0)" [label = "mean"]
"capitals(0)$0" -> "x(0)" [label = "mean"]
"numbers(0)$0" -> "np(0)" [label = "mean"]
"numbers(0)$0" -> "train_qs(0)$0" [label = "mean"]
"numbers(0)$0" -> "max(0)" [label = "mean"]
"numbers(0)$0" -> "y(0)" [label = "mean"]
"numbers(0)$0" -> "y(0)" [label = "mean"]
"numbers(0)$0" -> "x(0)" [label = "mean"]
"print[0]" -> "Questions with question marks: {:.2f}%(0)" [label = "print"]
"print[1]" -> "qmarks(0)$0" [label = "print"]
"print[2]" -> "100(0)" [label = "print"]
"print[0]" -> "Questions with [math] tags: {:.2f}%(0)" [label = "print"]
"print[1]" -> "math(0)$0" [label = "print"]
"print[2]" -> "100(0)" [label = "print"]
"print[0]" -> "Questions with full stops: {:.2f}%(0)" [label = "print"]
"print[1]" -> "fullstop(0)$0" [label = "print"]
"print[2]" -> "100(0)" [label = "print"]
"print[0]" -> "Questions with capitalised first letters: {:.2f}%(0)" [label = "print"]
"print[1]" -> "capital_first(0)$0" [label = "print"]
"print[2]" -> "100(0)" [label = "print"]
"print[0]" -> "Questions with capital letters: {:.2f}%(0)" [label = "print"]
"print[1]" -> "capitals(0)$0" [label = "print"]
"print[2]" -> "100(0)" [label = "print"]
"print[0]" -> "Questions with numbers: {:.2f}%(0)" [label = "print"]
"print[1]" -> "numbers(0)$0" [label = "print"]
"print[2]" -> "100(0)" [label = "print"]
"stops(0)$0" -> "stopwords(0)" [label = "set"]
"stops(0)$0" -> "english(0)" [label = "set"]
"row(1)" -> "word_match_share[0]" [label = "_argToVar"]
"word(1)" -> "str(1)" [label = "Iter"]
"word(1)" -> "row(1)" [label = "Iter"]
"word(1)" -> "question1(1)" [label = "Iter"]
"q1words(1)$0" -> "q1words(1)" [label = "eq"]
"q1words(1)$0" -> "1(1)" [label = "eq"]
"word(1)" -> "str(1)" [label = "Iter"]
"word(1)" -> "row(1)" [label = "Iter"]
"word(1)" -> "question2(1)" [label = "Iter"]
"q2words(1)$0" -> "q2words(1)" [label = "eq"]
"q2words(1)$0" -> "1(1)" [label = "eq"]
"shared_words_in_q1(1)$0" -> "w(1)" [label = "eq"]
"shared_words_in_q1(1)$0" -> "w(1)" [label = "eq"]
"shared_words_in_q1(1)$0" -> "q1words(1)$0" [label = "eq"]
"shared_words_in_q1(1)$0" -> "w(1)" [label = "eq"]
"shared_words_in_q1(1)$0" -> "q2words(1)$0" [label = "eq"]
"shared_words_in_q2(1)$0" -> "w(1)" [label = "eq"]
"shared_words_in_q2(1)$0" -> "w(1)" [label = "eq"]
"shared_words_in_q2(1)$0" -> "q2words(1)$0" [label = "eq"]
"shared_words_in_q2(1)$0" -> "w(1)" [label = "eq"]
"shared_words_in_q2(1)$0" -> "q1words(1)$0" [label = "eq"]
"R(1)$0" -> "len(1)" [label = "Div"]
"R(1)$0" -> "shared_words_in_q1(1)$0" [label = "Div"]
"R(1)$0" -> "len(1)" [label = "Div"]
"R(1)$0" -> "shared_words_in_q2(1)$0" [label = "Div"]
"R(1)$0" -> "len(1)" [label = "Div"]
"R(1)$0" -> "q1words(1)$0" [label = "Div"]
"R(1)$0" -> "len(1)" [label = "Div"]
"R(1)$0" -> "q2words(1)$0" [label = "Div"]
"plt(0)$23" -> "plt(0)$22" [label = "figure"]
"train_word_match(0)$0" -> "df_train(0)$1" [label = "apply"]
"train_word_match(0)$0" -> "word_match_share(0)" [label = "apply"]
"train_word_match(0)$0" -> "1(0)" [label = "apply"]
"plt(0)$24" -> "plt(0)$23" [label = "hist"]
"plt(0)$24" -> "train_word_match(0)$0" [label = "hist"]
"plt(0)$24" -> "df_train(0)$1" [label = "hist"]
"plt(0)$24" -> "is_duplicate(0)" [label = "hist"]
"plt(0)$24" -> "0(0)" [label = "hist"]
"plt(0)$25" -> "plt(0)$24" [label = "hist"]
"plt(0)$25" -> "train_word_match(0)$0" [label = "hist"]
"plt(0)$25" -> "df_train(0)$1" [label = "hist"]
"plt(0)$25" -> "is_duplicate(0)" [label = "hist"]
"plt(0)$25" -> "1(0)" [label = "hist"]
"plt(0)$26" -> "plt(0)$25" [label = "legend"]
"plt(0)$27" -> "plt(0)$26" [label = "title"]
"plt(0)$27" -> "Label distribution over word_match_share(0)" [label = "title"]
"plt(0)$28" -> "plt(0)$27" [label = "xlabel"]
"plt(0)$28" -> "word_match_share(0)" [label = "xlabel"]
"count(2)" -> "get_weight[0]" [label = "_argToVar"]
"eps(2)" -> "get_weight[1]" [label = "_argToVar"]
"min_count(2)" -> "get_weight[2]" [label = "_argToVar"]
"eps(0)$0" -> "5000(0)" [label = "eq"]
"words(0)$0" -> " (0)" [label = "split"]
"words(0)$0" -> "train_qs(0)$0" [label = "split"]
"counts(0)$0" -> "words(0)$0" [label = "Counter"]
"weights(0)$0" -> "word(0)" [label = "eq"]
"weights(0)$0" -> "get_weight(0)" [label = "eq"]
"weights(0)$0" -> "count(0)" [label = "eq"]
"weights(0)$0" -> "word(0)" [label = "eq"]
"weights(0)$0" -> "count(0)" [label = "eq"]
"weights(0)$0" -> "counts(0)$0" [label = "eq"]
"print[0]" -> "Most common words and weights: 
(0)" [label = "print"]
"print[0]" -> "sorted(0)" [label = "print"]
"print[1]" -> "weights(0)$0" [label = "print"]
"print[2]" -> "x(0)" [label = "print"]
"print[3]" -> "1(0)" [label = "print"]
"print[4]" -> "0(0)" [label = "print"]
"print[5]" -> "x(0)" [label = "print"]
"print[6]" -> "1(0)" [label = "print"]
"print[7]" -> "9999(0)" [label = "print"]
"print[8]" -> "10(0)" [label = "print"]
"print[0]" -> "
Least common words and weights: (0)" [label = "print"]
"row(3)" -> "tfidf_word_match_share[0]" [label = "_argToVar"]
"word(3)" -> "str(3)" [label = "Iter"]
"word(3)" -> "row(3)" [label = "Iter"]
"word(3)" -> "question1(3)" [label = "Iter"]
"q1words(3)$0" -> "q1words(3)" [label = "eq"]
"q1words(3)$0" -> "1(3)" [label = "eq"]
"word(3)" -> "str(3)" [label = "Iter"]
"word(3)" -> "row(3)" [label = "Iter"]
"word(3)" -> "question2(3)" [label = "Iter"]
"q2words(3)$0" -> "q2words(3)" [label = "eq"]
"q2words(3)$0" -> "1(3)" [label = "eq"]
"shared_weights(3)$0" -> "weights(3)" [label = "Add"]
"shared_weights(3)$0" -> "w(3)" [label = "Add"]
"shared_weights(3)$0" -> "0(3)" [label = "Add"]
"shared_weights(3)$0" -> "w(3)" [label = "Add"]
"shared_weights(3)$0" -> "q1words(3)$0" [label = "Add"]
"shared_weights(3)$0" -> "w(3)" [label = "Add"]
"shared_weights(3)$0" -> "q2words(3)$0" [label = "Add"]
"shared_weights(3)$0" -> "weights(3)" [label = "Add"]
"shared_weights(3)$0" -> "w(3)" [label = "Add"]
"shared_weights(3)$0" -> "0(3)" [label = "Add"]
"shared_weights(3)$0" -> "w(3)" [label = "Add"]
"shared_weights(3)$0" -> "q2words(3)$0" [label = "Add"]
"shared_weights(3)$0" -> "w(3)" [label = "Add"]
"shared_weights(3)$0" -> "q1words(3)$0" [label = "Add"]
"total_weights(3)$0" -> "weights(3)" [label = "Add"]
"total_weights(3)$0" -> "w(3)" [label = "Add"]
"total_weights(3)$0" -> "0(3)" [label = "Add"]
"total_weights(3)$0" -> "w(3)" [label = "Add"]
"total_weights(3)$0" -> "q1words(3)$0" [label = "Add"]
"total_weights(3)$0" -> "weights(3)" [label = "Add"]
"total_weights(3)$0" -> "w(3)" [label = "Add"]
"total_weights(3)$0" -> "0(3)" [label = "Add"]
"total_weights(3)$0" -> "w(3)" [label = "Add"]
"total_weights(3)$0" -> "q2words(3)$0" [label = "Add"]
"R(3)$0" -> "np(3)" [label = "Div"]
"R(3)$0" -> "shared_weights(3)$0" [label = "Div"]
"R(3)$0" -> "np(3)" [label = "Div"]
"R(3)$0" -> "total_weights(3)$0" [label = "Div"]
"plt(0)$29" -> "plt(0)$28" [label = "figure"]
"tfidf_train_word_match(0)$0" -> "df_train(0)$1" [label = "apply"]
"tfidf_train_word_match(0)$0" -> "tfidf_word_match_share(0)" [label = "apply"]
"tfidf_train_word_match(0)$0" -> "1(0)" [label = "apply"]
"plt(0)$30" -> "plt(0)$29" [label = "hist"]
"plt(0)$30" -> "tfidf_train_word_match(0)$0" [label = "hist"]
"plt(0)$30" -> "df_train(0)$1" [label = "hist"]
"plt(0)$30" -> "is_duplicate(0)" [label = "hist"]
"plt(0)$30" -> "0(0)" [label = "hist"]
"plt(0)$30" -> "0(0)" [label = "hist"]
"plt(0)$31" -> "plt(0)$30" [label = "hist"]
"plt(0)$31" -> "tfidf_train_word_match(0)$0" [label = "hist"]
"plt(0)$31" -> "df_train(0)$1" [label = "hist"]
"plt(0)$31" -> "is_duplicate(0)" [label = "hist"]
"plt(0)$31" -> "1(0)" [label = "hist"]
"plt(0)$31" -> "0(0)" [label = "hist"]
"plt(0)$32" -> "plt(0)$31" [label = "legend"]
"plt(0)$33" -> "plt(0)$32" [label = "title"]
"plt(0)$33" -> "Label distribution over tfidf_word_match_share(0)" [label = "title"]
"plt(0)$34" -> "plt(0)$33" [label = "xlabel"]
"plt(0)$34" -> "word_match_share(0)" [label = "xlabel"]
"print[0]" -> "Original AUC:(0)" [label = "print"]
"print[1]" -> "roc_auc_score(0)" [label = "print"]
"print[2]" -> "df_train(0)$1" [label = "print"]
"print[3]" -> "is_duplicate(0)" [label = "print"]
"print[4]" -> "train_word_match(0)$0" [label = "print"]
"print[0]" -> "   TFIDF AUC:(0)" [label = "print"]
"print[1]" -> "roc_auc_score(0)" [label = "print"]
"print[2]" -> "df_train(0)$1" [label = "print"]
"print[3]" -> "is_duplicate(0)" [label = "print"]
"print[4]" -> "tfidf_train_word_match(0)$0" [label = "print"]
"print[5]" -> "0(0)" [label = "print"]
"x_train(0)$0" -> "pd(0)" [label = "DataFrame"]
"x_test(0)$0" -> "pd(0)" [label = "DataFrame"]
"x_train(0)$1" -> "x_train(0)$0" [label = "eq"]
"x_train(0)$1" -> "train_word_match(0)$0" [label = "eq"]
"x_train(0)$2" -> "x_train(0)$1" [label = "eq"]
"x_train(0)$2" -> "tfidf_train_word_match(0)$0" [label = "eq"]
"x_test(0)$1" -> "x_test(0)$0" [label = "apply"]
"x_test(0)$1" -> "df_test(0)$2" [label = "apply"]
"x_test(0)$1" -> "word_match_share(0)" [label = "apply"]
"x_test(0)$1" -> "1(0)" [label = "apply"]
"x_test(0)$2" -> "x_test(0)$1" [label = "apply"]
"x_test(0)$2" -> "df_test(0)$2" [label = "apply"]
"x_test(0)$2" -> "tfidf_word_match_share(0)" [label = "apply"]
"x_test(0)$2" -> "1(0)" [label = "apply"]
"y_train(0)$0" -> "df_train(0)$1" [label = "eq"]
"y_train(0)$0" -> "is_duplicate(0)" [label = "eq"]
"pos_train(0)$0" -> "x_train(0)$2" [label = "eq"]
"pos_train(0)$0" -> "y_train(0)$0" [label = "eq"]
"pos_train(0)$0" -> "1(0)" [label = "eq"]
"neg_train(0)$0" -> "x_train(0)$2" [label = "eq"]
"neg_train(0)$0" -> "y_train(0)$0" [label = "eq"]
"neg_train(0)$0" -> "0(0)" [label = "eq"]
"p(0)$1" -> "0.165(0)" [label = "eq"]
"scale(0)$0" -> "len(0)" [label = "Sub"]
"scale(0)$0" -> "pos_train(0)$0" [label = "Sub"]
"scale(0)$0" -> "len(0)" [label = "Sub"]
"scale(0)$0" -> "pos_train(0)$0" [label = "Sub"]
"scale(0)$0" -> "len(0)" [label = "Sub"]
"scale(0)$0" -> "neg_train(0)$0" [label = "Sub"]
"scale(0)$0" -> "p(0)$1" [label = "Sub"]
"scale(0)$0" -> "1(0)" [label = "Sub"]
"neg_train(0)$1" -> "pd(0)" [label = "concat"]
"neg_train(0)$1" -> "[<_ast.Name object at 0x10421d250>, <_ast.Name object at 0x10421d150>](0)" [label = "concat"]
"scale(0)$1" -> "1(0)" [label = "Sub"]
"scale(0)$1" -> "scale(0)$0" [label = "Sub"]
"neg_train(0)$2" -> "pd(0)" [label = "concat"]
"neg_train(0)$2" -> "[<_ast.Name object at 0x10421d110>, <_ast.Subscript object at 0x10421dc10>](0)" [label = "concat"]
"print[0]" -> "len(0)" [label = "print"]
"print[1]" -> "pos_train(0)$0" [label = "print"]
"print[2]" -> "len(0)" [label = "print"]
"print[3]" -> "pos_train(0)$0" [label = "print"]
"print[4]" -> "len(0)" [label = "print"]
"print[5]" -> "neg_train(0)$2" [label = "print"]
"x_train(0)$3" -> "pd(0)" [label = "concat"]
"x_train(0)$3" -> "[<_ast.Name object at 0x10448f490>, <_ast.Name object at 0x10448f890>](0)" [label = "concat"]
"y_train(0)$1" -> "np(0)" [label = "Add"]
"y_train(0)$1" -> "len(0)" [label = "Add"]
"y_train(0)$1" -> "pos_train(0)$0" [label = "Add"]
"y_train(0)$1" -> "1(0)" [label = "Add"]
"y_train(0)$1" -> "np(0)" [label = "Add"]
"y_train(0)$1" -> "len(0)" [label = "Add"]
"y_train(0)$1" -> "neg_train(0)$2" [label = "Add"]
"x_train(0)$4" -> "x_train(0)$3" [label = "train_test_split"]
"x_valid(0)$0" -> "x_train(0)$3" [label = "train_test_split"]
"y_train(0)$2" -> "x_train(0)$3" [label = "train_test_split"]
"y_valid(0)$0" -> "x_train(0)$3" [label = "train_test_split"]
"x_train(0)$4" -> "y_train(0)$2" [label = "train_test_split"]
"x_valid(0)$0" -> "y_train(0)$2" [label = "train_test_split"]
"y_train(0)$2" -> "y_train(0)$2" [label = "train_test_split"]
"y_valid(0)$0" -> "y_train(0)$2" [label = "train_test_split"]
"x_train(0)$4" -> "0.2(0)" [label = "train_test_split"]
"x_valid(0)$0" -> "0.2(0)" [label = "train_test_split"]
"y_train(0)$2" -> "0.2(0)" [label = "train_test_split"]
"y_valid(0)$0" -> "0.2(0)" [label = "train_test_split"]
"x_train(0)$4" -> "4242(0)" [label = "train_test_split"]
"x_valid(0)$0" -> "4242(0)" [label = "train_test_split"]
"y_train(0)$2" -> "4242(0)" [label = "train_test_split"]
"y_valid(0)$0" -> "4242(0)" [label = "train_test_split"]
"params(0)$0" -> "params(0)" [label = "eq"]
"params(0)$0" -> "binary:logistic(0)" [label = "eq"]
"params(0)$1" -> "params(0)$0" [label = "eq"]
"params(0)$1" -> "logloss(0)" [label = "eq"]
"params(0)$2" -> "params(0)$1" [label = "eq"]
"params(0)$2" -> "0.02(0)" [label = "eq"]
"params(0)$3" -> "params(0)$2" [label = "eq"]
"params(0)$3" -> "4(0)" [label = "eq"]
"d_train(0)$0" -> "xgb(0)" [label = "DMatrix"]
"d_train(0)$0" -> "x_train(0)$4" [label = "DMatrix"]
"d_train(0)$0" -> "y_train(0)$2" [label = "DMatrix"]
"d_valid(0)$0" -> "xgb(0)" [label = "DMatrix"]
"d_valid(0)$0" -> "x_valid(0)$0" [label = "DMatrix"]
"d_valid(0)$0" -> "y_valid(0)$0" [label = "DMatrix"]
"watchlist(0)$0" -> "[<_ast.Tuple object at 0x1042a6850>, <_ast.Tuple object at 0x1042a6ed0>](0)" [label = "eq"]
"bst(0)$0" -> "xgb(0)" [label = "train"]
"bst(0)$0" -> "params(0)$3" [label = "train"]
"bst(0)$0" -> "d_train(0)$0" [label = "train"]
"bst(0)$0" -> "400(0)" [label = "train"]
"bst(0)$0" -> "watchlist(0)$0" [label = "train"]
"bst(0)$0" -> "50(0)" [label = "train"]
"bst(0)$0" -> "10(0)" [label = "train"]
"d_test(0)$0" -> "xgb(0)" [label = "DMatrix"]
"d_test(0)$0" -> "x_test(0)$2" [label = "DMatrix"]
"p_test(0)$0" -> "bst(0)$0" [label = "predict"]
"p_test(0)$0" -> "d_test(0)$0" [label = "predict"]
"sub(0)$3" -> "pd(0)" [label = "DataFrame"]
"sub(0)$4" -> "sub(0)$3" [label = "eq"]
"sub(0)$4" -> "df_test(0)$2" [label = "eq"]
"sub(0)$4" -> "test_id(0)" [label = "eq"]
"sub(0)$5" -> "sub(0)$4" [label = "eq"]
"sub(0)$5" -> "p_test(0)$0" [label = "eq"]
"sub(0)$6" -> "sub(0)$5" [label = "to_csv"]
"sub(0)$6" -> "simple_xgb.csv(0)" [label = "to_csv"]
}