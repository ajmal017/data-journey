digraph { 
"np(0)$0" -> "np(0)" [label = "set_printoptions"]
"PATH(0)$0" -> "../input/google-quest-challenge/(0)" [label = "eq"]
"BERT_PATH(0)$0" -> "../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12(0)" [label = "eq"]
"tokenizer(0)$0" -> "tokenization(0)" [label = "FullTokenizer"]
"tokenizer(0)$0" -> "BERT_PATH(0)$0" [label = "FullTokenizer"]
"tokenizer(0)$0" -> "/assets/vocab.txt(0)" [label = "FullTokenizer"]
"MAX_SEQUENCE_LENGTH(0)$0" -> "512(0)" [label = "eq"]
"df_train(0)$0" -> "pd(0)" [label = "read_csv"]
"df_train(0)$0" -> "PATH(0)$0" [label = "read_csv"]
"df_train(0)$0" -> "train.csv(0)" [label = "read_csv"]
"df_test(0)$0" -> "pd(0)" [label = "read_csv"]
"df_test(0)$0" -> "PATH(0)$0" [label = "read_csv"]
"df_test(0)$0" -> "test.csv(0)" [label = "read_csv"]
"df_sub(0)$0" -> "pd(0)" [label = "read_csv"]
"df_sub(0)$0" -> "PATH(0)$0" [label = "read_csv"]
"df_sub(0)$0" -> "sample_submission.csv(0)" [label = "read_csv"]
"print[0]" -> "train shape =(0)" [label = "print"]
"print[1]" -> "df_train(0)$0" [label = "print"]
"print[0]" -> "test shape =(0)" [label = "print"]
"print[1]" -> "df_test(0)$0" [label = "print"]
"output_categories(0)$0" -> "df_train(0)$0" [label = "list"]
"output_categories(0)$0" -> "11(0)" [label = "list"]
"input_categories(0)$0" -> "df_train(0)$0" [label = "list"]
"input_categories(0)$0" -> "[<_ast.Num object at 0x10b02d7d0>, <_ast.Num object at 0x10b02d790>, <_ast.Num object at 0x10b02d850>](0)" [label = "list"]
"print[0]" -> "
output categories:
	(0)" [label = "print"]
"print[1]" -> "output_categories(0)$0" [label = "print"]
"print[0]" -> "
input categories:
	(0)" [label = "print"]
"print[1]" -> "input_categories(0)$0" [label = "print"]
"tokens(1)" -> "_get_masks[0]" [label = "_argToVar"]
"max_seq_length(1)" -> "_get_masks[1]" [label = "_argToVar"]
"tokens(2)" -> "_get_segments[0]" [label = "_argToVar"]
"max_seq_length(2)" -> "_get_segments[1]" [label = "_argToVar"]
"segments(2)$0" -> "[](2)" [label = "eq"]
"current_segment_id(2)$0" -> "0(2)" [label = "eq"]
"token(2)" -> "tokens(2)" [label = "Iter"]
"segments(2)$1" -> "segments(2)$0" [label = "append"]
"segments(2)$1" -> "current_segment_id(2)$0" [label = "append"]
"current_segment_id(2)$1" -> "1(2)" [label = "eq"]
"tokens(3)" -> "_get_ids[0]" [label = "_argToVar"]
"tokenizer(3)" -> "_get_ids[1]" [label = "_argToVar"]
"max_seq_length(3)" -> "_get_ids[2]" [label = "_argToVar"]
"token_ids(3)$0" -> "tokenizer(3)" [label = "convert_tokens_to_ids"]
"token_ids(3)$0" -> "tokens(3)" [label = "convert_tokens_to_ids"]
"input_ids(3)$0" -> "token_ids(3)$0" [label = "Add"]
"input_ids(3)$0" -> "[<_ast.Num object at 0x10b028610>](3)" [label = "Add"]
"input_ids(3)$0" -> "max_seq_length(3)" [label = "Add"]
"input_ids(3)$0" -> "len(3)" [label = "Add"]
"input_ids(3)$0" -> "token_ids(3)$0" [label = "Add"]
"title(4)" -> "_trim_input[0]" [label = "_argToVar"]
"question(4)" -> "_trim_input[1]" [label = "_argToVar"]
"answer(4)" -> "_trim_input[2]" [label = "_argToVar"]
"max_sequence_length(4)" -> "_trim_input[3]" [label = "_argToVar"]
"t_max_len(4)" -> "_trim_input[4]" [label = "_argToVar"]
"q_max_len(4)" -> "_trim_input[5]" [label = "_argToVar"]
"a_max_len(4)" -> "_trim_input[6]" [label = "_argToVar"]
"t(4)$0" -> "tokenizer(4)" [label = "tokenize"]
"t(4)$0" -> "title(4)" [label = "tokenize"]
"q(4)$0" -> "tokenizer(4)" [label = "tokenize"]
"q(4)$0" -> "question(4)" [label = "tokenize"]
"a(4)$0" -> "tokenizer(4)" [label = "tokenize"]
"a(4)$0" -> "answer(4)" [label = "tokenize"]
"t_len(4)$0" -> "t(4)$0" [label = "len"]
"q_len(4)$0" -> "q(4)$0" [label = "len"]
"a_len(4)$0" -> "a(4)$0" [label = "len"]
"t_new_len(4)$0" -> "t_len(4)$0" [label = "eq"]
"a_max_len(4)$0" -> "a_max_len(4)" [label = "Add"]
"a_max_len(4)$0" -> "floor(4)" [label = "Add"]
"a_max_len(4)$0" -> "t_max_len(4)" [label = "Add"]
"a_max_len(4)$0" -> "t_len(4)$0" [label = "Add"]
"a_max_len(4)$0" -> "2(4)" [label = "Add"]
"q_max_len(4)$0" -> "q_max_len(4)" [label = "Add"]
"q_max_len(4)$0" -> "ceil(4)" [label = "Add"]
"q_max_len(4)$0" -> "t_max_len(4)" [label = "Add"]
"q_max_len(4)$0" -> "t_len(4)$0" [label = "Add"]
"q_max_len(4)$0" -> "2(4)" [label = "Add"]
"t_new_len(4)$1" -> "t_max_len(4)" [label = "eq"]
"a_new_len(4)$0" -> "a_len(4)$0" [label = "eq"]
"q_new_len(4)$0" -> "q_max_len(4)$0" [label = "Add"]
"q_new_len(4)$0" -> "a_max_len(4)$0" [label = "Add"]
"q_new_len(4)$0" -> "a_len(4)$0" [label = "Add"]
"a_new_len(4)$1" -> "a_max_len(4)$0" [label = "Add"]
"a_new_len(4)$1" -> "q_max_len(4)$0" [label = "Add"]
"a_new_len(4)$1" -> "q_len(4)$0" [label = "Add"]
"q_new_len(4)$1" -> "q_len(4)$0" [label = "eq"]
"a_new_len(4)$2" -> "a_max_len(4)$0" [label = "eq"]
"q_new_len(4)$2" -> "q_max_len(4)$0" [label = "eq"]
"t(4)$1" -> "t(4)$0" [label = "eq"]
"t(4)$1" -> "t_new_len(4)$1" [label = "eq"]
"q(4)$1" -> "q(4)$0" [label = "eq"]
"q(4)$1" -> "q_new_len(4)$2" [label = "eq"]
"a(4)$1" -> "a(4)$0" [label = "eq"]
"a(4)$1" -> "a_new_len(4)$2" [label = "eq"]
"title(5)" -> "_convert_to_bert_inputs[0]" [label = "_argToVar"]
"question(5)" -> "_convert_to_bert_inputs[1]" [label = "_argToVar"]
"answer(5)" -> "_convert_to_bert_inputs[2]" [label = "_argToVar"]
"tokenizer(5)" -> "_convert_to_bert_inputs[3]" [label = "_argToVar"]
"max_sequence_length(5)" -> "_convert_to_bert_inputs[4]" [label = "_argToVar"]
"stoken(5)$0" -> "[<_ast.Str object at 0x10b003a50>](5)" [label = "Add"]
"stoken(5)$0" -> "title(5)" [label = "Add"]
"stoken(5)$0" -> "[<_ast.Str object at 0x10b003e10>](5)" [label = "Add"]
"stoken(5)$0" -> "question(5)" [label = "Add"]
"stoken(5)$0" -> "[<_ast.Str object at 0x10b003e90>](5)" [label = "Add"]
"stoken(5)$0" -> "answer(5)" [label = "Add"]
"stoken(5)$0" -> "[<_ast.Str object at 0x10b003c90>](5)" [label = "Add"]
"input_ids(5)$0" -> "stoken(5)$0" [label = "_get_ids"]
"input_ids(5)$0" -> "tokenizer(5)" [label = "_get_ids"]
"input_ids(5)$0" -> "max_sequence_length(5)" [label = "_get_ids"]
"input_masks(5)$0" -> "stoken(5)$0" [label = "_get_masks"]
"input_masks(5)$0" -> "max_sequence_length(5)" [label = "_get_masks"]
"input_segments(5)$0" -> "stoken(5)$0" [label = "_get_segments"]
"input_segments(5)$0" -> "max_sequence_length(5)" [label = "_get_segments"]
"df(6)" -> "compute_input_arays[0]" [label = "_argToVar"]
"columns(6)" -> "compute_input_arays[1]" [label = "_argToVar"]
"tokenizer(6)" -> "compute_input_arays[2]" [label = "_argToVar"]
"max_sequence_length(6)" -> "compute_input_arays[3]" [label = "_argToVar"]
"input_ids(6)$0" -> "[](6)" [label = "eq"]
"input_masks(6)$0" -> "[](6)" [label = "eq"]
"input_segments(6)$0" -> "[](6)" [label = "eq"]
"input_ids(6)$0" -> "[](6)" [label = "eq"]
"input_masks(6)$0" -> "[](6)" [label = "eq"]
"input_segments(6)$0" -> "[](6)" [label = "eq"]
"input_ids(6)$0" -> "[](6)" [label = "eq"]
"input_masks(6)$0" -> "[](6)" [label = "eq"]
"input_segments(6)$0" -> "[](6)" [label = "eq"]
"_(6)" -> "tqdm(6)" [label = "Iter"]
"instance(6)" -> "tqdm(6)" [label = "Iter"]
"_(6)" -> "df(6)" [label = "Iter"]
"instance(6)" -> "df(6)" [label = "Iter"]
"_(6)" -> "columns(6)" [label = "Iter"]
"instance(6)" -> "columns(6)" [label = "Iter"]
"t(6)$0" -> "instance(6)" [label = "eq"]
"q(6)$0" -> "instance(6)" [label = "eq"]
"a(6)$0" -> "instance(6)" [label = "eq"]
"t(6)$0" -> "instance(6)" [label = "eq"]
"q(6)$0" -> "instance(6)" [label = "eq"]
"a(6)$0" -> "instance(6)" [label = "eq"]
"t(6)$0" -> "instance(6)" [label = "eq"]
"q(6)$0" -> "instance(6)" [label = "eq"]
"a(6)$0" -> "instance(6)" [label = "eq"]
"t(6)$1" -> "t(6)$0" [label = "_trim_input"]
"q(6)$1" -> "t(6)$0" [label = "_trim_input"]
"a(6)$1" -> "t(6)$0" [label = "_trim_input"]
"t(6)$1" -> "q(6)$1" [label = "_trim_input"]
"q(6)$1" -> "q(6)$1" [label = "_trim_input"]
"a(6)$1" -> "q(6)$1" [label = "_trim_input"]
"t(6)$1" -> "a(6)$1" [label = "_trim_input"]
"q(6)$1" -> "a(6)$1" [label = "_trim_input"]
"a(6)$1" -> "a(6)$1" [label = "_trim_input"]
"t(6)$1" -> "max_sequence_length(6)" [label = "_trim_input"]
"q(6)$1" -> "max_sequence_length(6)" [label = "_trim_input"]
"a(6)$1" -> "max_sequence_length(6)" [label = "_trim_input"]
"ids(6)$0" -> "t(6)$1" [label = "_convert_to_bert_inputs"]
"masks(6)$0" -> "t(6)$1" [label = "_convert_to_bert_inputs"]
"segments(6)$0" -> "t(6)$1" [label = "_convert_to_bert_inputs"]
"ids(6)$0" -> "q(6)$1" [label = "_convert_to_bert_inputs"]
"masks(6)$0" -> "q(6)$1" [label = "_convert_to_bert_inputs"]
"segments(6)$0" -> "q(6)$1" [label = "_convert_to_bert_inputs"]
"ids(6)$0" -> "a(6)$1" [label = "_convert_to_bert_inputs"]
"masks(6)$0" -> "a(6)$1" [label = "_convert_to_bert_inputs"]
"segments(6)$0" -> "a(6)$1" [label = "_convert_to_bert_inputs"]
"ids(6)$0" -> "tokenizer(6)" [label = "_convert_to_bert_inputs"]
"masks(6)$0" -> "tokenizer(6)" [label = "_convert_to_bert_inputs"]
"segments(6)$0" -> "tokenizer(6)" [label = "_convert_to_bert_inputs"]
"ids(6)$0" -> "max_sequence_length(6)" [label = "_convert_to_bert_inputs"]
"masks(6)$0" -> "max_sequence_length(6)" [label = "_convert_to_bert_inputs"]
"segments(6)$0" -> "max_sequence_length(6)" [label = "_convert_to_bert_inputs"]
"input_ids(6)$1" -> "input_ids(6)$0" [label = "append"]
"input_ids(6)$1" -> "ids(6)$0" [label = "append"]
"input_masks(6)$1" -> "input_masks(6)$0" [label = "append"]
"input_masks(6)$1" -> "masks(6)$0" [label = "append"]
"input_segments(6)$1" -> "input_segments(6)$0" [label = "append"]
"input_segments(6)$1" -> "segments(6)$0" [label = "append"]
"df(7)" -> "compute_output_arrays[0]" [label = "_argToVar"]
"columns(7)" -> "compute_output_arrays[1]" [label = "_argToVar"]
"trues(8)" -> "compute_spearmanr[0]" [label = "_argToVar"]
"preds(8)" -> "compute_spearmanr[1]" [label = "_argToVar"]
"rhos(8)$0" -> "[](8)" [label = "eq"]
"col_trues(8)" -> "zip(8)" [label = "Iter"]
"col_pred(8)" -> "zip(8)" [label = "Iter"]
"col_trues(8)" -> "trues(8)" [label = "Iter"]
"col_pred(8)" -> "trues(8)" [label = "Iter"]
"col_trues(8)" -> "preds(8)" [label = "Iter"]
"col_pred(8)" -> "preds(8)" [label = "Iter"]
"rhos(8)$1" -> "rhos(8)$0" [label = "append"]
"rhos(8)$1" -> "spearmanr(8)" [label = "append"]
"rhos(8)$1" -> "col_trues(8)" [label = "append"]
"rhos(8)$1" -> "col_pred(8)" [label = "append"]
"rhos(8)$1" -> "np(8)" [label = "append"]
"rhos(8)$1" -> "0(8)" [label = "append"]
"rhos(8)$1" -> "1e-07(8)" [label = "append"]
"rhos(8)$1" -> "col_pred(8)" [label = "append"]
"rhos(8)$1" -> "0(8)" [label = "append"]
"self(10)" -> "__init__[0]" [label = "_argToVar"]
"valid_data(10)" -> "__init__[1]" [label = "_argToVar"]
"test_data(10)" -> "__init__[2]" [label = "_argToVar"]
"batch_size(10)" -> "__init__[3]" [label = "_argToVar"]
"fold(10)" -> "__init__[4]" [label = "_argToVar"]
"self(10)$0" -> "self(10)" [label = "eq"]
"self(10)$0" -> "valid_data(10)" [label = "eq"]
"self(10)$0" -> "0(10)" [label = "eq"]
"self(10)$1" -> "self(10)$0" [label = "eq"]
"self(10)$1" -> "valid_data(10)" [label = "eq"]
"self(10)$1" -> "1(10)" [label = "eq"]
"self(10)$2" -> "self(10)$1" [label = "eq"]
"self(10)$2" -> "test_data(10)" [label = "eq"]
"self(10)$3" -> "self(10)$2" [label = "eq"]
"self(10)$3" -> "batch_size(10)" [label = "eq"]
"self(10)$4" -> "self(10)$3" [label = "eq"]
"self(10)$4" -> "fold(10)" [label = "eq"]
"self(11)" -> "on_train_begin[0]" [label = "_argToVar"]
"logs(11)" -> "on_train_begin[1]" [label = "_argToVar"]
"self(11)$0" -> "self(11)" [label = "eq"]
"self(11)$0" -> "[](11)" [label = "eq"]
"self(11)$1" -> "self(11)$0" [label = "eq"]
"self(11)$1" -> "[](11)" [label = "eq"]
"self(12)" -> "on_epoch_end[0]" [label = "_argToVar"]
"epoch(12)" -> "on_epoch_end[1]" [label = "_argToVar"]
"logs(12)" -> "on_epoch_end[2]" [label = "_argToVar"]
"self(12)$0" -> "self(12)" [label = "append"]
"self(12)$0" -> "self(12)$0" [label = "append"]
"self(12)$0" -> "self(12)$0" [label = "append"]
"self(12)$0" -> "self(12)$0" [label = "append"]
"rho_val(12)$0" -> "self(12)$0" [label = "compute_spearmanr"]
"rho_val(12)$0" -> "np(12)" [label = "compute_spearmanr"]
"rho_val(12)$0" -> "self(12)$0" [label = "compute_spearmanr"]
"rho_val(12)$0" -> "0(12)" [label = "compute_spearmanr"]
"print[0]" -> "
validation rho: %.4f(12)" [label = "print"]
"print[1]" -> "rho_val(12)$0" [label = "print"]
"self(12)$1" -> "self(12)$0" [label = "save_weights"]
"self(12)$1" -> "bert-base-(12)" [label = "save_weights"]
"self(12)$1" -> "fold(12)" [label = "save_weights"]
"self(12)$1" -> "-(12)" [label = "save_weights"]
"self(12)$1" -> "epoch(12)" [label = "save_weights"]
"self(12)$1" -> ".h5py(12)" [label = "save_weights"]
"self(12)$2" -> "self(12)$1" [label = "append"]
"self(12)$2" -> "self(12)$2" [label = "append"]
"self(12)$2" -> "self(12)$2" [label = "append"]
"self(12)$2" -> "self(12)$2" [label = "append"]
"input_word_ids(13)$0" -> "tf(13)" [label = "Input"]
"input_word_ids(13)$0" -> "MAX_SEQUENCE_LENGTH(13)" [label = "Input"]
"input_word_ids(13)$0" -> "tf(13)" [label = "Input"]
"input_word_ids(13)$0" -> "input_word_ids(13)$0" [label = "Input"]
"input_masks(13)$0" -> "tf(13)" [label = "Input"]
"input_masks(13)$0" -> "MAX_SEQUENCE_LENGTH(13)" [label = "Input"]
"input_masks(13)$0" -> "tf(13)" [label = "Input"]
"input_masks(13)$0" -> "input_masks(13)$0" [label = "Input"]
"input_segments(13)$0" -> "tf(13)" [label = "Input"]
"input_segments(13)$0" -> "MAX_SEQUENCE_LENGTH(13)" [label = "Input"]
"input_segments(13)$0" -> "tf(13)" [label = "Input"]
"input_segments(13)$0" -> "input_segments(13)$0" [label = "Input"]
"bert_layer(13)$0" -> "hub(13)" [label = "KerasLayer"]
"bert_layer(13)$0" -> "BERT_PATH(13)" [label = "KerasLayer"]
"_(13)$0" -> "[<_ast.Name object at 0x10b012790>, <_ast.Name object at 0x10b012190>, <_ast.Name object at 0x10b012d50>](13)" [label = "bert_layer"]
"sequence_output(13)$0" -> "[<_ast.Name object at 0x10b012790>, <_ast.Name object at 0x10b012190>, <_ast.Name object at 0x10b012d50>](13)" [label = "bert_layer"]
"x(13)$0" -> "tf(13)" [label = "eq"]
"x(13)$0" -> "sequence_output(13)$0" [label = "eq"]
"x(13)$1" -> "tf(13)" [label = "eq"]
"x(13)$1" -> "0.2(13)" [label = "eq"]
"x(13)$1" -> "x(13)$1" [label = "eq"]
"out(13)$0" -> "tf(13)" [label = "eq"]
"out(13)$0" -> "30(13)" [label = "eq"]
"out(13)$0" -> "sigmoid(13)" [label = "eq"]
"out(13)$0" -> "dense_output(13)" [label = "eq"]
"out(13)$0" -> "x(13)$1" [label = "eq"]
"model(13)$0" -> "tf(13)" [label = "Model"]
"model(13)$0" -> "[<_ast.Name object at 0x10a171450>, <_ast.Name object at 0x10a171050>, <_ast.Name object at 0x10a1718d0>](13)" [label = "Model"]
"model(13)$0" -> "out(13)$0" [label = "Model"]
"model(14)" -> "train_and_predict[0]" [label = "_argToVar"]
"train_data(14)" -> "train_and_predict[1]" [label = "_argToVar"]
"valid_data(14)" -> "train_and_predict[2]" [label = "_argToVar"]
"test_data(14)" -> "train_and_predict[3]" [label = "_argToVar"]
"learning_rate(14)" -> "train_and_predict[4]" [label = "_argToVar"]
"epochs(14)" -> "train_and_predict[5]" [label = "_argToVar"]
"batch_size(14)" -> "train_and_predict[6]" [label = "_argToVar"]
"loss_function(14)" -> "train_and_predict[7]" [label = "_argToVar"]
"fold(14)" -> "train_and_predict[8]" [label = "_argToVar"]
"custom_callback(14)$0" -> "valid_data(14)" [label = "CustomCallback"]
"custom_callback(14)$0" -> "0(14)" [label = "CustomCallback"]
"custom_callback(14)$0" -> "valid_data(14)" [label = "CustomCallback"]
"custom_callback(14)$0" -> "1(14)" [label = "CustomCallback"]
"custom_callback(14)$0" -> "test_data(14)" [label = "CustomCallback"]
"custom_callback(14)$0" -> "batch_size(14)" [label = "CustomCallback"]
"optimizer(14)$0" -> "tf(14)" [label = "Adam"]
"optimizer(14)$0" -> "learning_rate(14)" [label = "Adam"]
"model(14)$0" -> "model(14)" [label = "compile"]
"model(14)$1" -> "model(14)$0" [label = "fit"]
"model(14)$1" -> "train_data(14)" [label = "fit"]
"model(14)$1" -> "0(14)" [label = "fit"]
"model(14)$1" -> "train_data(14)" [label = "fit"]
"model(14)$1" -> "1(14)" [label = "fit"]
"gkf(0)$0" -> "GroupKFold(0)" [label = "split"]
"gkf(0)$0" -> "5(0)" [label = "split"]
"gkf(0)$0" -> "df_train(0)$0" [label = "split"]
"gkf(0)$0" -> "df_train(0)$0" [label = "split"]
"outputs(0)$0" -> "df_train(0)$0" [label = "compute_output_arrays"]
"outputs(0)$0" -> "output_categories(0)$0" [label = "compute_output_arrays"]
"inputs(0)$0" -> "df_train(0)$0" [label = "compute_input_arays"]
"inputs(0)$0" -> "input_categories(0)$0" [label = "compute_input_arays"]
"inputs(0)$0" -> "tokenizer(0)$0" [label = "compute_input_arays"]
"inputs(0)$0" -> "MAX_SEQUENCE_LENGTH(0)$0" [label = "compute_input_arays"]
"test_inputs(0)$0" -> "df_test(0)$0" [label = "compute_input_arays"]
"test_inputs(0)$0" -> "input_categories(0)$0" [label = "compute_input_arays"]
"test_inputs(0)$0" -> "tokenizer(0)$0" [label = "compute_input_arays"]
"test_inputs(0)$0" -> "MAX_SEQUENCE_LENGTH(0)$0" [label = "compute_input_arays"]
"histories(0)$0" -> "[](0)" [label = "eq"]
"fold(0)" -> "enumerate(0)" [label = "Iter"]
"train_idx(0)" -> "enumerate(0)" [label = "Iter"]
"valid_idx(0)" -> "enumerate(0)" [label = "Iter"]
"fold(0)" -> "gkf(0)$0" [label = "Iter"]
"train_idx(0)" -> "gkf(0)$0" [label = "Iter"]
"valid_idx(0)" -> "gkf(0)$0" [label = "Iter"]
"K(0)$0" -> "K(0)" [label = "clear_session"]
"train_inputs(0)$0" -> "inputs(0)$0" [label = "eq"]
"train_inputs(0)$0" -> "i(0)" [label = "eq"]
"train_inputs(0)$0" -> "train_idx(0)" [label = "eq"]
"train_inputs(0)$0" -> "i(0)" [label = "eq"]
"train_inputs(0)$0" -> "range(0)" [label = "eq"]
"train_inputs(0)$0" -> "3(0)" [label = "eq"]
"train_outputs(0)$0" -> "outputs(0)$0" [label = "eq"]
"train_outputs(0)$0" -> "train_idx(0)" [label = "eq"]
"valid_inputs(0)$0" -> "inputs(0)$0" [label = "eq"]
"valid_inputs(0)$0" -> "i(0)" [label = "eq"]
"valid_inputs(0)$0" -> "valid_idx(0)" [label = "eq"]
"valid_inputs(0)$0" -> "i(0)" [label = "eq"]
"valid_inputs(0)$0" -> "range(0)" [label = "eq"]
"valid_inputs(0)$0" -> "3(0)" [label = "eq"]
"valid_outputs(0)$0" -> "outputs(0)$0" [label = "eq"]
"valid_outputs(0)$0" -> "valid_idx(0)" [label = "eq"]
"history(0)$0" -> "model(0)" [label = "train_and_predict"]
"history(0)$0" -> "train_inputs(0)$0" [label = "train_and_predict"]
"history(0)$0" -> "train_outputs(0)$0" [label = "train_and_predict"]
"history(0)$0" -> "valid_inputs(0)$0" [label = "train_and_predict"]
"history(0)$0" -> "valid_outputs(0)$0" [label = "train_and_predict"]
"history(0)$0" -> "test_inputs(0)$0" [label = "train_and_predict"]
"history(0)$0" -> "3e-05(0)" [label = "train_and_predict"]
"history(0)$0" -> "4(0)" [label = "train_and_predict"]
"history(0)$0" -> "8(0)" [label = "train_and_predict"]
"history(0)$0" -> "binary_crossentropy(0)" [label = "train_and_predict"]
"history(0)$0" -> "fold(0)" [label = "train_and_predict"]
"histories(0)$1" -> "histories(0)$0" [label = "append"]
"histories(0)$1" -> "history(0)$0" [label = "append"]
"test_predictions(0)$0" -> "histories(0)$1" [label = "eq"]
"test_predictions(0)$0" -> "i(0)" [label = "eq"]
"test_predictions(0)$0" -> "i(0)" [label = "eq"]
"test_predictions(0)$0" -> "range(0)" [label = "eq"]
"test_predictions(0)$0" -> "len(0)" [label = "eq"]
"test_predictions(0)$0" -> "histories(0)$1" [label = "eq"]
"test_predictions(0)$1" -> "np(0)$0" [label = "eq"]
"test_predictions(0)$1" -> "test_predictions(0)$1" [label = "eq"]
"test_predictions(0)$1" -> "i(0)" [label = "eq"]
"test_predictions(0)$1" -> "0(0)" [label = "eq"]
"test_predictions(0)$1" -> "i(0)" [label = "eq"]
"test_predictions(0)$1" -> "range(0)" [label = "eq"]
"test_predictions(0)$1" -> "len(0)" [label = "eq"]
"test_predictions(0)$1" -> "test_predictions(0)$1" [label = "eq"]
"test_predictions(0)$2" -> "np(0)$0" [label = "mean"]
"test_predictions(0)$2" -> "test_predictions(0)$2" [label = "mean"]
"test_predictions(0)$2" -> "0(0)" [label = "mean"]
"df_sub(0)$1" -> "df_sub(0)$0" [label = "eq"]
"df_sub(0)$1" -> "test_predictions(0)$2" [label = "eq"]
"df_sub(0)$2" -> "df_sub(0)$1" [label = "to_csv"]
"df_sub(0)$2" -> "submission.csv(0)" [label = "to_csv"]
}